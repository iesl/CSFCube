======================================================================
paper_id: 11310392; YEAR: 2017
TITLE: The BURCHAK corpus: a Challenge Data Set for Interactive Learning of Visually Grounded Word Meanings
ABSTRACT: background_label: We motivate and describe a new freely available human-human dialogue dataset for interactive learning of visually grounded word meanings through ostensive definition by a tutor to a learner.
method_label: The data has been collected using a novel, character-by-character variant of the DiET chat tool (Healey et al., 2003; Mills and Healey, submitted) with a novel task, where a Learner needs to learn invented visual attribute words (such as"burchak"for square) from a tutor.
method_label: As such, the text-based interactions closely resemble face-to-face conversation and thus contain many of the linguistic phenomena encountered in natural, spontaneous dialogue.
method_label: These include self-and other-correction, mid-sentence continuations, interruptions, overlaps, fillers, and hedges.
other_label: We also present a generic n-gram framework for building user (i.e.
method_label: tutor) simulations from this type of incremental data, which is freely available to researchers.
result_label: We show that the simulations produce outputs that are similar to the original data (e.g.
result_label: 78% turn match similarity).
result_label: Finally, we train and evaluate a Reinforcement Learning dialogue control agent for learning visually grounded word meanings, trained from the BURCHAK corpus.
result_label: The learned policy shows comparable performance to a rule-based system built previously.
===================================
paper_id: 174798275; YEAR: 2019
adju relevance: Identical (+3)
difference: 1; annotator4: 3; annotator3: 2
sources: specter - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - abs_tfidfcbow200
TITLE: The PhotoBook Dataset: Building Common Ground through Visually-Grounded Dialogue
ABSTRACT: background_label: This paper introduces the PhotoBook dataset, a large-scale collection of visually-grounded, task-oriented dialogues in English designed to investigate shared dialogue history accumulating during conversation.
method_label: Taking inspiration from seminal work on dialogue analysis, we propose a data-collection task formulated as a collaborative game prompting two online participants to refer to images utilising both their visual context as well as previously established referring expressions.
method_label: We provide a detailed description of the task setup and a thorough analysis of the 2,500 dialogues collected.
method_label: To further illustrate the novel features of the dataset, we propose a baseline model for reference resolution which uses a simple method to take into account shared information accumulated in a reference chain.
result_label: Our results show that this information is particularly important to resolve later descriptions and underline the need to develop more sophisticated models of common ground in dialogue interaction.

===================================
paper_id: 1820614; YEAR: 2016
adju relevance: Identical (+3)
difference: 2; annotator4: 1; annotator3: 3
sources: abs_cbow200
TITLE: Visual Dialog
ABSTRACT: background_label: We introduce the task of Visual Dialog, which requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content.
background_label: Specifically, given an image, a dialog history, and a question about the image, the agent has to ground the question in image, infer context from history, and answer the question accurately.
objective_label: Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence, while being grounded in vision enough to allow objective evaluation of individual responses and benchmark progress.
method_label: We develop a novel two-person chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial).
method_label: VisDial v0.9 has been released and contains 1 dialog with 10 question-answer pairs on ~120k images from COCO, with a total of ~1.2M dialog question-answer pairs.
method_label: We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders -- Late Fusion, Hierarchical Recurrent Encoder and Memory Network -- and 2 decoders (generative and discriminative), which outperform a number of sophisticated baselines.
method_label: We propose a retrieval-based evaluation protocol for Visual Dialog where the AI agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank of human response.
method_label: We quantify gap between machine and human performance on the Visual Dialog task via human studies.
other_label: Putting it all together, we demonstrate the first 'visual chatbot'!
other_label: Our dataset, code, trained models and visual chatbot are available on https://visualdialog.org

===================================
paper_id: 52197708; YEAR: 2018
adju relevance: Identical (+3)
difference: 1; annotator4: 2; annotator3: 3
sources: abs_tfidf
TITLE: Game-Based Video-Context Dialogue
ABSTRACT: background_label: Current dialogue systems focus more on textual and speech context knowledge and are usually based on two speakers.
background_label: Some recent work has investigated static image-based dialogue.
background_label: However, several real-world human interactions also involve dynamic visual context (similar to videos) as well as dialogue exchanges among multiple speakers.
method_label: To move closer towards such multimodal conversational skills and visually-situated applications, we introduce a new video-context, many-speaker dialogue dataset based on live-broadcast soccer game videos and chats from Twitch.tv.
method_label: This challenging testbed allows us to develop visually-grounded dialogue models that should generate relevant temporal and spatial event language from the live video, while also being relevant to the chat history.
method_label: For strong baselines, we also present several discriminative and generative models, e.g., based on tridirectional attention flow (TriDAF).
result_label: We evaluate these models via retrieval ranking-recall, automatic phrase-matching metrics, as well as human evaluation studies.
result_label: We also present dataset analyses, model ablations, and visualizations to understand the contribution of different modalities and model components.

===================================
paper_id: 202565569; YEAR: 2019
adju relevance: Similar (+2)
difference: 1; annotator4: 2; annotator3: 1
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset
ABSTRACT: background_label: A significant barrier to progress in data-driven approaches to building dialog systems is the lack of high quality, goal-oriented conversational data.
method_label: To help satisfy this elementary requirement, we introduce the initial release of the Taskmaster-1 dataset which includes 13,215 task-based dialogs comprising six domains.
method_label: Two procedures were used to create this collection, each with unique advantages.
method_label: The first involves a two-person, spoken"Wizard of Oz"(WOz) approach in which trained agents and crowdsourced workers interact to complete the task while the second is"self-dialog"in which crowdsourced workers write the entire dialog themselves.
method_label: We do not restrict the workers to detailed scripts or to a small knowledge base and hence we observe that our dataset contains more realistic and diverse conversations in comparison to existing datasets.
method_label: We offer several baseline models including state of the art neural seq2seq architectures with benchmark performance as well as qualitative human evaluations.
method_label: Dialogs are labeled with API calls and arguments, a simple and cost effective approach which avoids the requirement of complex annotation schema.
method_label: The layer of abstraction between the dialog model and the service provider API allows for a given model to interact with multiple services that provide similar functionally.
result_label: Finally, the dataset will evoke interest in written vs. spoken language, discourse patterns, error handling and other linguistic phenomena related to dialog system research, development and design.

===================================
paper_id: 195886289; YEAR: 2019
adju relevance: Similar (+2)
difference: 0; annotator4: 2; annotator3: 2
sources: specter
TITLE: MeetUp! A Corpus of Joint Activity Dialogues in a Visual Environment
ABSTRACT: background_label: Building computer systems that can converse about their visual environment is one of the oldest concerns of research in Artificial Intelligence and Computational Linguistics (see, for example, Winograd's 1972 SHRDLU system).
background_label: Only recently, however, have methods from computer vision and natural language processing become powerful enough to make this vision seem more attainable.
background_label: Pushed especially by developments in computer vision, many data sets and collection environments have recently been published that bring together verbal interaction and visual processing.
objective_label: Here, we argue that these datasets tend to oversimplify the dialogue part, and we propose a task---MeetUp!---that requires both visual and conversational grounding, and that makes stronger demands on representations of the discourse.
other_label: MeetUp!
method_label: is a two-player coordination game where players move in a visual environment, with the objective of finding each other.
method_label: To do so, they must talk about what they see, and achieve mutual understanding.
result_label: We describe a data collection and show that the resulting dialogues indeed exhibit the dialogue phenomena of interest, while also challenging the language&vision aspect.

===================================
paper_id: 8143148; YEAR: 2017
adju relevance: Similar (+2)
difference: 2; annotator4: 0; annotator3: 2
sources: abs_tfidf - title_tfidf
TITLE: End-to-end optimization of goal-driven and visually grounded dialogue systems
ABSTRACT: background_label: End-to-end design of dialogue systems has recently become a popular research topic thanks to powerful tools such as encoder-decoder architectures for sequence-to-sequence learning.
background_label: Yet, most current approaches cast human-machine dialogue management as a supervised learning problem, aiming at predicting the next utterance of a participant given the full history of the dialogue.
background_label: This vision is too simplistic to render the intrinsic planning problem inherent to dialogue as well as its grounded nature, making the context of a dialogue larger than the sole history.
background_label: This is why only chit-chat and question answering tasks have been addressed so far using end-to-end architectures.
method_label: In this paper, we introduce a Deep Reinforcement Learning method to optimize visually grounded task-oriented dialogues, based on the policy gradient algorithm.
result_label: This approach is tested on a dataset of 120k dialogues collected through Mechanical Turk and provides encouraging results at solving both the problem of generating natural dialogues and the task of discovering a specific object in a complex picture.

===================================
paper_id: 27418157; YEAR: 2017
adju relevance: Similar (+2)
difference: 1; annotator4: 2; annotator3: 3
sources: title_tfidf - abs_tfidf - specter
TITLE: Learning how to learn: an adaptive dialogue agent for incrementally learning visually grounded word meanings
ABSTRACT: background_label: We present an optimised multi-modal dialogue agent for interactive learning of visually grounded word meanings from a human tutor, trained on real human-human tutoring data.
background_label: Within a life-long interactive learning period, the agent, trained using Reinforcement Learning (RL), must be able to handle natural conversations with human users and achieve good learning performance (accuracy) while minimising human effort in the learning process.
method_label: We train and evaluate this system in interaction with a simulated human tutor, which is built on the BURCHAK corpus -- a Human-Human Dialogue dataset for the visual learning task.
result_label: The results show that: 1) The learned policy can coherently interact with the simulated user to achieve the goal of the task (i.e.
result_label: learning visual attributes of objects, e.g.
result_label: colour and shape); and 2) it finds a better trade-off between classifier accuracy and tutoring costs than hand-crafted rule-based policies, including ones with dynamic policies.

===================================
paper_id: 11039143; YEAR: 2007
adju relevance: Similar (+2)
difference: 1; annotator4: 1; annotator3: 2
sources: abs_tfidfcbow200 - abs_cbow200 - specter
TITLE: Developmental Word Acquisition and Grammar Learning by Humanoid Robots Through a Self-Organizing Incremental Neural Network
ABSTRACT: objective_label: We present a new approach for online incremental word acquisition and grammar learning by humanoid robots.
background_label: Using no data set provided in advance, the proposed system grounds language in a physical context, as mediated by its perceptual capacities.
method_label: It is carried out using show-and-tell procedures, interacting with its human partner.
method_label: Moreover, this procedure is open-ended for new words and multiword utterances.
method_label: These facilities are supported by a self-organizing incremental neural network, which can execute online unsupervised classification and topology learning.
method_label: Embodied with a mental imagery, the system also learns by both top-down and bottom-up processes, which are the syntactic structures that are contained in utterances.
method_label: Thereby, it performs simple grammar learning.
method_label: Under such a multimodal scheme, the robot is able to describe online a given physical context (both static and dynamic) through natural language expressions.
result_label: It can also perform actions through verbal interactions with its human partner.

===================================
paper_id: 49876295; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_tfidf
TITLE: Towards Explainable and Controllable Open Domain Dialogue Generation with Dialogue Acts
ABSTRACT: background_label: We study open domain dialogue generation with dialogue acts designed to explain how people engage in social chat.
objective_label: To imitate human behavior, we propose managing the flow of human-machine interactions with the dialogue acts as policies.
method_label: The policies and response generation are jointly learned from human-human conversations, and the former is further optimized with a reinforcement learning approach.
result_label: With the dialogue acts, we achieve significant improvement over state-of-the-art methods on response quality for given contexts and dialogue length in both machine-machine simulation and human-machine conversation.

===================================
paper_id: 4938015; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_tfidf
TITLE: Dialogue Learning with Human Teaching and Feedback in End-to-End Trainable Task-Oriented Dialogue Systems
ABSTRACT: background_label: In this work, we present a hybrid learning method for training task-oriented dialogue systems through online user interactions.
method_label: Popular methods for learning task-oriented dialogues include applying reinforcement learning with user feedback on supervised pre-training models.
method_label: Efficiency of such learning method may suffer from the mismatch of dialogue state distribution between offline training and online interactive learning stages.
method_label: To address this challenge, we propose a hybrid imitation and reinforcement learning method, with which a dialogue agent can effectively learn from its interaction with users by learning from human teaching and feedback.
method_label: We design a neural network based task-oriented dialogue agent that can be optimized end-to-end with the proposed learning method.
result_label: Experimental results show that our end-to-end dialogue agent can learn effectively from the mistake it makes via imitation learning from user teaching.
result_label: Applying reinforcement learning with user feedback after the imitation learning stage further improves the agent's capability in successfully completing a task.

===================================
paper_id: 1072465; YEAR: 2012
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: specter
TITLE: Exploiting Social Information in Grounded Language Learning via Grammatical Reduction
ABSTRACT: background_label: AbstractThis paper uses an unsupervised model of grounded language acquisition to study the role that social cues play in language acquisition.
method_label: The input to the model consists of (orthographically transcribed) child-directed utterances accompanied by the set of objects present in the non-linguistic context.
method_label: Each object is annotated by social cues, indicating e.g., whether the caregiver is looking at or touching the object.
method_label: We show how to model the task of inferring which objects are being talked about (and which words refer to which objects) as standard grammatical inference, and describe PCFG-based unigram models and adaptor grammar-based collocation models for the task.
result_label: Exploiting social cues improves the performance of all models.
result_label: Our models learn the relative importance of each social cue jointly with word-object mappings and collocation structure, consistent with the idea that children could discover the importance of particular social information sources during word learning.

===================================
paper_id: 11567339; YEAR: 2017
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidfcbow200 - title_tfidf - title_cbow200
TITLE: SPEECH-COCO: 600k Visually Grounded Spoken Captions Aligned to MSCOCO Data Set
ABSTRACT: background_label: This paper presents an augmentation of MSCOCO dataset where speech is added to image and text.
method_label: Speech captions are generated using text-to-speech (TTS) synthesis resulting in 616,767 spoken captions (more than 600h) paired with images.
method_label: Disfluencies and speed perturbation are added to the signal in order to sound more natural.
method_label: Each speech signal (WAV) is paired with a JSON file containing exact timecode for each word/syllable/phoneme in the spoken caption.
method_label: Such a corpus could be used for Language and Vision (LaVi) tasks including speech input or output instead of text.
result_label: Investigating multimodal learning schemes for unsupervised speech pattern discovery is also possible with this corpus, as demonstrated by a preliminary study conducted on a subset of the corpus (10h, 10k spoken captions).

===================================
paper_id: 90261084; YEAR: 2019
adju relevance: Related (+1)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_cbow200
TITLE: Conversation Model Fine-Tuning for Classifying Client Utterances in Counseling Dialogues
ABSTRACT: background_label: The recent surge of text-based online counseling applications enables us to collect and analyze interactions between counselors and clients.
method_label: A dataset of those interactions can be used to learn to automatically classify the client utterances into categories that help counselors in diagnosing client status and predicting counseling outcome.
method_label: With proper anonymization, we collect counselor-client dialogues, define meaningful categories of client utterances with professional counselors, and develop a novel neural network model for classifying the client utterances.
method_label: The central idea of our model, ConvMFiT, is a pre-trained conversation model which consists of a general language model built from an out-of-domain corpus and two role-specific language models built from unlabeled in-domain dialogues.
result_label: The classification result shows that ConvMFiT outperforms state-of-the-art comparison models.
result_label: Further, the attention weights in the learned model confirm that the model finds expected linguistic patterns for each category.

===================================
paper_id: 1866991; YEAR: 2014
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Learning Grounded Meaning Representations with Autoencoders
ABSTRACT: background_label: In this paper we address the problem of grounding distributional representations of lexical meaning.
method_label: We introduce a new model which uses stacked autoencoders to learn higher-level embeddings from textual and visual input.
method_label: The two modalities are encoded as vectors of attributes and are obtained automatically from text and images, respectively.
result_label: We evaluate our model on its ability to simulate similarity judgments and concept categorization.
result_label: On both tasks, our approach outperforms baselines and related models.

===================================
paper_id: 2173169; YEAR: 2016
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Bootstrapping incremental dialogue systems: using linguistic knowledge to learn from minimal data
ABSTRACT: background_label: We present a method for inducing new dialogue systems from very small amounts of unannotated dialogue data, showing how word-level exploration using Reinforcement Learning (RL), combined with an incremental and semantic grammar - Dynamic Syntax (DS) - allows systems to discover, generate, and understand many new dialogue variants.
method_label: The method avoids the use of expensive and time-consuming dialogue act annotations, and supports more natural (incremental) dialogues than turn-based systems.
method_label: Here, language generation and dialogue management are treated as a joint decision/optimisation problem, and the MDP model for RL is constructed automatically.
method_label: With an implemented system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue.
method_label: The variants include question-answer pairs, over- and under-answering, self- and other-corrections, clarification interaction, split-utterances, and ellipsis.
result_label: This generalisation property results from the structural knowledge and constraints present within the DS grammar, and highlights some limitations of recent systems built using machine learning techniques only.

===================================
paper_id: 53218829; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: specter - abs_cbow200
TITLE: Wizard of Wikipedia: Knowledge-Powered Conversational agents
ABSTRACT: background_label: In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date.
background_label: The most popular sequence to sequence models typically"generate and hope"generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context.
background_label: Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding.
method_label: To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia.
method_label: We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses.
result_label: Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction.

===================================
paper_id: 2096410; YEAR: 2004
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Developing a Flexible Spoken Dialog System Using Simulation
ABSTRACT: objective_label: In this paper, we describe a new methodology to develop mixed-initiative spoken dialog systems, which is based on the extensive use of simulations to accelerate the development process.
method_label: With the help of simulations, a system providing information about a database of nearly 1000 restaurants in the Boston area has been developed.
method_label: The simulator can produce thousands of unique dialogs which benefit not only dialog development but also provide data to train the speech recognizer and understanding components, in preparation for real user interactions.
method_label: Also described is a strategy for creating cooperative responses to user queries, incorporating an intelligent language generation capability that produces content-dependent verbal descriptions of listed items.

===================================
paper_id: 6678765; YEAR: 2014
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Training a Multilingual Sportscaster: Using Perceptual Context to Learn Language
ABSTRACT: background_label: We present a novel framework for learning to interpret and generate language using only perceptual context as supervision.
method_label: We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language-specific prior knowledge.
method_label: Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace.
method_label: The system simultaneously establishes correspondences between individual comments and the events that they describe while building a translation model that supports both parsing and generation.
method_label: We also present a novel algorithm for learning which events are worth describing.
result_label: Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain.

===================================
paper_id: 146120855; YEAR: 2019
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: title_tfidfcbow200
TITLE: A Novel Task-Oriented Text Corpus in Silent Speech Recognition and its Natural Language Generation Construction Method
ABSTRACT: background_label: Millions of people with severe speech disorders around the world may regain their communication capabilities through techniques of silent speech recognition (SSR).
background_label: Using electroencephalography (EEG) as a biomarker for speech decoding has been popular for SSR.
background_label: However, the lack of SSR text corpus has impeded the development of this technique.
method_label: Here, we construct a novel task-oriented text corpus, which is utilized in the field of SSR.
method_label: In the process of construction, we propose a task-oriented hybrid construction method based on natural language generation algorithm.
method_label: The algorithm focuses on the strategy of data-to-text generation, and has two advantages including linguistic quality and high diversity.
method_label: These two advantages use template-based method and deep neural networks respectively.
result_label: In an SSR experiment with the generated text corpus, analysis results show that the performance of our hybrid construction method outperforms the pure method such as template-based natural language generation or neural natural language generation models.

===================================
paper_id: 61412708; YEAR: 1992
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: SWITCHBOARD: telephone speech corpus for research and development
ABSTRACT: background_label: SWITCHBOARD is a large multispeaker corpus of conversational speech and text which should be of interest to researchers in speaker authentication and large vocabulary speech recognition.
background_label: About 2500 conversations by 500 speakers from around the US were collected automatically over T1 lines at Texas Instruments.
method_label: Designed for training and testing of a variety of speech processing algorithms, especially in speaker verification, it has over an 1 h of speech from each of 50 speakers, and several minutes each from hundreds of others.
other_label: A time-aligned word for word transcription accompanies each recording.<<ETX>>

===================================
paper_id: 7335121; YEAR: 2017
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: title_tfidf
TITLE: Learning Multi-Modal Word Representation Grounded in Visual Context
ABSTRACT: background_label: Representing the semantics of words is a long-standing problem for the natural language processing community.
background_label: Most methods compute word semantics given their textual context in large corpora.
background_label: More recently, researchers attempted to integrate perceptual and visual features.
background_label: Most of these works consider the visual appearance of objects to enhance word representations but they ignore the visual environment and context in which objects appear.
method_label: We propose to unify text-based techniques with vision-based techniques by simultaneously leveraging textual and visual context to learn multimodal word embeddings.
method_label: We explore various choices for what can serve as a visual context and present an end-to-end method to integrate visual context elements in a multimodal skip-gram model.
result_label: We provide experiments and extensive analysis of the obtained results.

===================================
paper_id: 6694311; YEAR: 2017
adju relevance: Related (+1)
difference: 2; annotator4: 0; annotator3: 2
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Training an adaptive dialogue policy for interactive learning of visually grounded word meanings
ABSTRACT: background_label: We present a multi-modal dialogue system for interactive learning of perceptually grounded word meanings from a human tutor.
method_label: The system integrates an incremental, semantic parsing/generation framework - Dynamic Syntax and Type Theory with Records (DS-TTR) - with a set of visual classifiers that are learned throughout the interaction and which ground the meaning representations that it produces.
method_label: We use this system in interaction with a simulated human tutor to study the effects of different dialogue policies and capabilities on the accuracy of learned meanings, learning rates, and efforts/costs to the tutor.
result_label: We show that the overall performance of the learning agent is affected by (1) who takes initiative in the dialogues; (2) the ability to express/use their confidence level about visual attributes; and (3) the ability to process elliptical and incrementally constructed dialogue turns.
result_label: Ultimately, we train an adaptive dialogue policy which optimises the trade-off between classifier accuracy and tutoring costs.

===================================
paper_id: 6882058; YEAR: 2015
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: specter
TITLE: Comparing Attribute Classifiers for Interactive Language Grounding
ABSTRACT: background_label: AbstractWe address the problem of interactively learning perceptually grounded word meanings in a multimodal dialogue system.
objective_label: We design a semantic and visual processing system to support this and illustrate how they can be integrated.
method_label: We then focus on comparing the performance (Precision, Recall, F1, AUC) of three state-of-the-art attribute classifiers for the purpose of interactive language grounding (MLKNN, DAP, and SVMs), on the aPascal-aYahoo datasets.
method_label: In prior work, results were presented for object classification using these methods for attribute labelling, whereas we focus on their performance for attribute labelling itself.
result_label: We find that while these methods can perform well for some of the attributes (e.g.
result_label: head, ears, furry) none of these models has good performance over the whole attribute set, and none supports incremental learning.
result_label: This leads us to suggest directions for future work.

===================================
paper_id: 977486; YEAR: 2017
adju relevance: Related (+1)
difference: 2; annotator4: 0; annotator3: 2
sources: title_tfidf - specter
TITLE: Language Bootstrapping: Learning Word Meanings From Perception-Action Association
ABSTRACT: objective_label: We address the problem of bootstrapping language acquisition for an artificial system similarly to what is observed in experiments with human infants.
method_label: Our method works by associating meanings to words in manipulation tasks, as a robot interacts with objects and listens to verbal descriptions of the interactions.
method_label: The model is based on an affordance network, i.e., a mapping between robot actions, robot perceptions, and the perceived effects of these actions upon objects.
method_label: We extend the affordance model to incorporate spoken words, which allows us to ground the verbal symbols to the execution of actions and the perception of the environment.
method_label: The model takes verbal descriptions of a task as the input and uses temporal co-occurrence to create links between speech utterances and the involved objects, actions, and effects.
result_label: We show that the robot is able form useful word-to-meaning associations, even without considering grammatical structure in the learning process and in the presence of recognition errors.
method_label: These word-to-meaning associations are embedded in the robot's own understanding of its actions.
result_label: Thus, they can be directly used to instruct the robot to perform tasks and also allow to incorporate context in the speech recognition task.
result_label: We believe that the encouraging results with our approach may afford robots with a capacity to acquire language descriptors in their operation's environment as well as to shed some light as to how this challenging process develops with human infants.

===================================
paper_id: 202661057; YEAR: 2019
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Word Recognition, Competition, and Activation in a Model of Visually Grounded Speech
ABSTRACT: background_label: In this paper, we study how word-like units are represented and activated in a recurrent neural model of visually grounded speech.
method_label: The model used in our experiments is trained to project an image and its spoken description in a common representation space.
method_label: We show that a recurrent model trained on spoken sentences implicitly segments its input into word-like units and reliably maps them to their correct visual referents.
method_label: We introduce a methodology originating from linguistics to analyse the representation learned by neural networks -- the gating paradigm -- and show that the correct representation of a word is only activated if the network has access to first phoneme of the target word, suggesting that the network does not rely on a global acoustic pattern.
result_label: Furthermore, we find out that not all speech frames (MFCC vectors in our case) play an equal role in the final encoded representation of a given word, but that some frames have a crucial effect on it.
result_label: Finally, we suggest that word representation could be activated through a process of lexical competition.

===================================
paper_id: 3304729; YEAR: 2017
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidfcbow200 - title_tfidf
TITLE: Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns
ABSTRACT: background_label: Important advances have recently been made using computational semantic models to decode brain activity patterns associated with concepts; however, this work has almost exclusively focused on concrete nouns.
background_label: How well these models extend to decoding abstract nouns is largely unknown.
objective_label: We address this question by applying state-of-the-art computational models to decode functional Magnetic Resonance Imaging (fMRI) activity patterns, elicited by participants reading and imagining a diverse set of both concrete and abstract nouns.
method_label: One of the models we use is linguistic, exploiting the recent word2vec skipgram approach trained on Wikipedia.
method_label: The second is visually grounded, using deep convolutional neural networks trained on Google Images.
method_label: Dual coding theory considers concrete concepts to be encoded in the brain both linguistically and visually, and abstract concepts only linguistically.
result_label: Splitting the fMRI data according to human concreteness ratings, we indeed observe that both models significantly decode the most concrete nouns; however, accuracy is significantly greater using the text-based models for the most abstract nouns.
result_label: More generally this confirms that current computational models are sufficiently advanced to assist in investigating the representational structure of abstract concepts in the brain.

===================================
paper_id: 198312054; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: specter
TITLE: MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling
ABSTRACT: background_label: Even though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available.
background_label: To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.
background_label: At a size of $10$k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora.
method_label: The contribution of this work apart from the open-sourced dataset labelled with dialogue belief states and dialogue actions is two-fold: firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided.
result_label: The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators; secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.

===================================
paper_id: 52801069; YEAR: 2016
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Visually Grounded Meaning Representations.
ABSTRACT: background_label: In this paper we address the problem of grounding distributional representations of lexical meaning.
objective_label: We introduce a new model which uses stacked autoencoders to learn higher-level representations from textual and visual input.
method_label: The visual modality is encoded via vectors of attributes obtained automatically from images.
method_label: We create a new large-scale taxonomy of 600 visual attributes representing more than 500 concepts and 700K images.
method_label: We use this dataset to train attribute classifiers and integrate their predictions with text-based distributional models of word meaning.
result_label: We evaluate our model on its ability to simulate word similarity judgments and concept categorization.
result_label: On both tasks, our model yields a better fit to behavioral data compared to baselines and related models which either rely on a single modality or do not make use of attribute-based input.

===================================
paper_id: 12445034; YEAR: 2017
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: abs_cbow200 - abs_tfidf - specter - abs_tfidfcbow200
TITLE: Challenging Neural Dialogue Models with Natural Data: Memory Networks Fail on Incremental Phenomena
ABSTRACT: background_label: Natural, spontaneous dialogue proceeds incrementally on a word-by-word basis; and it contains many sorts of disfluency such as mid-utterance/sentence hesitations, interruptions, and self-corrections.
background_label: But training data for machine learning approaches to dialogue processing is often either cleaned-up or wholly synthetic in order to avoid such phenomena.
background_label: The question then arises of how well systems trained on such clean data generalise to real spontaneous dialogue, or indeed whether they are trainable at all on naturally occurring dialogue data.
method_label: To answer this question, we created a new corpus called bAbI+ by systematically adding natural spontaneous incremental dialogue phenomena such as restarts and self-corrections to the Facebook AI Research's bAbI dialogues dataset.
method_label: We then explore the performance of a state-of-the-art retrieval model, MemN2N, on this more natural dataset.
result_label: Results show that the semantic accuracy of the MemN2N model drops drastically; and that although it is in principle able to learn to process the constructions in bAbI+, it needs an impractical amount of training data to do so.
result_label: Finally, we go on to show that an incremental, semantic parser -- DyLan -- shows 100% semantic accuracy on both bAbI and bAbI+, highlighting the generalisation properties of linguistically informed dialogue models.

===================================
paper_id: 53110354; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator4: 1; annotator3: 0
sources: specter
TITLE: Cross-Lingual Transfer Learning for Multilingual Task Oriented Dialog
ABSTRACT: background_label: One of the first steps in the utterance interpretation pipeline of many task-oriented conversational AI systems is to identify user intents and the corresponding slots.
background_label: Since data collection for machine learning models for this task is time-consuming, it is desirable to make use of existing data in a high-resource language to train models in low-resource languages.
background_label: However, development of such models has largely been hindered by the lack of multilingual training data.
method_label: In this paper, we present a new data set of 57k annotated utterances in English (43k), Spanish (8.6k) and Thai (5k) across the domains weather, alarm, and reminder.
method_label: We use this data set to evaluate three different cross-lingual transfer methods: (1) translating the training data, (2) using cross-lingual pre-trained embeddings, and (3) a novel method of using a multilingual machine translation encoder as contextual word representations.
result_label: We find that given several hundred training examples in the the target language, the latter two methods outperform translating the training data.
result_label: Further, in very low-resource settings, multilingual contextual word representations give better results than using cross-lingual static embeddings.
result_label: We also compare the cross-lingual methods to using monolingual resources in the form of contextual ELMo representations and find that given just small amounts of target language data, this method outperforms all cross-lingual methods, which highlights the need for more sophisticated cross-lingual methods.

===================================
paper_id: 11459939; YEAR: 2008
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: User Simulation as Testing for Spoken Dialog Systems
ABSTRACT: objective_label: We propose to use user simulation for testing during the development of a sophisticated dialog system.
method_label: While the limited behaviors of the state-of-the-art user simulation may not cover important aspects in the dialog system testing, our proposed approach extends the functionality of the simulation so that it can be used at least for the early stage testing before the system reaches stable performance for evaluation involving human users.
method_label: The proposed approach includes a set of evaluation measures that can be computed automatically from the interaction logs between the user simulator and the dialog system.
method_label: We first validate these measures on human user dialogs using user satisfaction scores.
method_label: We also build a regression model to estimate the user satisfaction scores using these evaluation measures.
method_label: Then, we apply the evaluation measures on a simulated dialog corpus trained from the real user corpus.
result_label: We show that the user satisfaction scores estimated from the simulated corpus are not statistically different from the real users' satisfaction scores.

===================================
paper_id: 6848649; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator4: 1; annotator3: 0
sources: specter
TITLE: Denotation Extraction for Interactive Learning in Dialogue Systems
ABSTRACT: background_label: This paper presents a novel task using real user data obtained in human-machine conversation.
background_label: The task concerns with denotation extraction from answer hints collected interactively in a dialogue.
background_label: The task is motivated by the need for large amounts of training data for question answering dialogue system development, where the data is often expensive and hard to collect.
method_label: Being able to collect denotation interactively and directly from users, one could improve, for example, natural understanding components on-line and ease the collection of the training data.
result_label: This paper also presents introductory results of evaluation of several denotation extraction models including attention-based neural network approaches.

===================================
paper_id: 30046385; YEAR: 2017
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_cbow200 - specter
TITLE: Punny Captions: Witty Wordplay in Image Descriptions
ABSTRACT: background_label: Wit is a form of rich interaction that is often grounded in a specific situation (e.g., a comment in response to an event).
objective_label: In this work, we attempt to build computational models that can produce witty descriptions for a given image.
objective_label: Inspired by a cognitive account of humor appreciation, we employ linguistic wordplay, specifically puns, in image descriptions.
method_label: We develop two approaches which involve retrieving witty descriptions for a given image from a large corpus of sentences, or generating them via an encoder-decoder neural network architecture.
method_label: We compare our approach against meaningful baseline approaches via human studies and show substantial improvements.
result_label: We find that when a human is subject to similar constraints as the model regarding word usage and style, people vote the image descriptions generated by our model to be slightly wittier than human-written witty descriptions.
result_label: Unsurprisingly, humans are almost always wittier than the model when they are free to choose the vocabulary, style, etc.

===================================
paper_id: 2488088; YEAR: 2008
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_tfidfcbow200 - title_tfidf - abs_cbow200
TITLE: Learning to sportscast: a test of grounded language acquisition
ABSTRACT: background_label: We present a novel commentator system that learns language from sportscasts of simulated soccer games.
method_label: The system learns to parse and generate commentaries without any engineered knowledge about the English language.
method_label: Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games.
method_label: The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model.
method_label: We also present a novel algorithm, Iterative Generation Strategy Learning (IGSL), for deciding which events to comment on.
result_label: Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries.

===================================
paper_id: 13690180; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: Polite Dialogue Generation Without Parallel Data
ABSTRACT: background_label: Stylistic dialogue response generation, with valuable applications in personality-based conversational agents, is a challenging task because the response needs to be fluent, contextually-relevant, as well as paralinguistically accurate.
background_label: Moreover, parallel datasets for regular-to-stylistic pairs are usually unavailable.
objective_label: We present three weakly-supervised models that can generate diverse polite (or rude) dialogue responses without parallel data.
method_label: Our late fusion model (Fusion) merges the decoder of an encoder-attention-decoder dialogue model with a language model trained on stand-alone polite utterances.
method_label: Our label-fine-tuning (LFT) model prepends to each source sequence a politeness-score scaled label (predicted by our state-of-the-art politeness classifier) during training, and at test time is able to generate polite, neutral, and rude responses by simply scaling the label embedding by the corresponding score.
method_label: Our reinforcement learning model (Polite-RL) encourages politeness generation by assigning rewards proportional to the politeness classifier score of the sampled response.
method_label: We also present two retrieval-based polite dialogue model baselines.
result_label: Human evaluation validates that while the Fusion and the retrieval-based models achieve politeness with poorer context-relevance, the LFT and Polite-RL models can produce significantly more polite responses without sacrificing dialogue quality.

===================================
paper_id: 18711201; YEAR: 2016
adju relevance: Related (+1)
difference: 2; annotator4: 0; annotator3: 2
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Interactively Learning Visually Grounded Word Meanings from a Human Tutor
ABSTRACT: background_label: AbstractWe present a multi-modal dialogue system for interactive learning of perceptually grounded word meanings from a human tutor.
method_label: The system integrates an incremental, semantic parsing/generation framework -Dynamic Syntax and Type Theory with Records (DS-TTR) -with a set of visual classifiers that are learned throughout the interaction and which ground the meaning representations that it produces.
method_label: We use this system in interaction with a simulated human tutor to study the effect of different dialogue policies and capabilities on accuracy of learned meanings, learning rates, and efforts/costs to the tutor.
result_label: We show that the overall performance of the learning agent is affected by (1) who takes initiative in the dialogues; (2) the ability to express/use their confidence level about visual attributes; and (3) the ability to process elliptical as well as incrementally constructed dialogue turns.

===================================
paper_id: 174798289; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Visually Grounded, Situated Learning in Neural Models
ABSTRACT: background_label: We examine the benefits of visual context in training neural language models to perform next-word prediction.
background_label: A multi-modal neural architecture is introduced that outperform its equivalent trained on language alone with a 2\% decrease in perplexity, even when no visual context is available at test.
method_label: Fine-tuning the embeddings of a pre-trained state-of-the-art bidirectional language model (BERT) in the language modeling framework yields a 3.5\% improvement.
result_label: The advantage for training with visual context when testing without is robust across different languages (English, German and Spanish) and different models (GRU, LSTM, $\Delta$-RNN, as well as those that use BERT embeddings).
result_label: Thus, language models perform better when they learn like a baby, i.e, in a multi-modal environment.
result_label: This finding is compatible with the theory of situated cognition: language is inseparable from its physical context.

===================================
paper_id: 16247856; YEAR: 2010
adju relevance: Related (+1)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: Disentangling Chat
ABSTRACT: background_label: When multiple conversations occur simultaneously, a listener must decide which conversation each utterance is part of in order to interpret and respond to it appropriately.
background_label: We refer to this task as disentanglement.
method_label: We present a corpus of Internet Relay Chat dialogue in which the various conversations have been manually disentangled, and evaluate annotator reliability.
method_label: We propose a graph-based clustering model for disentanglement, using lexical, timing, and discourse-based features.
method_label: The model's predicted disentanglements are highly correlated with manual annotations.
result_label: We conclude by discussing two extensions to the model, specificity tuning and conversation start detection, both of which are promising but do not currently yield practical improvements.

===================================
paper_id: 13441906; YEAR: 2015
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_tfidf
TITLE: A Recursive Dialogue Game for Personalized Computer-Aided Pronunciation Training
ABSTRACT: background_label: Learning languages in addition to the native language is very important for all people in the globalized world today, and computer-aided pronunciation training (CAPT) is attractive since the software can be used anywhere at any time, and repeated as many times as desired.
objective_label: In this paper, we introduce the immersive interaction scenario offered by spoken dialogues to CAPT by proposing a recursive dialogue game to make CAPT personalized.
method_label: A number of tree-structured sub-dialogues are linked sequentially and recursively as the script for the game.
method_label: The system policy at each dialogue turn is to select in real-time along the dialogue the best training sentence for each specific individual learner within the dialogue script, considering the learner's learning status and the future possible dialogue paths in the script, such that the learner can have the scores for all pronunciation units considered reaching a predefined standard in a minimum number of turns.
objective_label: The purpose here is that those pronunciation units poorly produced by the specific learner can be offered with more practice opportunities in the future sentences along the dialogue, which enables the learner to improve the pronunciation without having to repeat the same training sentences many times.
method_label: This makes the learning process for each learner completely personalized.
method_label: The dialogue policy is modeled by Markov decision process (MDP) with high-dimensional continuous state space, and trained with fitted value iteration using a huge number of simulated learners.
method_label: These simulated leaners have the behavior similar to real learners, and were generated from a corpus of real learner data.
result_label: The experiments demonstrated very promising results and a real cloud-based system is also successfully implemented.

===================================
paper_id: 52897360; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator4: 1; annotator3: 0
sources: specter
TITLE: MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling
ABSTRACT: background_label: Even though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available.
background_label: To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.
background_label: At a size of $10$k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora.
method_label: The contribution of this work apart from the open-sourced dataset labelled with dialogue belief states and dialogue actions is two-fold: firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided.
result_label: The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators; secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.

===================================
paper_id: 53208150; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: abs_tfidfcbow200
TITLE: The RLLChatbot: a solution to the ConvAI challenge
ABSTRACT: background_label: Current conversational systems can follow simple commands and answer basic questions, but they have difficulty maintaining coherent and open-ended conversations about specific topics.
background_label: Competitions like the Conversational Intelligence (ConvAI) challenge are being organized to push the research development towards that goal.
objective_label: This article presents in detail the RLLChatbot that participated in the 2017 ConvAI challenge.
objective_label: The goal of this research is to better understand how current deep learning and reinforcement learning tools can be used to build a robust yet flexible open domain conversational agent.
method_label: We provide a thorough description of how a dialog system can be built and trained from mostly public-domain datasets using an ensemble model.
method_label: The first contribution of this work is a detailed description and analysis of different text generation models in addition to novel message ranking and selection methods.
method_label: Moreover, a new open-source conversational dataset is presented.
result_label: Training on this data significantly improves the Recall@k score of the ranking and selection mechanisms compared to our baseline model responsible for selecting the message returned at each interaction.

===================================
paper_id: 58439904; YEAR: 2012
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: User Simulation in the Development of Statistical Spoken Dialogue Systems
ABSTRACT: background_label: Statistical approaches to dialogue management have steadily increased inpopularity over the last decade.
background_label: Recent evaluations of such dialogue managershave shown their feasibility for sizeable domains and their advantage in terms ofincreased robustness.
background_label: Moreover, simulated users have shown to be highly beneficialin the development and testing of dialogue managers and in particular, fortraining statistical dialogue managers.
method_label: Learning the optimal policy of aPOMDP dialogue manager is typically done using the reinforcement learning(RL), but with the RL algorithms that are commonly used today, thisprocess still relies on the use of a simulated user.
method_label: Data-driven approaches touser simulation have been developed to train dialogue managers on morerealistic user behaviour.
method_label: This chapter provides an overview of user simulationtechniques and evaluation methodologies.
method_label: In particular, recent developments inagenda-based user simulation, dynamic Bayesian network-based simulations andinverse reinforcement learning-based user simulations are discussed indetail.
result_label: Finally, we will discuss ongoing work and future challenges for usersimulation.

===================================
paper_id: 195848094; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: title_tfidfcbow200 - title_cbow200
TITLE: Extracting Arguments from Korean Question and Command: An Annotated Corpus for Structured Paraphrasing
ABSTRACT: background_label: Intention identification is a core issue in dialog management.
background_label: However, due to the non-canonicality of the spoken language, it is difficult to extract the content automatically from the conversation-style utterances.
background_label: This is much more challenging for languages like Korean and Japanese since the agglutination between morphemes make it difficult for the machines to parse the sentence and understand the intention.
method_label: To suggest a guideline for this problem, and to merge the issue flexibly with the neural paraphrasing systems introduced recently, we propose a structured annotation scheme for Korean question/commands and the resulting corpus which are widely applicable to the field of argument mining.
method_label: The scheme and dataset are expected to help machines understand the intention of natural language and grasp the core meaning of conversation-style instructions.

===================================
paper_id: 602134; YEAR: 2015
adju relevance: Related (+1)
difference: 2; annotator4: 0; annotator3: 2
sources: abs_tfidf
TITLE: Incremental grounded language learning in robot-robot interactions  Examples from spatial language
ABSTRACT: background_label: This paper reports on models of the grounded co-acquisition of syntax and semantics of locative spatial language in developmental robots.
method_label: We instantiate theories from Cognitive Linguistics and Developmental Psychology and show how a learner robot can learn to produce and interpret spatial utterances in guided-learning interactions with a tutor robot.
method_label: Particular emphasis is put on the role of the tutor.
result_label: Our experiments show that the learner rapidly becomes successful in communication given the right tutoring strategy and learning operators.

===================================
paper_id: 196471152; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Knowledge-incorporating ESIM models for Response Selection in Retrieval-based Dialog Systems
ABSTRACT: background_label: Goal-oriented dialog systems, which can be trained end-to-end without manually encoding domain-specific features, show tremendous promise in the customer support use-case e.g.
background_label: flight booking, hotel reservation, technical support, student advising etc.
background_label: These dialog systems must learn to interact with external domain knowledge to achieve the desired goal e.g.
background_label: recommending courses to a student, booking a table at a restaurant etc.
method_label: This paper presents extended Enhanced Sequential Inference Model (ESIM) models: a) K-ESIM (Knowledge-ESIM), which incorporates the external domain knowledge and b) T-ESIM (Targeted-ESIM), which leverages information from similar conversations to improve the prediction accuracy.
method_label: Our proposed models and the baseline ESIM model are evaluated on the Ubuntu and Advising datasets in the Sentence Selection track of the latest Dialog System Technology Challenge (DSTC7), where the goal is to find the correct next utterance, given a partial conversation, from a set of candidates.
result_label: Our preliminary results suggest that incorporating external knowledge sources and leveraging information from similar dialogs leads to performance improvements for predicting the next utterance.

===================================
paper_id: 417137; YEAR: 2004
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200
TITLE: Semantic variation in idiolect and sociolect: Corpus linguistic evidence from literary texts
ABSTRACT: background_label: Idiolects are person-dependent similarities in language use.
background_label: They imply that texts by one author show more similarities in language use than texts between authors.
background_label: Sociolects, on the other hand, are group-dependent similarities in language use.
background_label: They imply that texts by a group of authors, for instance in terms of gender or time period, share more similarities within a group than between groups.
background_label: Although idiolects and sociolects are commonly used terms in the humanities, they have not been investigated a great deal from corpus and computational linguistic points of view.
method_label: To test several idiolect and sociolect hypotheses a factorial combination was used of time period (Modernism, Realism), gender of author (male, female) and author (Eliot, Dickens, Woolf, Joyce) totaling 16 corresponding literary texts.
result_label: In a series of corpus linguistic studies using Boolean and vector models, no conclusive evidence was found for the selected idiolect and sociolect hypotheses.
result_label: In final analyses testing the semantics within each literary text, this lack of evidence was explained by the low homogeneity within a literary text.

===================================
paper_id: 30444239; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Joint Concept Learning and Semantic Parsing from Natural Language Explanations
ABSTRACT: background_label: AbstractNatural language constitutes a predominant medium for much of human learning and pedagogy.
background_label: We consider the problem of concept learning from natural language explanations, and a small number of labeled examples of the concept.
background_label: For example, in learning the concept of a phishing email, one might say 'this is a phishing email because it asks for your bank account number'.
method_label: Solving this problem involves both learning to interpret open-ended natural language statements, as well as learning the concept itself.
method_label: We present a joint model for (1) language interpretation (semantic parsing) and (2) concept learning (classification) that does not require labeling statements with logical forms.
method_label: Instead, the model prefers discriminative interpretations of statements in context of observable features of the data as a weak signal for parsing.
result_label: On a dataset of email-related concepts, this approach yields across-theboard improvements in classification performance, with a 30% relative improvement in F1 score over competitive classification methods in the low data regime.

===================================
paper_id: 17953812; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Representations of language in a model of visually grounded speech signal
ABSTRACT: background_label: We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space.
method_label: We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaning-based linguistic knowledge from the input signal.
result_label: We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of form-related aspects of the language input tends to initially increase and then plateau or decrease.

===================================
paper_id: 14940757; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 2; annotator4: 0; annotator3: 2
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Describing objects by their attributes
ABSTRACT: objective_label: We propose to shift the goal of recognition from naming to describing.
objective_label: Doing so allows us not only to name familiar objects, but also: to report unusual aspects of a familiar object (spotty dog, not just dog); to say something about unfamiliar objects (hairy and four-legged, not just unknown); and to learn how to recognize new objects with few or no visual examples.
method_label: Rather than focusing on identity assignment, we make inferring attributes the core problem of recognition.
method_label: These attributes can be semantic (spotty) or discriminative (dogs have it but sheep do not).
method_label: Learning attributes presents a major new challenge: generalization across object categories, not just across instances within a category.
method_label: In this paper, we also introduce a novel feature selection method for learning attributes that generalize well across categories.
result_label: We support our claims by thorough evaluation that provides insights into the limitations of the standard recognition paradigm of naming and demonstrates the new abilities provided by our attribute-based framework.

===================================
paper_id: 15943168; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Multimedia Lab $@$ ACL WNUT NER Shared Task: Named Entity Recognition for Twitter Microposts using Distributed Word Representations
ABSTRACT: background_label: AbstractDue to the short and noisy nature of Twitter microposts, detecting named entities is often a cumbersome task.
background_label: As part of the ACL2015 Named Entity Recognition (NER) shared task, we present a semisupervised system that detects 10 types of named entities.
method_label: To that end, we leverage 400 million Twitter microposts to generate powerful word embeddings as input features and use a neural network to execute the classification.
method_label: To further boost the performance, we employ dropout to train the network and leaky Rectified Linear Units (ReLUs).
result_label: Our system achieved the fourth position in the final ranking, without using any kind of hand-crafted features such as lexical features or gazetteers.

===================================
paper_id: 12982947; YEAR: 2005
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Support Vector Learning for Semantic Argument Classification
ABSTRACT: background_label: The natural language processing community has recently experienced a growth of interest in domain independent shallow semantic parsingthe process of assigning a Who did What to Whom, When, Where, Why, How etc.
background_label: structure to plain text.
method_label: This process entails identifying groups of words in a sentence that represent these semantic arguments and assigning specific labels to them.
background_label: It could play a key role in NLP tasks like Information Extraction, Question Answering and Summarization.
method_label: We propose a machine learning algorithm for semantic role parsing, extending the work of Gildea and Jurafsky (2002), Surdeanu et al.
method_label: (2003) and others.
background_label: Our algorithm is based on Support Vector Machines which we show give large improvement in performance over earlier classifiers.
background_label: We show performance improvements through a number of new features designed to improve generalization to unseen data, such as automatic clustering of verbs.
background_label: We also report on various analytic studies examining which features are most important, comparing our classifier to other machine learning algorithms in the literature, and testing its generalization to new test set from different genre.
method_label: On the task of assigning semantic labels to the PropBank (Kingsbury, Palmer, & Marcus, 2002) corpus, our final system has a precision of 84% and a recall of 75%, which are the best results currently reported for this task.
method_label: Finally, we explore a completely different architecture which does not requires a deep syntactic parse.
result_label: We reformulate the task as a combined chunking and classification problem, thus allowing our algorithm to be applied to new languages or genres of text for which statistical syntactic parsers may not be available.

===================================
paper_id: 2996070; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf - specter
TITLE: Visually grounded learning of keyword prediction from untranscribed speech
ABSTRACT: background_label: During language acquisition, infants have the benefit of visual cues to ground spoken language.
background_label: Robots similarly have access to audio and visual sensors.
background_label: Recent work has shown that images and spoken captions can be mapped into a meaningful common space, allowing images to be retrieved using speech and vice versa.
objective_label: In this setting of images paired with untranscribed spoken captions, we consider whether computer vision systems can be used to obtain textual labels for the speech.
method_label: Concretely, we use an image-to-words multi-label visual classifier to tag images with soft textual labels, and then train a neural network to map from the speech to these soft targets.
method_label: We show that the resulting speech system is able to predict which words occur in an utterance---acting as a spoken bag-of-words classifier---without seeing any parallel speech and text.
other_label: We find that the model often confuses semantically related words, e.g.
result_label: "man"and"person", making it even more effective as a semantic keyword spotter.

===================================
paper_id: 929001; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Not All Dialogues are Created Equal: Instance Weighting for Neural Conversational Models
ABSTRACT: background_label: Neural conversational models require substantial amounts of dialogue data for their parameter estimation and are therefore usually learned on large corpora such as chat forums or movie subtitles.
background_label: These corpora are, however, often challenging to work with, notably due to their frequent lack of turn segmentation and the presence of multiple references external to the dialogue itself.
objective_label: This paper shows that these challenges can be mitigated by adding a weighting model into the architecture.
method_label: The weighting model, which is itself estimated from dialogue data, associates each training example to a numerical weight that reflects its intrinsic quality for dialogue modelling.
method_label: At training time, these sample weights are included into the empirical loss to be minimised.
result_label: Evaluation results on retrieval-based models trained on movie and TV subtitles demonstrate that the inclusion of such a weighting model improves the model performance on unsupervised metrics.

===================================
paper_id: 9963298; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions
ABSTRACT: background_label: The context in which language is used provides a strong signal for learning to recover its meaning.
method_label: In this paper, we show it can be used within a grounded CCG semantic parsing approach that learns a joint model of meaning and context for interpreting and executing natural language instructions, using various types of weak supervision.
method_label: The joint nature provides crucial benefits by allowing situated cues, such as the set of visible objects, to directly influence learning.
method_label: It also enables algorithms that learn while executing instructions, for example by trying to replicate human actions.
result_label: Experiments on a benchmark navigational dataset demonstrate strong performance under differing forms of supervision, including correctly executing 60% more instruction sets relative to the previous state of the art.

===================================
paper_id: 143834354; YEAR: 1987
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Learning Word Meanings From Context During Normal Reading
ABSTRACT: background_label: This study investigated incidental learning of word meanings from context during normal reading.
background_label: A total of 352 students in third, fifth, and seventh grades read either expository or narrative passages selected from grade-level textbooks, and after six days were tested on their knowledge of difficult words from the passages.
background_label: Small but reliable gains in knowledge of words from the passages read were found at all grade and ability levels.
method_label: Effects of word and text properties on learning from context were examined in some detail.
method_label: Word properties investigated included length, morphological complexity, and part of speech.
method_label: Text properties included the strength of contextual support for each word, readability as measured by standard formulas, and several measures of density of difficult words.
result_label: Among the word properties, only conceptual difficulty was significantly related to learning from context.
result_label: Among the text properties, learning from context was most strongly influenced by the proportion of unfamiliar words t...

===================================
paper_id: 18866306; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Workflow approach to design automatic tutor in e-learning environment
ABSTRACT: background_label: E-learning is becoming more and more a strategic choice of modern educational systems in the world.
background_label: Consequently the requirements of the platforms used are eminent.
objective_label: One of the requirements on which our work has focused is how to make the job of a tutor, automatic and intelligent.
method_label: Given that the role of a Tutor is reflected essentially by the appropriate decision-making to a critical situation, what the learner can pass.
result_label: Depending on the situation, the decision of the tutor guides the student to an alternative or another in the pedagogical strategy.
background_label: This tutorial is based on the flow of information returned by the system that summarizes the traceability of the learner who attended a training session.
objective_label: To achieve this goal, we started by studying the modeling approaches of information flows.
method_label: Among these approaches we chose the workflow model that meets the needs of our conception of an automatic and intelligent tutor.
method_label: The basic inputs of this workflow are the outputs of the GISMO tool that makes traceability of a learner who attends a course on Moodle.
method_label: During the workflow life cycle, the motor of the latter is based on the fundamental characteristic which is the apprenticeship.
method_label: The workflow is enriched with interactions performed between the learner and the system during the action learning advance.

===================================
paper_id: 7996125; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: The Parallel Meaning Bank: Towards a Multilingual Corpus of Translations Annotated with Compositional Meaning Representations
ABSTRACT: background_label: The Parallel Meaning Bank is a corpus of translations annotated with shared, formal meaning representations comprising over 11 million words divided over four languages (English, German, Italian, and Dutch).
method_label: Our approach is based on cross-lingual projection: automatically produced (and manually corrected) semantic annotations for English sentences are mapped onto their word-aligned translations, assuming that the translations are meaning-preserving.
method_label: The semantic annotation consists of five main steps: (i) segmentation of the text in sentences and lexical items; (ii) syntactic parsing with Combinatory Categorial Grammar; (iii) universal semantic tagging; (iv) symbolization; and (v) compositional semantic analysis based on Discourse Representation Theory.
method_label: These steps are performed using statistical models trained in a semi-supervised manner.
method_label: The employed annotation models are all language-neutral.
result_label: Our first results are promising.

===================================
paper_id: 201645370; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Neural Poetry: Learning to Generate Poems using Syllables
ABSTRACT: background_label: Motivated by the recent progresses on machine learning-based models that learn artistic styles, in this paper we focus on the problem of poem generation.
background_label: This is a challenging task in which the machine has to capture the linguistic features that strongly characterize a certain poet, as well as the semantics of the poet's production, that are influenced by his personal experiences and by his literary background.
method_label: Since poetry is constructed using syllables, that regulate the form and structure of poems, we propose a syllable-based neural language model, and we describe a poem generation mechanism that is designed around the poet style, automatically selecting the most representative generations.
method_label: The poetic work of a target author is usually not enough to successfully train modern deep neural networks, so we propose a multi-stage procedure that exploits non-poetic works of the same author, and also other publicly available huge corpora to learn syntax and grammar of the target language.
method_label: We focus on the Italian poet Dante Alighieri, widely famous for his Divine Comedy.
method_label: A quantitative and qualitative experimental analysis of the generated tercets is reported, where we included expert judges with strong background in humanistic studies.
result_label: The generated tercets are frequently considered to be real by a generic population of judges, with relative difference of 56.25\% with respect to the ones really authored by Dante, and expert judges perceived Dante's style and rhymes in the generated text.

===================================
paper_id: 62561424; YEAR: 1997
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Learning dialogue strategies within the Markov decision process framework
ABSTRACT: method_label: We introduce a stochastic model for dialogue systems based on the Markov decision process.
method_label: Within this framework we show that the problem of dialogue strategy design can be stated as an optimization problem, and solved by a variety of methods, including the reinforcement learning approach.
method_label: The advantages of this new paradigm include objective evaluation of dialogue systems and their automatic design and adaptation.
result_label: We show some preliminary results on learning a dialogue strategy for an air travel information system.

===================================
paper_id: 9049364; YEAR: 1980
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences
ABSTRACT: background_label: Several parametric representations of the acoustic signal were compared with regard to word recognition performance in a syllable-oriented continuous speech recognition system.
background_label: The vocabulary included many phonetically similar monosyllabic words, therefore the emphasis was on the ability to retain phonetically significant acoustic information in the face of syntactic and duration variations.
method_label: For each parameter set (based on a mel-frequency cepstrum, a linear frequency cepstrum, a linear prediction cepstrum, a linear prediction spectrum, or a set of reflection coefficients), word templates were generated using an efficient dynamic warping method, and test data were time registered with the templates.
result_label: A set of ten mel-frequency cepstrum coefficients computed every 6.4 ms resulted in the best performance, namely 96.5 percent and 95.0 percent recognition with each of two speakers.
result_label: The superior performance of the mel-frequency cepstrum coefficients may be attributed to the fact that they better represent the perceptually relevant aspects of the short-term speech spectrum.

===================================
paper_id: 12309059; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: title_cbow200
TITLE: Building and Annotating the Linguistically Diverse NTU-MC (NTU-Multilingual Corpus)
ABSTRACT: other_label: Abstract.
background_label: The NTU-MC compilation taps on the linguistic diversity of multilingual texts available within Singapore.
background_label: The current version of NTU-MC contains 375,000 words (15,000 sentences) in 6 languages (English, Chinese, Japanese, Korean, Indonesian and Vietnamese) from 6 language families (Indo-European, Sino-Tibetan, Japonic, Korean as a language isolate, Austronesian and Austro-Asiatic).
method_label: The NTU-MC is annotated with a layer of monolingual annotation (POS tags) and cross-lingual annotation (sentence-level alignments).
method_label: The diverse language data and cross-lingual annotations provide valuable information on linguistic diversity for traditional linguistic research as well as natural language processing tasks.
result_label: This paper describes the corpus compilation process with the evaluation of the monolingual and cross-lingual annotations of the corpus data.
other_label: The corpus is available under the Creative Commons -Attribute 3.0 Unported license (CC by).

===================================
paper_id: 9053813; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: JAIST: A two-phase machine learning approach for identifying discourse relations in newswire texts
ABSTRACT: background_label: In this paper, we present a machine learning approach for identifying shallow discourse relations in news wire text.
background_label: Our approach has 2 phases.
method_label: The arguments detection phase will identify arguments and explicit connectives by using the Conditional Random Fields (CRFs) learning algorithm with a set of features such as words, parts of speech (POS) and features extracted from the parsing tree of sentences.
method_label: The second phase, the sense classification phase, will classify arguments and explicit connectives into one of fifteen types of senses by using the SMO classifier with a simple feature set.
result_label: The performance of system was evaluated three different data sets given by the CoNLL 2015 Shared Task.
result_label: The parser of our system was ranked 4 of 16 participating systems on F-measure when evaluating on the blind data set (strict matching).

===================================
paper_id: 28834601; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Collective Contexts in Conversation: Grounding by Proxy.
ABSTRACT: background_label: Anecdotal evidence suggests that participants in conversation can sometimes act as a coalition.
background_label: This implies a level of conversational organization in which groups of individuals form a coherent unit.
objective_label: This paper investigates the implications of this phenomenon for psycholinguistic and semantic models of shared context in dialog.
background_label: We present a corpus study of multiparty dialog which shows that, in certain circumstances, people with different levels of overt involvement in a conversation, that is, one responding and one not, can nonetheless access the same shared context.
method_label: We argue that contemporary models of shared context need to be adapted to capture this situation.
method_label: To address this, we propose "grounding by proxy," in which one person can respond on behalf of another, as a simple mechanism by which shared context can accumulate for a coalition as a whole.
method_label: We explore this hypothesis experimentally by investigating how people in a task-oriented coalition respond when their shared context appears to be weakened.
result_label: The results provide evidence that, by default, coalition members act on each other's behalf, and when this fails they work to compensate.
result_label: We conclude that this points to the need for a new concept of collective grounding acts and a corresponding concept of collective contexts in psycholinguistic and semantic models of dialog.

===================================
paper_id: 3787778; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Syntactic parsing of clinical text: guideline and corpus development with handling ill-formed sentences.
ABSTRACT: objective_label: OBJECTIVE To develop, evaluate, and share: (1) syntactic parsing guidelines for clinical text, with a new approach to handling ill-formed sentences; and (2) a clinical Treebank annotated according to the guidelines.
objective_label: To document the process and findings for readers with similar interest.
method_label: METHODS Using random samples from a shared natural language processing challenge dataset, we developed a handbook of domain-customized syntactic parsing guidelines based on iterative annotation and adjudication between two institutions.
method_label: Special considerations were incorporated into the guidelines for handling ill-formed sentences, which are common in clinical text.
method_label: Intra- and inter-annotator agreement rates were used to evaluate consistency in following the guidelines.
method_label: Quantitative and qualitative properties of the annotated Treebank, as well as its use to retrain a statistical parser, were reported.
result_label: RESULTS A supplement to the Penn Treebank II guidelines was developed for annotating clinical sentences.
background_label: After three iterations of annotation and adjudication on 450 sentences, the annotators reached an F-measure agreement rate of 0.930 (while intra-annotator rate was 0.948) on a final independent set.
background_label: A total of 1100 sentences from progress notes were annotated that demonstrated domain-specific linguistic features.
background_label: A statistical parser retrained with combined general English (mainly news text) annotations and our annotations achieved an accuracy of 0.811 (higher than models trained purely with either general or clinical sentences alone).
other_label: Both the guidelines and syntactic annotations are made available at https://sourceforge.net/projects/medicaltreebank.
method_label: CONCLUSIONS We developed guidelines for parsing clinical text and annotated a corpus accordingly.
result_label: The high intra- and inter-annotator agreement rates showed decent consistency in following the guidelines.
result_label: The corpus was shown to be useful in retraining a statistical parser that achieved moderate accuracy.

===================================
paper_id: 9477273; YEAR: 2005
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: The meanings of entropy
ABSTRACT: background_label: Abstract: Entropy is a basic physical quantity that led to various, and sometimes apparently con icting interpretations.
background_label: It has been successively assimilated to di erent concepts such as disorder and information.
method_label: In this paper we're going to revisit these conceptions, and establish the three following results: Entropy measures lack of information; it also measures information.
method_label: These two conceptions are complementary.
method_label: Entropy measures freedom, and this allows a coherent interpretation of entropy formulas and of experimental facts.
method_label: To associate entropy and disorder implies de ning order as absence of freedom.
result_label: Disorder or agitation is shown to be more appropriately linked with temperature.

===================================
paper_id: 53038840; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 2; annotator4: 0; annotator3: 2
sources: abs_cbow200 - abs_tfidf - specter
TITLE: Knowledge-aware Multimodal Dialogue Systems
ABSTRACT: background_label: By offering a natural way for information seeking, multimodal dialogue systems are attracting increasing attention in several domains such as retail, travel etc.
background_label: However, most existing dialogue systems are limited to textual modality, which cannot be easily extended to capture the rich semantics in visual modality such as product images.
background_label: For example, in fashion domain, the visual appearance of clothes and matching styles play a crucial role in understanding the user's intention.
background_label: Without considering these, the dialogue agent may fail to generate desirable responses for users.
objective_label: In this paper, we present a Knowledge-aware Multimodal Dialogue (KMD) model to address the limitation of text-based dialogue systems.
background_label: It gives special consideration to the semantics and domain knowledge revealed in visual content, and is featured with three key components.
method_label: First, we build a taxonomy-based learning module to capture the fine-grained semantics in images the category and attributes of a product).
method_label: Second, we propose an end-to-end neural conversational model to generate responses based on the conversation history, visual semantics, and domain knowledge.
method_label: Lastly, to avoid inconsistent dialogues, we adopt a deep reinforcement learning method which accounts for future rewards to optimize the neural conversational model.
result_label: We perform extensive evaluation on a multi-turn task-oriented dialogue dataset in fashion domain.
result_label: Experiment results show that our method significantly outperforms state-of-the-art methods, demonstrating the efficacy of modeling visual modality and domain knowledge for dialogue systems.

===================================
paper_id: 143666444; YEAR: 1971
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Two meanings of word abstractness
ABSTRACT: background_label: Word abstractness has been defined in terms of hierarchical superordination or empirical ratings based on accessibility to the senses.
background_label: Since a high-level superordinate (a generic term) should not be accessible to the senses, the two definitions should be correlated.
background_label: Four S s constructed word hierarchies from a pool of 925 nouns.
result_label: Neither the size of a patriarch's hierarchy, nor its status as a superordinate was noticeably predictive of its abstractness rating, while its particular hierarchy membership was.
result_label: The two definitions of abstractness appear to be mostly orthogonal.
result_label: Subjects appear to rate the abstractness of a generic noun in terms of the abstractness of its exemplars.

===================================
paper_id: 51918625; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - specter
TITLE: Spoken Dialogue for Information Navigation
ABSTRACT: background_label: AbstractAiming to expand the current research paradigm for training conversational AI agents that can address real-world challenges, we take a step away from traditional slot-filling goal-oriented spoken dialogue systems (SDS) and model the dialogue in a way that allows users to be more expressive in describing their needs.
objective_label: The goal is to help users make informed decisions rather than being fed matching items.
method_label: To this end, we describe the Linked-Data SDS (LD-SDS), a system that exploits semantic knowledge bases that connect to linked data, and supports complex constraints and preferences.
result_label: We describe the required changes in language understanding and state tracking, and the need for mined features, and we report the promising results (in terms of semantic errors, effort, etc) of a preliminary evaluation after training two statistical dialogue managers in various conditions.

===================================
paper_id: 2394627; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Error simulation for training statistical dialogue systems
ABSTRACT: background_label: Human-machine dialogue is heavily influenced by speech recognition and understanding errors and it is hence desirable to train and test statistical dialogue system policies under realistic noise conditions.
objective_label: This paper presents a novel approach to error simulation based on statistical models for word-level utterance generation, ASR confusions, and confidence score generation.
method_label: While the method explicitly models the context-dependent acoustic confusability of words and allows the system specific language model and semantic decoder to be incorporated, it is computationally inexpensive and thus potentially suitable for running thousands of training simulations.
result_label: Experimental evaluation results with a POMDP-based dialogue system and the Hidden Agenda User Simulator indicate a close match between the statistical properties of real and synthetic errors.

===================================
paper_id: 53083178; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: Automatic Poetry Generation with Mutual Reinforcement Learning
ABSTRACT: background_label: AbstractPoetry is one of the most beautiful forms of human language art.
background_label: As a crucial step towards computer creativity, automatic poetry generation has drawn researchers' attention for decades.
background_label: In recent years, some neural models have made remarkable progress in this task.
background_label: However, they are all based on maximum likelihood estimation, which only learns common patterns of the corpus and results in lossevaluation mismatch.
method_label: Human experts evaluate poetry in terms of some specific criteria, instead of word-level likelihood.
method_label: To handle this problem, we directly model the criteria and use them as explicit rewards to guide gradient update by reinforcement learning, so as to motivate the model to pursue higher scores.
method_label: Besides, inspired by writing theories, we propose a novel mutual reinforcement learning schema.
method_label: We simultaneously train two learners (generators) which learn not only from the teacher (rewarder) but also from each other to further improve performance.
method_label: We experiment on Chinese poetry.
result_label: Based on a strong basic model, our method achieves better results and outperforms the current state-of-theart method.

===================================
paper_id: 58675945; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: A Persona-based Multi-turn Conversation Model in an Adversarial Learning Framework
ABSTRACT: background_label: In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq) neural network conversation model to multi-turn dialogue by modifying the state-of-the-art hredGAN architecture.
method_label: To achieve this, we introduce an additional input modality into the encoder and decoder of hredGAN to capture other attributes such as speaker identity, location, sub-topics, and other external attributes that might be available from the corpus of human-to-human interactions.
result_label: The resulting persona hredGAN ($phredGAN$) shows better performance than both the existing persona-based Seq2Seq and hredGAN models when those external attributes are available in a multi-turn dialogue corpus.
result_label: This superiority is demonstrated on TV drama series with character consistency (such as Big Bang Theory and Friends) and customer service interaction datasets such as Ubuntu dialogue corpus in terms of perplexity, BLEU, ROUGE, and Distinct n-gram scores.

===================================
paper_id: 5786016; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter - abs_tfidf - abs_cbow200
TITLE: A joint model of word segmentation and meaning acquisition through cross-situational learning.
ABSTRACT: background_label: Human infants learn meanings for spoken words in complex interactions with other people, but the exact learning mechanisms are unknown.
background_label: Among researchers, a widely studied learning mechanism is called cross-situational learning (XSL).
background_label: In XSL, word meanings are learned when learners accumulate statistical information between spoken words and co-occurring objects or events, allowing the learner to overcome referential uncertainty after having sufficient experience with individually ambiguous scenarios.
background_label: Existing models in this area have mainly assumed that the learner is capable of segmenting words from speech before grounding them to their referential meaning, while segmentation itself has been treated relatively independently of the meaning acquisition.
method_label: In this article, we argue that XSL is not just a mechanism for word-to-meaning mapping, but that it provides strong cues for proto-lexical word segmentation.
result_label: If a learner directly solves the correspondence problem between continuous speech input and the contextual referents being talked about, segmentation of the input into word-like units emerges as a by-product of the learning.
background_label: We present a theoretical model for joint acquisition of proto-lexical segments and their meanings without assuming a priori knowledge of the language.
method_label: We also investigate the behavior of the model using a computational implementation, making use of transition probability-based statistical learning.
result_label: Results from simulations show that the model is not only capable of replicating behavioral data on word learning in artificial languages, but also shows effective learning of word segments and their meanings from continuous speech.
result_label: Moreover, when augmented with a simple familiarity preference during learning, the model shows a good fit to human behavioral data in XSL tasks.
result_label: These results support the idea of simultaneous segmentation and meaning acquisition and show that comprehensive models of early word segmentation should take referential word meanings into account.
other_label: (PsycINFO Database Record

===================================
paper_id: 119425731; YEAR: 1972
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Unzerlegbare Darstellungen I
ABSTRACT: background_label: LetK be the structure got by forgetting the composition law of morphisms in a given category.
background_label: A linear representation ofK is given by a map V associating with any morphism : ae ofK a linear vector space map V(): V(a)V(e).
method_label: We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations.
other_label: This classification is related to an old paper by Yoshii [3].

===================================
paper_id: 8763802; YEAR: 2004
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Multimodal Integration of Haptics, Speech, and Affect in an Educational Environment
ABSTRACT: background_label: In this paper we investigate the introduction of haptics in a multimodal tutoring environment.
method_label: In this environment a haptic device is used to control a virtual injection needle and speech input and output is provided to interact with a virtual tutor, available as a talking head, and a virtual patient.
method_label: We survey the agent-based architecture of the system and discuss the different interaction modalities.
method_label: One of the agents, the virtual tutor monitors the actions of the student, provides feedback and is able to demonstrate.
method_label: Incorporated is a simple emotion model that the tutor tries to maintain and update by considering the students actions and its progress.
result_label: The model allows the tutor to show affective behavior to the student.

===================================
paper_id: 1801325; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: CITlab ARGUS for historical data tables Description of CITlab  s System for the ANWRESH-2014 Word Recognition Task Gundram
ABSTRACT: background_label: We describe CITlab's recognition system for the ANWRESH-2014 competition attached to the 14. International Conference on Frontiers in Handwriting Recognition, ICFHR 2014.
background_label: The task comprises word recognition from segmented historical documents.
method_label: The core components of our system are based on multi-dimensional recurrent neural networks (MDRNN) and connectionist temporal classification (CTC).
method_label: The software modules behind that as well as the basic utility technologies are essentially powered by PLANET's ARGUS framework for intelligent text recognition and image processing.

===================================
paper_id: 16752980; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Continuously Learning Neural Dialogue Management
ABSTRACT: background_label: We describe a two-step approach for dialogue management in task-oriented spoken dialogue systems.
method_label: A unified neural network framework is proposed to enable the system to first learn by supervision from a set of dialogue data and then continuously improve its behaviour via reinforcement learning, all using gradient-based algorithms on one single model.
result_label: The experiments demonstrate the supervised model's effectiveness in the corpus-based evaluation, with user simulation, and with paid human subjects.
result_label: The use of reinforcement learning further improves the model's performance in both interactive settings, especially under higher-noise conditions.

===================================
paper_id: 52290666; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Combining Deep Learning and Argumentative Reasoning for the Analysis of Social Media Textual Content Using Small Data Sets
ABSTRACT: background_label: The use of social media has become a regular habit for many and has changed the way people interact with each other.
objective_label: In this article, we focus on analyzing whether news headlines support tweets and whether reviews are deceptive by analyzing the interaction or the influence that these texts have on the others, thus exploiting contextual information.
method_label: Concretely, we define a deep learning method for relationbased argument mining to extract argumentative relations of attack and support.
method_label: We then use this method for determining whether news articles support tweets, a useful task in fact-checking settings, where determining agreement toward a statement is a useful step toward determining its truthfulness.
method_label: Furthermore, we use our method for extracting bipolar argumentation frameworks from reviews to help detect whether they are deceptive.
result_label: We show experimentally that our method performs well in both settings.
result_label: In particular, in the case of deception detection, our method contributes a novel argumentative feature that, when used in combination with other features in standard supervised classifiers, outperforms the latter even on small data sets.

===================================
paper_id: 37642332; YEAR: 2002
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Using uh and um in Spontaneous Speaking
ABSTRACT: background_label: The proposal examined here is that speakers use uh and um to announce that they are initiating what they expect to be a minor (uh), or major (um), delay in speaking.
background_label: Speakers can use these announcements in turn to implicate, for example, that they are searching for a word, are deciding what to say next, want to keep the floor, or want to cede the floor.
background_label: Evidence for the proposal comes from several large corpora of spontaneous speech.
method_label: The evidence shows that speakers monitor their speech plans for upcoming delays worthy of comment.
method_label: When they discover such a delay, they formulate where and how to suspend speaking, which item to produce (uh or um), whether to attach it as a clitic onto the previous word (as in "and-uh"), and whether to prolong it.
result_label: The argument is that uh and um are conventional English words, and speakers plan for, formulate, and produce them just as they would any word.

===================================
paper_id: 298504; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Sound-Word2Vec: Learning Word Representations Grounded in Sounds
ABSTRACT: background_label: To be able to interact better with humans, it is crucial for machines to understand sound - a primary modality of human perception.
background_label: Previous works have used sound to learn embeddings for improved generic textual similarity assessment.
background_label: In this work, we treat sound as a first-class citizen, studying downstream textual tasks which require aural grounding.
objective_label: To this end, we propose sound-word2vec - a new embedding scheme that learns specialized word embeddings grounded in sounds.
method_label: For example, we learn that two seemingly (semantically) unrelated concepts, like leaves and paper are similar due to the similar rustling sounds they make.
method_label: Our embeddings prove useful in textual tasks requiring aural reasoning like text-based sound retrieval and discovering foley sound effects (used in movies).
result_label: Moreover, our embedding space captures interesting dependencies between words and onomatopoeia and outperforms prior work on aurally-relevant word relatedness datasets such as AMEN and ASLex.

===================================
paper_id: 52824278; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Explainable PCGML via Game Design Patterns
ABSTRACT: background_label: Procedural content generation via Machine Learning (PCGML) is the umbrella term for approaches that generate content for games via machine learning.
background_label: One of the benefits of PCGML is that, unlike search or grammar-based PCG, it does not require hand authoring of initial content or rules.
background_label: Instead, PCGML relies on existing content and black box models, which can be difficult to tune or tweak without expert knowledge.
background_label: This is especially problematic when a human designer needs to understand how to manipulate their data or models to achieve desired results.
method_label: We present an approach to Explainable PCGML via Design Patterns in which the design patterns act as a vocabulary and mode of interaction between user and model.
result_label: We demonstrate that our technique outperforms non-explainable versions of our system in interactions with five expert designers, four of whom lack any machine learning expertise.

===================================
paper_id: 15266684; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Corpora Preparation and Stopword List Generation for Arabic data in Social Network
ABSTRACT: objective_label: This paper proposes a methodology to prepare corpora in Arabic language from online social network (OSN) and review site for Sentiment Analysis (SA) task.
objective_label: The paper also proposes a methodology for generating a stopword list from the prepared corpora.
objective_label: The aim of the paper is to investigate the effect of removing stopwords on the SA task.
objective_label: The problem is that the stopwords lists generated before were on Modern Standard Arabic (MSA) which is not the common language used in OSN.
method_label: We have generated a stopword list of Egyptian dialect and a corpus-based list to be used with the OSN corpora.
method_label: We compare the efficiency of text classification when using the generated lists along with previously generated lists of MSA and combining the Egyptian dialect list with the MSA list.
method_label: The text classification was performed using Na\"ive Bayes and Decision Tree classifiers and two feature selection approaches, unigrams and bigram.
result_label: The experiments show that the general lists containing the Egyptian dialects words give better performance than using lists of MSA stopwords only.

===================================
paper_id: 49658003; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf - abs_tfidfcbow200
TITLE: Design and Evaluation of a Tutor Platform for Personalized Vocabulary Learning
ABSTRACT: background_label: This paper presents our experiences in designing, implementing, and piloting an intelligent vocabulary learning tutor.
background_label: The design builds on several intelligent tutoring design concepts, including graph-based knowledge representation, learner modeling, and adaptive learning content and assessment exposition.
method_label: Specifically, we design a novel phased learner model approach to enable systematic exposure to words during vocabulary instruction.
method_label: We also built an example application over the tutor platform that uses a learning activity involving videos and an assessment activity involving word to picture/image association.
method_label: More importantly, the tutor adapts to the significant variation in children's knowledge at the beginning of kindergarten, and evolves the application at the speed of each individual learner.
method_label: A pilot study with 180 kindergarten learners allowed the tutor to collect various kinds of activity information suitable for insights and interventions both at an individual- and class-level.
result_label: The effort also demonstrates that we can do A/B testing for a variety of hypotheses at scale with such a framework.

===================================
paper_id: 16435329; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Simple Learning and Compositional Application of Perceptually Grounded Word Meanings for Incremental Reference Resolution
ABSTRACT: background_label: An elementary way of using language is to refer to objects.
background_label: Often, these objects are physically present in the shared environment and reference is done via mention of perceivable properties of the objects.
background_label: This is a type of language use that is modelled well neither by logical semantics nor by distributional semantics, the former focusing on inferential relations between expressed propositions, the latter on similarity relations between words or phrases.
method_label: We present an account of word and phrase meaning that is perceptually grounded, trainable, compositional, and dialogueplausible in that it computes meanings word-by-word.
result_label: We show that the approach performs well (with an accuracy of 65% on a 1-out-of-32 reference resolution task) on direct descriptions and target/landmark descriptions, even when trained with less than 800 training examples and automatically transcribed utterances.

===================================
paper_id: 14155276; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: A Trainable Spaced Repetition Model for Language Learning
ABSTRACT: background_label: AbstractWe present half-life regression (HLR), a novel model for spaced repetition practice with applications to second language acquisition.
method_label: HLR combines psycholinguistic theory with modern machine learning techniques, indirectly estimating the "halflife" of a word or concept in a student's long-term memory.
method_label: We use data from Duolingo -a popular online language learning application -to fit HLR models, reducing error by 45%+ compared to several baselines at predicting student recall rates.
method_label: HLR model weights also shed light on which linguistic concepts are systematically challenging for second language learners.
result_label: Finally, HLR was able to improve Duolingo daily student engagement by 12% in an operational user study.

===================================
paper_id: 60390403; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Semantic annotation of deverbal nominalizations in the Spanish corpus AnCora
ABSTRACT: objective_label: This paper presents the methodology and the linguistic criteria followed to enrich the AnCora-Es corpus with the semantic annotation of deverbal nominalizations.
method_label: The first step was to run two independent automated processes: one for the annotation of denotation types and another one for the annotation of argument structure.
method_label: Secondly, we manually checked both types of information and measured inter-annotator agreement.
result_label: The result is the Spanish AnCora-Es corpus enriched with the semantic  annotation of deverbal nominalizations.
result_label: As far as we know, this is the first Spanish corpus annotated with this type of information.

===================================
paper_id: 53113988; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Learning to Sketch with Deep Q Networks and Demonstrated Strokes
ABSTRACT: background_label: Doodling is a useful and common intelligent skill that people can learn and master.
objective_label: In this work, we propose a two-stage learning framework to teach a machine to doodle in a simulated painting environment via Stroke Demonstration and deep Q-learning (SDQ).
method_label: The developed system, Doodle-SDQ, generates a sequence of pen actions to reproduce a reference drawing and mimics the behavior of human painters.
method_label: In the first stage, it learns to draw simple strokes by imitating in supervised fashion from a set of strokeaction pairs collected from artist paintings.
method_label: In the second stage, it is challenged to draw real and more complex doodles without ground truth actions; thus, it is trained with Qlearning.
result_label: Our experiments confirm that (1) doodling can be learned without direct stepby- step action supervision and (2) pretraining with stroke demonstration via supervised learning is important to improve performance.
result_label: We further show that Doodle-SDQ is effective at producing plausible drawings in different media types, including sketch and watercolor.

===================================
paper_id: 15491802; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems
ABSTRACT: background_label: User simulation is essential for generating enough data to train a statistical spoken dialogue system.
background_label: Previous models for user simulation suffer from several drawbacks, such as the inability to take dialogue history into account, the need of rigid structure to ensure coherent user behaviour, heavy dependence on a specific domain, the inability to output several user intentions during one dialogue turn, or the requirement of a summarized action space for tractability.
objective_label: This paper introduces a data-driven user simulator based on an encoder-decoder recurrent neural network.
method_label: The model takes as input a sequence of dialogue contexts and outputs a sequence of dialogue acts corresponding to user intentions.
method_label: The dialogue contexts include information about the machine acts and the status of the user goal.
result_label: We show on the Dialogue State Tracking Challenge 2 (DSTC2) dataset that the sequence-to-sequence model outperforms an agenda-based simulator and an n-gram simulator, according to F-score.
result_label: Furthermore, we show how this model can be used on the original action space and thereby models user behaviour with finer granularity.

===================================
paper_id: 173188813; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 2; annotator4: 0; annotator3: 2
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: Multi-modal Discriminative Model for Vision-and-Language Navigation
ABSTRACT: background_label: Vision-and-Language Navigation (VLN) is a natural language grounding task where agents have to interpret natural language instructions in the context of visual scenes in a dynamic environment to achieve prescribed navigation goals.
background_label: Successful agents must have the ability to parse natural language of varying linguistic styles, ground them in potentially unfamiliar scenes, plan and react with ambiguous environmental feedback.
background_label: Generalization ability is limited by the amount of human annotated data.
background_label: In particular, \emph{paired} vision-language sequence data is expensive to collect.
method_label: We develop a discriminator that evaluates how well an instruction explains a given path in VLN task using multi-modal alignment.
result_label: Our study reveals that only a small fraction of the high-quality augmented data from \citet{Fried:2018:Speaker}, as scored by our discriminator, is useful for training VLN agents with similar performance on previously unseen environments.
result_label: We also show that a VLN agent warm-started with pre-trained components from the discriminator outperforms the benchmark success rates of 35.5 by 10\% relative measure on previously unseen environments.

===================================
paper_id: 28502573; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Visually Grounded Word Embeddings and Richer Visual Features for Improving Multimodal Neural Machine Translation
ABSTRACT: background_label: In Multimodal Neural Machine Translation (MNMT), a neural model generates a translated sentence that describes an image, given the image itself and one source descriptions in English.
background_label: This is considered as the multimodal image caption translation task.
method_label: The images are processed with Convolutional Neural Network (CNN) to extract visual features exploitable by the translation model.
background_label: So far, the CNNs used are pre-trained on object detection and localization task.
method_label: We hypothesize that richer architecture, such as dense captioning models, may be more suitable for MNMT and could lead to improved translations.
method_label: We extend this intuition to the word-embeddings, where we compute both linguistic and visual representation for our corpus vocabulary.
result_label: We combine and compare different confi

===================================
paper_id: 16572160; YEAR: 2004
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Tutor design for speech-based interfaces
ABSTRACT: background_label: Speech-based applications commonly come with web-based or printed manuals.
background_label: Alternatively, the dialogue can be designed so that users should be able to start using the application on their own.
objective_label: We studied an alternative approach, an integrated tutor.
method_label: The tutor participates in the interaction when new users learn to use a speech-based system.
method_label: It teaches the users how to operate the system and monitors user actions to be certain that the users do indeed learn.
method_label: In this paper we describe our experiences with the design and the iterative development of an integrated tutor.
method_label: Expert evaluation and two user tests were conducted with different versions of the tutor.
result_label: The results show that the tutor can effectively guide new users.
result_label: We identify the six most important lessons learned, the most important being that it is essential to spot problems by monitoring user actions, especially when novice users are tutored.

===================================
paper_id: 52282089; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Characterizing Variation in Crowd-Sourced Data for Training Neural Language Generators to Produce Stylistically Varied Outputs
ABSTRACT: background_label: One of the biggest challenges of end-to-end language generation from meaning representations in dialogue systems is making the outputs more natural and varied.
method_label: Here we take a large corpus of 50K crowd-sourced utterances in the restaurant domain and develop text analysis methods that systematically characterize types of sentences in the training data.
method_label: We then automatically label the training data to allow us to conduct two kinds of experiments with a neural generator.
method_label: First, we test the effect of training the system with different stylistic partitions and quantify the effect of smaller, but more stylistically controlled training data.
method_label: Second, we propose a method of labeling the style variants during training, and show that we can modify the style of the generated utterances using our stylistic labels.
result_label: We contrast and compare these methods that can be used with any existing large corpus, showing how they vary in terms of semantic quality and stylistic control.

===================================
paper_id: 7350883; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200
TITLE: Using Ontology-Based Context in the Portuguese-English Translation of Homographs in Textual Dialogues
ABSTRACT: objective_label: This paper introduces a novel approach to tackle the existing gap on message translations in dialogue systems.
background_label: Currently, submitted messages to the dialogue systems are considered as isolated sentences.
background_label: Thus, missing context information impede the disambiguation of homographs words in ambiguous sentences.
method_label: Our approach solves this disambiguation problem by using concepts over existing ontologies.

===================================
paper_id: 174801519; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Visually Grounded Neural Syntax Acquisition
ABSTRACT: background_label: We present the Visually Grounded Neural Syntax Learner (VG-NSL), an approach for learning syntactic representations and structures without any explicit supervision.
background_label: The model learns by looking at natural images and reading paired captions.
method_label: VG-NSL generates constituency parse trees of texts, recursively composes representations for constituents, and matches them with images.
method_label: We define concreteness of constituents by their matching scores with images, and use it to guide the parsing of text.
method_label: Experiments on the MSCOCO data set show that VG-NSL outperforms various unsupervised parsing approaches that do not use visual grounding, in terms of F1 scores against gold parse trees.
method_label: We find that VGNSL is much more stable with respect to the choice of random initialization and the amount of training data.
result_label: We also find that the concreteness acquired by VG-NSL correlates well with a similar measure defined by linguists.
result_label: Finally, we also apply VG-NSL to multiple languages in the Multi30K data set, showing that our model consistently outperforms prior unsupervised approaches.

===================================
paper_id: 13663353; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: title_tfidfcbow200
TITLE: Cantonese AphasiaBank: An annotated database of spoken discourse and co-verbal gestures by healthy and language-impaired native Cantonese speakers.
ABSTRACT: background_label: This article reports the construction of a multimodal annotated database of spoken discourse and co-verbal gestures by native healthy speakers of Cantonese and individuals with language impairment: the Cantonese AphasiaBank.
objective_label: This corpus was established as a foundation for aphasiologists and clinicians to use in designing and conducting research investigations into theoretical and clinical issues related to acquired language disorders in Chinese.
method_label: Details in terms of the purpose, structure, and levels of annotation of the database (containing part-of-speech-annotated orthographic transcripts with Romanization and the corresponding videos) are described.
method_label: The discussion presents the challenges of building a spoken database of a language that is not linguistically well-researched and that does not have a standardized written form for many of its lexical items, as well as presenting how these issues were addressed.
result_label: Most importantly, the article highlights the potential of Cantonese AphasiaBank as a powerful research tool for linguists and psycholinguists.

===================================
paper_id: 31743299; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Redundancy Localization for the Conversationalization of Unstructured Responses
ABSTRACT: background_label: AbstractConversational agents offer users a naturallanguage interface to accomplish tasks, entertain themselves, or access information.
background_label: Informational dialogue is particularly challenging in that the agent has to hold a conversation on an open topic, and to achieve a reasonable coverage it generally needs to digest and present unstructured information from textual sources.
background_label: Making responses based on such sources sound natural and fit appropriately into the conversation context is a topic of ongoing research, one of the key issues of which is preventing the agent's responses from sounding repetitive.
objective_label: Targeting this issue, we propose a new task, known as redundancy localization, which aims to pinpoint semantic overlap between text passages.
method_label: To help address it systematically, we formalize the task, prepare a public dataset with fine-grained redundancy labels, and propose a model utilizing a weak training signal defined over the results of a passage-retrieval system on web texts.
result_label: The proposed model demonstrates superior performance compared to a state-of-the-art entailment model and yields encouraging results when applied to a real-world dialogue.

===================================
paper_id: 345344; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: A Multiword Expression Data Set: Annotating Non-Compositionality and Conventionalization for English Noun Compounds
ABSTRACT: background_label: Scarcity of multiword expression data sets raises a fundamental challenge to evaluating the systems that deal with these linguistic structures.
objective_label: In this work we attempt to address this problem for a subclass of multiword expressions by producing a large data set annotated by experts and validated by common statistical measures.
method_label: We present a set of 1048 noun-noun compounds annotated as non-compositional, compositional, conventionalized and not conventionalized.
method_label: We build this data set following common trends in previous work while trying to address some of the well known issues such as small number of annotated instances, quality of the annotations, and lack of availability of true negative instances.

===================================
paper_id: 7450499; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: BUCC 2017 Shared Task: a First Attempt Toward a Deep Learning Framework for Identifying Parallel Sentences in Comparable Corpora
ABSTRACT: background_label: AbstractThis paper describes our participation in BUCC 2017 shared task: identifying parallel sentences in comparable corpora.
objective_label: Our goal is to leverage continuous vector representations and distributional semantics with a minimal use of external preprocessing and postprocessing tools.
result_label: We report experiments that were conducted after transmitting our results.

===================================
paper_id: 8056287; YEAR: 1997
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: DIA-MOLE: An Unsupervised Learning Approach to Adaptive Dialogue Models for Spoken Dialogue Systems
ABSTRACT: background_label: The DIAlogue MOdel Learning Environment supports an engineering-oriented approach towards dialogue modelling for a spoken-language interface.
objective_label: Major steps towards dialogue models is to know about the basic units that are used to construct a dialogue model and possible sequences.
method_label: In difference to many other approaches a set of dialogue acts is not predefined by any theory or manually during the engineering process, but is learned from data that are available in an avised spoken dialogue system.
method_label: The architecture is outlined and the approach is applied to the domain of appointment scheduling.
result_label: Even though based on a word correctness of about 70% predictability of dialogue acts in DIA-MOLE turns out to be comparable to human-assigned dialogue acts.

===================================
paper_id: 29101270; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Dialogue Act Recognition via CRF-Attentive Structured Network
ABSTRACT: background_label: Dialogue Act Recognition (DAR) is a challenging problem in dialogue interpretation, which aims to attach semantic labels to utterances and characterize the speaker's intention.
background_label: Currently, many existing approaches formulate the DAR problem ranging from multi-classification to structured prediction, which suffer from handcrafted feature extensions and attentive contextual structural dependencies.
objective_label: In this paper, we consider the problem of DAR from the viewpoint of extending richer Conditional Random Field (CRF) structural dependencies without abandoning end-to-end training.
method_label: We incorporate hierarchical semantic inference with memory mechanism on the utterance modeling.
method_label: We then extend structured attention network to the linear-chain conditional random field layer which takes into account both contextual utterances and corresponding dialogue acts.
result_label: The extensive experiments on two major benchmark datasets Switchboard Dialogue Act (SWDA) and Meeting Recorder Dialogue Act (MRDA) datasets show that our method achieves better performance than other state-of-the-art solutions to the problem.
result_label: It is a remarkable fact that our method is nearly close to the human annotator's performance on SWDA within 2% gap.

===================================
paper_id: 14492070; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: The Gun Violence Database: A new task and data set for NLP
ABSTRACT: background_label: AbstractWe argue that NLP researchers are especially well-positioned to contribute to the national discussion about gun violence.
background_label: Reasoning about the causes and outcomes of gun violence is typically dominated by politics and emotion, and data-driven research on the topic is stymied by a shortage of data and a lack of federal funding.
background_label: However, data abounds in the form of unstructured text from news articles across the country.
objective_label: This is an ideal application of NLP technologies, such as relation extraction, coreference resolution, and event detection.
method_label: We introduce a new and growing dataset, the Gun Violence Database, in order to facilitate the adaptation of current NLP technologies to the domain of gun violence, thus enabling better social science research on this important and under-resourced problem.

===================================
paper_id: 625213; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Data-Driven Broad-Coverage Grammars for Opinionated Natural Language Generation (ONLG)
ABSTRACT: background_label: AbstractOpinionated natural language generation (ONLG) is a new, challenging, NLG task in which we aim to automatically generate human-like, subjective, responses to opinionated articles online.
objective_label: We present a data-driven architecture for ONLG that generates subjective responses triggered by users' agendas, based on automatically acquired wide-coverage generative grammars.
method_label: We compare three types of grammatical representations that we design for ONLG.
method_label: The grammars interleave different layers of linguistic information, and are induced from a new, enriched dataset we developed.
result_label: Our evaluation shows that generation with Relational-Realizational (Tsarfaty and Sima'an, 2008) inspired grammar gets better language model scores than lexicalized grammars la Collins (2003) , and that the latter gets better humanevaluation scores.
result_label: We also show that conditioning the generation on topic models makes generated responses more relevant to the document content.

===================================
paper_id: 76660838; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - specter
TITLE: Benchmarking Natural Language Understanding Services for building Conversational Agents
ABSTRACT: background_label: We have recently seen the emergence of several publicly available Natural Language Understanding (NLU) toolkits, which map user utterances to structured, but more abstract, Dialogue Act (DA) or Intent specifications, while making this process accessible to the lay developer.
method_label: In this paper, we present the first wide coverage evaluation and comparison of some of the most popular NLU services, on a large, multi-domain (21 domains) dataset of 25K user utterances that we have collected and annotated with Intent and Entity Type specifications and which will be released as part of this submission.
result_label: The results show that on Intent classification Watson significantly outperforms the other platforms, namely, Dialogflow, LUIS and Rasa; though these also perform well.
result_label: Interestingly, on Entity Type recognition, Watson performs significantly worse due to its low Precision.
result_label: Again, Dialogflow, LUIS and Rasa perform well on this task.

===================================
paper_id: 6797800; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Agenda-Based User Simulation for Bootstrapping a POMDP Dialogue System
ABSTRACT: objective_label: This paper investigates the problem of bootstrapping a statistical dialogue manager without access to training data and proposes a new probabilistic agenda-based method for simulating user behaviour.
method_label: In experiments with a statistical POMDP dialogue system, the simulator was realistic enough to successfully test the prototype system and train a dialogue policy.
result_label: An extensive study with human subjects showed that the learned policy was highly competitive, with task completion rates above 90%.

===================================
paper_id: 36117198; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: DeepMind_Commentary
ABSTRACT: background_label: We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential.
background_label: However, we favor an approach that centers on one additional ingredient: autonomy.
objective_label: In particular, we aim toward agents that can both build and exploit their own internal models, with minimal human hand-engineering.
method_label: We believe an approach centered on autonomous learning has the greatest chance of success as we scale toward real-world complexity, tackling domains for which ready-made formal models are not available.
result_label: Here we survey several important examples of the progress that has been made toward building autonomous agents with humanlike abilities, and highlight some outstanding challenges.

===================================
paper_id: 121347508; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter - abs_cbow200 - abs_tfidfcbow200
TITLE: Learning to Collocate Neural Modules for Image Captioning
ABSTRACT: background_label: We do not speak word by word from scratch; our brain quickly structures a pattern like \textsc{sth do sth at someplace} and then fill in the detailed descriptions.
objective_label: To render existing encoder-decoder image captioners such human-like reasoning, we propose a novel framework: learning to Collocate Neural Modules (CNM), to generate the `inner pattern' connecting visual encoder and language decoder.
method_label: Unlike the widely-used neural module networks in visual Q\&A, where the language (ie, question) is fully observable, CNM for captioning is more challenging as the language is being generated and thus is partially observable.
method_label: To this end, we make the following technical contributions for CNM training: 1) compact module design --- one for function words and three for visual content words (eg, noun, adjective, and verb), 2) soft module fusion and multi-step module execution, robustifying the visual reasoning in partial observation, 3) a linguistic loss for module controller being faithful to part-of-speech collocations (eg, adjective is before noun).
result_label: Extensive experiments on the challenging MS-COCO image captioning benchmark validate the effectiveness of our CNM image captioner.
result_label: In particular, CNM achieves a new state-of-the-art 127.9 CIDEr-D on Karpathy split and a single-model 126.0 c40 on the official server.
result_label: CNM is also robust to few training samples, eg, by training only one sentence per image, CNM can halve the performance loss compared to a strong baseline.

===================================
paper_id: 49480783; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Learning Visually-Grounded Semantics from Contrastive Adversarial Samples
ABSTRACT: background_label: We study the problem of grounding distributional representations of texts on the visual domain, namely visual-semantic embeddings (VSE for short).
background_label: Begin with an insightful adversarial attack on VSE embeddings, we show the limitation of current frameworks and image-text datasets (e.g., MS-COCO) both quantitatively and qualitatively.
background_label: The large gap between the number of possible constitutions of real-world semantics and the size of parallel data, to a large extent, restricts the model to establish the link between textual semantics and visual concepts.
method_label: We alleviate this problem by augmenting the MS-COCO image captioning datasets with textual contrastive adversarial samples.
method_label: These samples are synthesized using linguistic rules and the WordNet knowledge base.
method_label: The construction procedure is both syntax- and semantics-aware.
method_label: The samples enforce the model to ground learned embeddings to concrete concepts within the image.
method_label: This simple but powerful technique brings a noticeable improvement over the baselines on a diverse set of downstream tasks, in addition to defending known-type adversarial attacks.
other_label: We release the codes at https://github.com/ExplorerFreda/VSE-C.

===================================
paper_id: 7181600; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Learning Visually Grounded Sentence Representations
ABSTRACT: background_label: We introduce a variety of models, trained on a supervised image captioning corpus to predict the image features for a given caption, to perform sentence representation grounding.
method_label: We train a grounded sentence encoder that achieves good performance on COCO caption and image retrieval and subsequently show that this encoder can successfully be transferred to various NLP tasks, with improved performance over text-only models.
result_label: Lastly, we analyze the contribution of grounding, and show that word embeddings learned by this system outperform non-grounded ones.

===================================
paper_id: 52114019; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: title_cbow200
TITLE: Semantic Role Labeling for Learner Chinese: the Importance of Syntactic Parsing and L2-L1 Parallel Data
ABSTRACT: background_label: This paper studies semantic parsing for interlanguage (L2), taking semantic role labeling (SRL) as a case task and learner Chinese as a case language.
method_label: We first manually annotate the semantic roles for a set of learner texts to derive a gold standard for automatic SRL.
method_label: Based on the new data, we then evaluate three off-the-shelf SRL systems, i.e., the PCFGLA-parser-based, neural-parser-based and neural-syntax-agnostic systems, to gauge how successful SRL for learner Chinese can be.
method_label: We find two non-obvious facts: 1) the L1-sentence-trained systems performs rather badly on the L2 data; 2) the performance drop from the L1 data to the L2 data of the two parser-based systems is much smaller, indicating the importance of syntactic parsing in SRL for interlanguages.
method_label: Finally, the paper introduces a new agreement-based model to explore the semantic coherency information in the large-scale L2-L1 parallel data.
method_label: We then show such information is very effective to enhance SRL for learner texts.
result_label: Our model achieves an F-score of 72.06, which is a 2.02 point improvement over the best baseline.

===================================
paper_id: 3262559; YEAR: 1993
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Using Speakers  Referential Intentions to Model Early Cross-Situational Word Learning
ABSTRACT: background_label: Word learning is a "chicken and egg" problem.
background_label: If a child could understand speakers' utterances, it would be easy to learn the meanings of individual words, and once a child knows what many words mean, it is easy to infer speakers' intended meanings.
background_label: To the beginning learner, however, both individual word meanings and speakers' intentions are unknown.
method_label: We describe a computational model of word learning that solves these two inference problems in parallel, rather than relying exclusively on either the inferred meanings of utterances or cross-situational word-meaning associations.
method_label: We tested our model using annotated corpus data and found that it inferred pairings between words and object concepts with higher precision than comparison models.
result_label: Moreover, as the result of making probabilistic inferences about speakers' intentions, our model explains a variety of behavioral phenomena described in the word-learning literature.
result_label: These phenomena include mutual exclusivity, one-trial learning, cross-situational learning, the role of words in object individuation, and the use of inferred intentions to disambiguate reference.

===================================
paper_id: 170486; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Automatic Word Decompounding for ASR in a Morphologically Rich Language: Application to Amharic
ABSTRACT: background_label: This paper investigates a data-driven word decompounding algorithm for use in automatic speech recognition.
background_label: An existing algorithm, called ldquoMorfessor,rdquo has been enhanced in order to address the problem of increased phonetic confusability arising from word decompounding by incorporating phonetic properties and some constraints on recognition units derived from forced alignments experiments.
method_label: Speech recognition experiments have been carried out on a broadcast news task for the Amharic language to validate the approach.
result_label: The out of vocabulary (OOV) word rates were reduced by 35% to 50% and a small reduction in word error rate (WER) has been achieved.
result_label: The algorithm is relatively language independent and requires minimal adaptation to be applied to other languages.

===================================
paper_id: 14841591; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Perceived or Not Perceived: Film character Models for Expressive NLG
ABSTRACT: other_label: Abstract.
method_label: This paper presents a method for learning models of character linguistic style from a corpus of film dialogues and tests the method in a perceptual experiment.
method_label: We apply our method in the context of SpyFeet, a prototype role playing game.
method_label: In previous work, we used the PERSONAGE engine to produce restaurant recommendations that varied according to the speaker's personality.
method_label: Here we show for the first time that: (1) our expressive generation engine can operate on content from the story structures of an RPG; (2) PERSONAGE parameter models can be learned from film dialogue; (3) PERSONAGE rule-based models for extraversion and neuroticism are be perceived as intended in a new domain (SpyFeet character utterances); and (4) that the parameter models learned from film dialogue are generally perceived as being similar to the character that the model is based on.
result_label: This is the first step of our long term goal to create off-theshelf tools to support authors in the creation of interesting dramatic characters and dialogue partners, for a broad range of types of interactive stories and role playing games.

===================================
paper_id: 48354032; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: iParaphrasing: Extracting Visually Grounded Paraphrases via an Image
ABSTRACT: background_label: A paraphrase is a restatement of the meaning of a text in other words.
background_label: Paraphrases have been studied to enhance the performance of many natural language processing tasks.
objective_label: In this paper, we propose a novel task iParaphrasing to extract visually grounded paraphrases (VGPs), which are different phrasal expressions describing the same visual concept in an image.
method_label: These extracted VGPs have the potential to improve language and image multimodal tasks such as visual question answering and image captioning.
method_label: How to model the similarity between VGPs is the key of iParaphrasing.
result_label: We apply various existing methods as well as propose a novel neural network-based method with image attention, and report the results of the first attempt toward iParaphrasing.

===================================
paper_id: 5958681; YEAR: 2012
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Generative Goal-Driven User Simulation for Dialog Management
ABSTRACT: background_label: AbstractUser simulation is frequently used to train statistical dialog managers for task-oriented domains.
background_label: At present, goal-driven simulators (those that have a persistent notion of what they wish to achieve in the dialog) require some task-specific engineering, making them impossible to evaluate intrinsically.
background_label: Instead, they have been evaluated extrinsically by means of the dialog managers they are intended to train, leading to circularity of argument.
objective_label: In this paper, we propose the first fully generative goal-driven simulator that is fully induced from data, without hand-crafting or goal annotation.
method_label: Our goals are latent, and take the form of topics in a topic model, clustering together semantically equivalent and phonetically confusable strings, implicitly modelling synonymy and speech recognition noise.
result_label: We evaluate on two standard dialog resources, the Communicator and Let's Go datasets, and demonstrate that our model has substantially better fit to held out data than competing approaches.
result_label: We also show that features derived from our model allow significantly greater improvement over a baseline at distinguishing real from randomly permuted dialogs.

===================================
paper_id: 3102038; YEAR: 2006
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Learning To Generate Naturalistic Utterances Using Reviews In Spoken Dialogue Systems
ABSTRACT: background_label: Spoken language generation for dialogue systems requires a dictionary of mappings between semantic representations of concepts the system wants to express and realizations of those concepts.
background_label: Dictionary creation is a costly process; it is currently done by hand for each dialogue domain.
method_label: We propose a novel unsupervised method for learning such mappings from user reviews in the target domain, and test it on restaurant reviews.
method_label: We test the hypothesis that user reviews that provide individual ratings for distinguished attributes of the domain entity make it possible to map review sentences to their semantic representation with high precision.
result_label: Experimental analyses show that the mappings learned cover most of the domain ontology, and provide good linguistic variation.
result_label: A subjective user evaluation shows that the consistency between the semantic representations and the learned realizations is high and that the naturalness of the realizations is higher than a hand-crafted baseline.

===================================
paper_id: 4559436; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - abs_tfidfcbow200
TITLE: Attentive Sequence-to-Sequence Learning for Diacritic Restoration of Yor\`ub\'a Language Text
ABSTRACT: background_label: Yor\`ub\'a is a widely spoken West African language with a writing system rich in tonal and orthographic diacritics.
background_label: With very few exceptions, diacritics are omitted from electronic texts, due to limited device and application support.
background_label: Diacritics provide morphological information, are crucial for lexical disambiguation, pronunciation and are vital for any Yor\`ub\'a text-to-speech (TTS), automatic speech recognition (ASR) and natural language processing (NLP) tasks.
method_label: Reframing Automatic Diacritic Restoration (ADR) as a machine translation task, we experiment with two different attentive Sequence-to-Sequence neural models to process undiacritized text.
result_label: On our evaluation dataset, this approach produces diacritization error rates of less than 5%.
result_label: We have released pre-trained models, datasets and source-code as an open-source project to advance efforts on Yor\`ub\'a language technology.

===================================
paper_id: 14543285; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200
TITLE: Geocoding for texts with fine-grain toponyms: an experiment on a geoparsed hiking descriptions corpus
ABSTRACT: background_label: Geoparsing and geocoding are two essential middleware services to facilitate final user applications such as location-aware searching or different types of location-based services.
objective_label: The objective of this work is to propose a method for establishing a processing chain to support the geoparsing and geocoding of text documents describing events strongly linked with space and with a frequent use of fine-grain toponyms.
method_label: The geoparsing part is a Natural Language Processing approach which combines the use of part of speech and syntactico-semantic combined patterns (cascade of transducers).
method_label: However, the real novelty of this work lies in the geocoding method.
method_label: The geocoding algorithm is unsupervised and takes profit of clustering techniques to provide a solution for disambiguating the toponyms found in gazetteers, and at the same time estimating the spatial footprint of those other fine-grain toponyms not found in gazetteers.
result_label: The feasibility of the proposal has been tested with a corpus of hiking descriptions in French, Spanish and Italian.

===================================
paper_id: 7849196; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Overview of the NLPCC 2015 Shared Task: Chinese Word Segmentation and POS Tagging for Micro-blog Texts
ABSTRACT: background_label: In this paper, we give an overview for the shared task at the 4th CCF Conference on Natural Language Processing \&Chinese Computing (NLPCC 2015): Chinese word segmentation and part-of-speech (POS) tagging for micro-blog texts.
background_label: Different with the popular used newswire datasets, the dataset of this shared task consists of the relatively informal micro-texts.
method_label: The shared task has two sub-tasks: (1) individual Chinese word segmentation and (2) joint Chinese word segmentation and POS Tagging.
method_label: Each subtask has three tracks to distinguish the systems with different resources.
method_label: We first introduce the dataset and task, then we characterize the different approaches of the participating systems, report the test results, and provide a overview analysis of these results.
other_label: An online system is available for open registration and evaluation at http://nlp.fudan.edu.cn/nlpcc2015.

===================================
paper_id: 3350229; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: A retrieval-based dialogue system utilizing utterance and context embeddings
ABSTRACT: background_label: Finding semantically rich and computer-understandable representations for textual dialogues, utterances and words is crucial for dialogue systems (or conversational agents), as their performance mostly depends on understanding the context of conversations.
objective_label: Recent research aims at finding distributed vector representations (embeddings) for words, such that semantically similar words are relatively close within the vector-space.
method_label: Encoding the"meaning"of text into vectors is a current trend, and text can range from words, phrases and documents to actual human-to-human conversations.
method_label: In recent research approaches, responses have been generated utilizing a decoder architecture, given the vector representation of the current conversation.
method_label: In this paper, the utilization of embeddings for answer retrieval is explored by using Locality-Sensitive Hashing Forest (LSH Forest), an Approximate Nearest Neighbor (ANN) model, to find similar conversations in a corpus and rank possible candidates.
result_label: Experimental results on the well-known Ubuntu Corpus (in English) and a customer service chat dataset (in Dutch) show that, in combination with a candidate selection method, retrieval-based approaches outperform generative ones and reveal promising future research directions towards the usability of such a system.

===================================
paper_id: 370787; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Split Utterances in Dialogue: a Corpus Study
ABSTRACT: background_label: This paper presents a preliminary English corpus study of split utterances (SUs), single utterances split between two or more dialogue turns or speakers.
background_label: It has been suggested that SUs are a key phenomenon of dialogue, which this study confirms: almost 20% of utterances were found to fit this general definition, with nearly 3% being the between-speaker case most often studied.
result_label: Other claims/assumptions in the literature about SUs' form and distribution are investigated, with preliminary results showing: splits can occur within syntactic constituents, apparently at any point in the string; it is unusual for the separate parts to be complete units in their own right; explicit repair of the antecedent does not occur very often.
result_label: The theoretical consequences of these results for claims in the literature are pointed out.
result_label: The practical implications for dialogue systems are mentioned too.

===================================
paper_id: 10117235; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Multiple Alternative Sentence Compressions and Word-Pair Antonymy for Automatic Text Summarization and Recognizing Textual Entailment
ABSTRACT: background_label: Abstract The University of Maryland participatedin three tasks organized by the Text Anal-ysis Conference 2008 (TAC 2008): (1) theupdate task of text summarization; (2) theopinion task of text summarization; and(3) recognizing textual entailment (RTE).At the heart of our summarization sys-tem is Trimmer, which generates multi-ple alternative compressed versions of thesource sentences that act as candidate sen-tences for inclusion in the summary.
method_label: Forthe rst time, we investigated the use ofautomatically generated antonym pairs forboth text summarization and recognizingtextual entailment.
result_label: The UMD summariesfor the opinion task were especially effec-tive in providing non-redundant informa-tion (rank 3 out of a total 19 submissions).More coherent summaries resulted whenusing the antonymy feature as comparedto when not using it.
result_label: On the RTE task,even when using only automatically gen-erated antonyms the system performed aswell as when using a manually compiledlist of antonyms.
other_label: 1 Introduction

===================================
paper_id: 52899089; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Automatic Data Expansion for Customer-care Spoken Language Understanding
ABSTRACT: background_label: Spoken language understanding (SLU) systems are widely used in handling of customer-care calls.A traditional SLU system consists of an acoustic model (AM) and a language model (LM) that areused to decode the utterance and a natural language understanding (NLU) model that predicts theintent.
background_label: While AM can be shared across different domains, LM and NLU models need to be trainedspecifically for every new task.
background_label: However, preparing enough data to train these models is prohibitivelyexpensive.
method_label: In this paper, we introduce an efficient method to expand the limited in-domain data.
method_label: Theprocess starts with training a preliminary NLU model based on logistic regression on the in-domaindata.
method_label: Since the features are based onn= 1,2-grams, we can detect the most informative n-gramsfor each intent class.
method_label: Using these n-grams, we find the samples in the out-of-domain corpus that1) contain the desired n-gram and/or 2) have similar intent label.
method_label: The ones which meet the firstconstraint are used to train a new LM model and the ones that meet both constraints are used to train anew NLU model.
result_label: Our results on two divergent experimental setups show that the proposed approachreduces by 30% the absolute classification error rate (CER) comparing to the preliminary modelsand it significantly outperforms the traditional data expansion algorithms such as the ones based onsemi-supervised learning, TF-IDF and embedding vectors.

===================================
paper_id: 12492067; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: A probabilistic multimodal approach for predicting listener backchannels
ABSTRACT: background_label: During face-to-face interactions, listeners use backchannel feedback such as head nods as a signal to the speaker that the communication is working and that they should continue speaking.
background_label: Predicting these backchannel opportunities is an important milestone for building engaging and natural virtual humans.
method_label: In this paper we show how sequential probabilistic models (e.g., Hidden Markov Model or Conditional Random Fields) can automatically learn from a database of human-to-human interactions to predict listener backchannels using the speaker multimodal output features (e.g., prosody, spoken words and eye gaze).
method_label: The main challenges addressed in this paper are automatic selection of the relevant features and optimal feature representation for probabilistic models.
result_label: For prediction of visual backchannel cues (i.e., head nods), our prediction model shows a statistically significant improvement over a previously published approach based on hand-crafted rules.

===================================
paper_id: 4897037; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: What Happened? Leveraging VerbNet to Predict the Effects of Actions in Procedural Text
ABSTRACT: objective_label: Our goal is to answer questions about paragraphs describing processes (e.g., photosynthesis).
background_label: Texts of this genre are challenging because the effects of actions are often implicit (unstated), requiring background knowledge and inference to reason about the changing world states.
method_label: To supply this knowledge, we leverage VerbNet to build a rulebase (called the Semantic Lexicon) of the preconditions and effects of actions, and use it along with commonsense knowledge of persistence to answer questions about change.
result_label: Our evaluation shows that our system, ProComp, significantly outperforms two strong reading comprehension (RC) baselines.
method_label: Our contributions are two-fold: the Semantic Lexicon rulebase itself, and a demonstration of how a simulation-based approach to machine reading can outperform RC methods that rely on surface cues alone.
method_label: Since this work was performed, we have developed neural systems that outperform ProComp, described elsewhere (Dalvi et al., NAACL'18).
result_label: However, the Semantic Lexicon remains a novel and potentially useful resource, and its integration with neural systems remains a currently unexplored opportunity for further improvements in machine reading about processes.

===================================
paper_id: 52176339; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf - specter
TITLE: Community Regularization of Visually-Grounded Dialog
ABSTRACT: background_label: The task of conducting visually grounded dialog involves learning goal-oriented cooperative dialog between autonomous agents who exchange information about a scene through several rounds of questions and answers in natural language.
background_label: We posit that requiring artificial agents to adhere to the rules of human language, while also requiring them to maximize information exchange through dialog is an ill-posed problem.
method_label: We observe that humans do not stray from a common language because they are social creatures who live in communities, and have to communicate with many people everyday, so it is far easier to stick to a common language even at the cost of some efficiency loss.
result_label: Using this as inspiration, we propose and evaluate a multi-agent community-based dialog framework where each agent interacts with, and learns from, multiple agents, and show that this community-enforced regularization results in more relevant and coherent dialog (as judged by human evaluators) without sacrificing task performance (as judged by quantitative metrics).

===================================
paper_id: 9626021; YEAR: 2000
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: DT Tutor: A Decision-Theoretic, Dynamic Approach for Optimal Selection of Tutorial Actions
ABSTRACT: background_label: DT Tutor uses a decision-theoretic approach to select tutorial actions for coached problem solving that are optimal given the tutor's beliefs and objectives.
method_label: It employs a model of learning to predict the possible outcomes of each action, weighs the utility of each outcome by the tutor's belief that it will occur, and selects the action with highest expected utility.
method_label: For each tutor and student action, an updated student model is added to a dynamic decision network to reflect the changing student state.
method_label: The tutor considers multiple objectives, including the student's problem-related knowledge, focus of attention, independence, and morale, as well as action relevance and dialog coherence.
result_label: Evaluation in a calculus domain shows that DT Tutor can select rational and interesting tutorial actions for real-world-sized problems in satisfactory response time.
result_label: The tutor does not yet have a suitable user interface, so it has not been evaluated with human students.

===================================
paper_id: 4323602; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Two birds with one stone: learning semantic models for text categorization and word sense disambiguation
ABSTRACT: objective_label: In this paper we present a novel approach to learning semantic models for multiple domains, which we use to categorize Wikipedia pages and to perform domain Word Sense Disambiguation (WSD).
method_label: In order to learn a semantic model for each domain we first extract relevant terms from the texts in the domain and then use these terms to initialize a random walk over the WordNet graph.
method_label: Given an input text, we check the semantic models, choose the appropriate domain for that text and use the best-matching model to perform WSD.
result_label: Our results show considerable improvements on text categorization and domain WSD tasks.

===================================
paper_id: 8291243; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Word Meanings across Languages Support Efficient Communication
ABSTRACT: background_label: Why do languages have the semantic categories they do?
background_label: Each language partitions human experience into a system of semantic categories, labeled by words or morphemes, which are used to communicate about experience.
background_label: These categories often differ widely across languages.
background_label: Thus, languages do not merely provide different labels for the same universally shared set of categoriesinstead, both the labels and the categories themselves may be to some extent language-specific.
background_label: However this cross-language variation is constrained.
background_label: Words with similar or identical meanings often appear in unrelated languages, and most logically possible meanings are unattestedsuggesting that there are universal forces constraining the cross-language diversity.
result_label: Accounting for this pattern of wide but constrained variation is a central theoretical challenge in understanding why languages have the particular forms they do.

===================================
paper_id: 67855487; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Towards Visually Grounded Sub-Word Speech Unit Discovery
ABSTRACT: objective_label: In this paper, we investigate the manner in which interpretable sub-word speech units emerge within a convolutional neural network model trained to associate raw speech waveforms with semantically related natural image scenes.
method_label: We show how diphone boundaries can be superficially extracted from the activation patterns of intermediate layers of the model, suggesting that the model may be leveraging these events for the purpose of word recognition.
result_label: We present a series of experiments investigating the information encoded by these events.

===================================
paper_id: 174799218; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: The FRENK Datasets of Socially Unacceptable Discourse in Slovene and English
ABSTRACT: background_label: In this paper we present datasets of Facebook comment threads to mainstream media posts in Slovene and English developed inside the Slovene national project FRENK which cover two topics, migrants and LGBT, and are manually annotated for different types of socially unacceptable discourse (SUD).
method_label: The main advantages of these datasets compared to the existing ones are identical sampling procedures, producing comparable data across languages and an annotation schema that takes into account six types of SUD and five targets at which SUD is directed.
method_label: We describe the sampling and annotation procedures, and analyze the annotation distributions and inter-annotator agreements.
result_label: We consider this dataset to be an important milestone in understanding and combating SUD for both languages.

===================================
paper_id: 59553632; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: ProteinNet: a standardized data set for machine learning of protein structure
ABSTRACT: background_label: Rapid progress in deep learning has spurred its application to bioinformatics problems including protein structure prediction and design.
background_label: In classic machine learning problems like computer vision, progress has been driven by standardized data sets that facilitate fair assessment of new methods and lower the barrier to entry for non-domain experts.
background_label: While data sets of protein sequence and structure exist, they lack certain components critical for machine learning, including high-quality multiple sequence alignments and insulated training / validation splits that account for deep but only weakly detectable homology across protein space.
method_label: We have created the ProteinNet series of data sets to provide a standardized mechanism for training and assessing data-driven models of protein sequence-structure relationships.
method_label: ProteinNet integrates sequence, structure, and evolutionary information in programmatically accessible file formats tailored for machine learning frameworks.
method_label: Multiple sequence alignments of all structurally characterized proteins were created using substantial high-performance computing resources.
method_label: Standardized data splits were also generated to emulate the difficulty of past CASP (Critical Assessment of protein Structure Prediction) experiments by resetting protein sequence and structure space to the historical states that preceded six prior CASPs.
method_label: Utilizing sensitive evolution-based distance metrics to segregate distantly related proteins, we have additionally created validation sets distinct from the official CASP sets that faithfully mimic their difficulty.
result_label: ProteinNet thus represents a comprehensive and accessible resource for training and assessing machine-learned models of protein structure.

===================================
paper_id: 11468390; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Induction of Word and Phrase Alignments for Automatic Document Summarization
ABSTRACT: background_label: Current research in automatic single document summarization is dominated by two effective, yet naive approaches: summarization by sentence extraction, and headline generation via bag-of-words models.
background_label: While successful in some tasks, neither of these models is able to adequately capture the large set of linguistic devices utilized by humans when they produce summaries.
background_label: One possible explanation for the widespread use of these models is that good techniques have been developed to extract appropriate training data for them from existing document/abstract and document/headline corpora.
background_label: We believe that future progress in automatic summarization will be driven both by the development of more sophisticated, linguistically informed models, as well as a more effective leveraging of document/abstract corpora.
method_label: In order to open the doors to simultaneously achieving both of these goals, we have developed techniques for automatically producing word-to-word and phrase-to-phrase alignments between documents and their human-written abstracts.
method_label: These alignments make explicit the correspondences that exist in such document/abstract pairs, and create a potentially rich data source from which complex summarization algorithms may learn.
method_label: This paper describes experiments we have carried out to analyze the ability of humans to perform such alignments, and based on these analyses, we describe experiments for creating them automatically.
method_label: Our model for the alignment task is based on an extension of the standard hidden Markov model, and learns to create alignments in a completely unsupervised fashion.
result_label: We describe our model in detail and present experimental results that show that our model is able to learn to reliably identify word- and phrase-level alignments in a corpus of<document,abstract>pairs.

===================================
paper_id: 17629956; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Predicting Speaker Head Nods and the Effects of Affective Information
ABSTRACT: background_label: During face-to-face conversation, our body is continually in motion, displaying various head, gesture, and posture movements.
background_label: Based on findings describing the communicative functions served by these nonverbal behaviors, many virtual agent systems have modeled them to make the virtual agent look more effective and believable.
background_label: One channel of nonverbal behaviors that has received less attention is head movements, despite the important functions served by them.
objective_label: The goal for this work is to build a domain-independent model of speaker's head movements that could be used to generate head movements for virtual agents.
method_label: In this paper, we present a machine learning approach for learning models of head movements by focusing on when speaker head nods should occur, and conduct evaluation studies that compare the nods generated by this work to our previous approach of using handcrafted rules .
method_label: To learn patterns of speaker head nods, we use a gesture corpus and rely on the linguistic and affective features of the utterance.
method_label: We describe the feature selection process and training process for learning hidden Markov models and compare the results of the learned models under varying conditions.
result_label: The results show that we can predict speaker head nods with high precision (.84) and recall (.89) rates, even without a deep representation of the surface text and that using affective information can help improve the prediction of the head nods (precision: .89, recall: .90).
result_label: The evaluation study shows that the nods generated by the machine learning approach are perceived to be more natural in terms of nod timing than the nods generated by the rule-based approach.

===================================
paper_id: 118988729; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: A Microphotonic Astrocomb
ABSTRACT: background_label: One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers.
background_label: It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources.
background_label: A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers.
method_label: Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz.
method_label: This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer.
result_label: As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research.

===================================
paper_id: 18694761; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_tfidfcbow200 - specter
TITLE: Incremental understanding in human-computer dialogue and experimental evidence for advantages over nonincremental methods
ABSTRACT: background_label: Current dialogue systems generally operate in a pipelined, modular fashion on one complete utterance at a time.
background_label: Converging evidence shows that human understanding operates incrementally and makes use of multiple sources of information during the parsing process, including traditionally later aspects such as pragmatics.
method_label: We describe a spoken dialogue system that understands language incrementally, gives visual feedback on possible referents during the course of the users utterance, and allows for overlapping speech and actions.
result_label: We present findings from an empirical study showing that the resulting dialogue system is faster overall than its nonincremental counterpart.
result_label: Furthermore, the incremental system is preferred to its counterpart  beyond what is accounted for by factors such as speed and accuracy.
result_label: These results are the first to indicate, from a controlled user study, that successful incremental understanding systems will improve both performance and usability.

===================================
paper_id: 19856100; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Predicting the Learner's Emotional Reaction towards the Tutor's Intervention
ABSTRACT: background_label: The tutor tries, by using feedbacks, to keep the learner's attention and to increase his motivation and then his performance.
background_label: However, the effectiveness of the tutor's feedbacks on the learner varies from one learner to another.
background_label: It depends essentially on the learner's traits and it is reflected in the learner's emotional reaction.
objective_label: Consequently, it is important to detect the learner's emotional reaction following the tutor's intervention in order to personalize the feedback type.
method_label: Our proposal consists of a methodology, based on machine learning technique, able to predict the learner's emotional reaction starting from the analysis of descriptive variables of the learner's current situation, such as: personality, motivation and tutor's feedback type.

===================================
paper_id: 549335; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text
ABSTRACT: background_label: AbstractThe CoNLL-2010 Shared Task was dedicated to the detection of uncertainty cues and their linguistic scope in natural language texts.
objective_label: The motivation behind this task was that distinguishing factual and uncertain information in texts is of essential importance in information extraction.
method_label: This paper provides a general overview of the shared task, including the annotation protocols of the training and evaluation datasets, the exact task definitions, the evaluation metrics employed and the overall results.
result_label: The paper concludes with an analysis of the prominent approaches and an overview of the systems submitted to the shared task.

===================================
paper_id: 53017405; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Discourse Embellishment Using a Deep Encoder-Decoder Network
ABSTRACT: background_label: We suggest a new NLG task in the context of the discourse generation pipeline of computational storytelling systems.
background_label: This task, textual embellishment, is defined by taking a text as input and generating a semantically equivalent output with increased lexical and syntactic complexity.
method_label: Ideally, this would allow the authors of computational storytellers to implement just lightweight NLG systems and use a domain-independent embellishment module to translate its output into more literary text.
result_label: We present promising first results on this task using LSTM Encoder-Decoder networks trained on the WikiLarge dataset.
result_label: Furthermore, we introduce"Compiled Computer Tales", a corpus of computationally generated stories, that can be used to test the capabilities of embellishment algorithms.

===================================
paper_id: 35018362; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_cbow200 - abs_tfidf - specter - abs_tfidfcbow200
TITLE: Bootstrapping incremental dialogue systems from minimal data: the generalisation power of dialogue grammars
ABSTRACT: background_label: We investigate an end-to-end method for automatically inducing task-based dialogue systems from small amounts of unannotated dialogue data.
method_label: It combines an incremental semantic grammar - Dynamic Syntax and Type Theory with Records (DS-TTR) - with Reinforcement Learning (RL), where language generation and dialogue management are a joint decision problem.
background_label: The systems thus produced are incremental: dialogues are processed word-by-word, shown previously to be essential in supporting natural, spontaneous dialogue.
method_label: We hypothesised that the rich linguistic knowledge within the grammar should enable a combinatorially large number of dialogue variations to be processed, even when trained on very few dialogues.
method_label: Our experiments show that our model can process 74% of the Facebook AI bAbI dataset even when trained on only 0.13% of the data (5 dialogues).
method_label: It can in addition process 65% of bAbI+, a corpus we created by systematically adding incremental dialogue phenomena such as restarts and self-corrections to bAbI.
method_label: We compare our model with a state-of-the-art retrieval model, MemN2N.
result_label: We find that, in terms of semantic accuracy, MemN2N shows very poor robustness to the bAbI+ transformations even when trained on the full bAbI dataset.

===================================
paper_id: 8852172; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Fassieh, a Semi-Automatic Visual Interactive Tool for Morphological, PoS-Tags, Phonetic, and Semantic Annotation of Arabic Text Corpora
ABSTRACT: background_label: This paper introduces an Arabic text annotation tool called Fassiehreg.
background_label: Via a sophisticated interactive GUI application, Fassiehreg makes it easy to build structured large standard written Arabic corpora, then allows the production of fundamental linguistic analyses; i.e., language factorizations, at high coverage and accuracy rates over such corpora.
background_label: Arabic morphological analysis, part-of-speech (PoS)-tagging, full phonetic transcription (diacritization), and lexical semantics analysis are the most significant Arabic language factorizations currently supported by Fassiehreg.
method_label: The high inherent ambiguity of these analyses is statistically resolved in Fassiehreg which also affords a multitude of auxiliary features enabling a guided, normalized, and efficient proofreading of any part of the factorized corpus.
method_label: The paper first reviews the highly inflective and derivative nature of Arabic language, our Arabic language factorization models, and the associated statistical disambiguation methodology.
result_label: Afterwards, we present Fassiehreg which is not only a text annotation tool, but is also an evaluation, demonstrative, and tutorial means of Arabic natural language processing (NLP).

===================================
paper_id: 5059949; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_cbow200
TITLE: Attention Based Natural Language Grounding by Navigating Virtual Environment
ABSTRACT: objective_label: In this work, we focus on the problem of grounding language by training an agent to follow a set of natural language instructions and navigate to a target object in an environment.
background_label: The agent receives visual information through raw pixels and a natural language instruction telling what task needs to be achieved and is trained in an end-to-end way.
method_label: We develop an attention mechanism for multi-modal fusion of visual and textual modalities that allows the agent to learn to complete the task and achieve language grounding.
result_label: Our experimental results show that our attention mechanism outperforms the existing multi-modal fusion mechanisms proposed for both 2D and 3D environments in order to solve the above-mentioned task in terms of both speed and success rate.
method_label: We show that the learnt textual representations are semantically meaningful as they follow vector arithmetic in the embedding space.
method_label: The effectiveness of our attention approach over the contemporary fusion mechanisms is also highlighted from the textual embeddings learnt by the different approaches.
result_label: We also show that our model generalizes effectively to unseen scenarios and exhibit zero-shot generalization capabilities both in 2D and 3D environments.
other_label: The code for our 2D environment as well as the models that we developed for both 2D and 3D are available at https://github.com/rl-lang-grounding/rl-lang-ground.

===================================
paper_id: 53787909; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf - specter
TITLE: Visual Entailment Task for Visually-Grounded Language Learning
ABSTRACT: background_label: We introduce a new inference task - Visual Entailment (VE) - which differs from traditional Textual Entailment (TE) tasks whereby a premise is defined by an image, rather than a natural language sentence as in TE tasks.
method_label: A novel dataset SNLI-VE (publicly available at https://github.com/necla-ml/SNLI-VE) is proposed for VE tasks based on the Stanford Natural Language Inference corpus and Flickr30k.
method_label: We introduce a differentiable architecture called the Explainable Visual Entailment model (EVE) to tackle the VE problem.
result_label: EVE and several other state-of-the-art visual question answering (VQA) based models are evaluated on the SNLI-VE dataset, facilitating grounded language understanding and providing insights on how modern VQA based models perform.

===================================
paper_id: 174797743; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter - abs_cbow200 - abs_tfidfcbow200
TITLE: Curate and Generate: A Corpus and Method for Joint Control of Semantics and Style in Neural NLG
ABSTRACT: background_label: Neural natural language generation (NNLG) from structured meaning representations has become increasingly popular in recent years.
background_label: While we have seen progress with generating syntactically correct utterances that preserve semantics, various shortcomings of NNLG systems are clear: new tasks require new training data which is not available or straightforward to acquire, and model outputs are simple and may be dull and repetitive.
objective_label: This paper addresses these two critical challenges in NNLG by: (1) scalably (and at no cost) creating training datasets of parallel meaning representations and reference texts with rich style markup by using data from freely available and naturally descriptive user reviews, and (2) systematically exploring how the style markup enables joint control of semantic and stylistic aspects of neural model output.
method_label: We present YelpNLG, a corpus of 300,000 rich, parallel meaning representations and highly stylistically varied reference texts spanning different restaurant attributes, and describe a novel methodology that can be scalably reused to generate NLG datasets for other domains.
result_label: The experiments show that the models control important aspects, including lexical choice of adjectives, output length, and sentiment, allowing the models to successfully hit multiple style targets without sacrificing semantics.

===================================
paper_id: 13564013; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200
TITLE: Ontology-based model for Arabic lexicons: An application of the Place Nouns in the Holy Quran
ABSTRACT: background_label: Ontology is an explicit specification of conceptualization.
background_label: It defines the terms with specified relationships between them and can be interpreted by both humans and computers.
background_label: In general, there are scare semantic resources for Arabic language especially in Arabic ontologies.
background_label: These semantic resources are very essential components in both Information Retrieval and Natural Language Processing applications like search engines, question answering, machine translation, etc.
background_label: In recent years, many researchers are interested in building Arabic sematic resources, which are then can be exploited by others to build Arabic sematic applications.
method_label: Recently, a proposed ontological model for Time Nouns vocabulary in the Holy Quran was introduced.
objective_label: To share towards building an integrated and unified ontology for Arabic language, in this paper, we are proposing an ontology-based model for Arabic language vocabulary associated with Place Nouns in the Holy Quran.
method_label: This ontology is represented by the Web Ontology Language (OWL), which is the standard language for the semantic web.
result_label: The ontology will be useful in the knowledge of the Islamic learning, linguistics researches, and Semantic Web applications.

===================================
paper_id: 8897969; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: SICK through the SemEval glasses. Lesson learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment
ABSTRACT: background_label: AbstractThis paper is an extended description of SemEval-2014 Task 1, the task on the evaluation of Compositional Distributional Semantics Models on full sentences.
method_label: Systems participating in the task were presented with pairs of sentences and were evaluated on their ability to predict human judgments on (1) semantic relatedness and (2) entailment.
method_label: Training and testing data were subsets of the SICK (Sentences Involving Compositional Knowledge) data set.
objective_label: SICK was developed with the aim of providing a proper benchmark to evaluate compositional semantic systems, though task participation was open to systems based on any approach.
objective_label: Taking advantage of the SemEval experience, in this paper we analyze the SICK data set, in order to evaluate the extent to which it meets its design goal and to shed light on the linguistic phenomena that are still challenging for state-of-the-art computational semantic systems.
result_label: Qualitative and quantitative error analyses show that many systems are quite sensitive to changes in the proportion of sentence pair types, and degrade in the presence of additional lexico-syntactic complexities which do not affect human judgements.
result_label: More compositional systems seem to perform better when the task proportions are changed, but the effect needs further confirmation.

===================================
paper_id: 5595621; YEAR: 2012
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Mind the Gap: Learning to Choose Gaps for Question Generation
ABSTRACT: background_label: AbstractNot all learning takes place in an educational setting: more and more self-motivated learners are turning to on-line text to learn about new topics.
objective_label: Our goal is to provide such learners with the well-known benefits of testing by automatically generating quiz questions for online text.
background_label: Prior work on question generation has focused on the grammaticality of generated questions and generating effective multiple-choice distractors for individual question targets, both key parts of this problem.
objective_label: Our work focuses on the complementary aspect of determining what part of a sentence we should be asking about in the first place; we call this "gap selection."
method_label: We address this problem by asking human judges about the quality of questions generated from a Wikipedia-based corpus, and then training a model to effectively replicate these judgments.
result_label: Our data shows that good gaps are of variable length and span all semantic roles, i.e., nouns as well as verbs, and that a majority of good questions do not focus on named entities.
result_label: Our resulting system can generate fill-in-the-blank (cloze) questions from generic source materials.

===================================
paper_id: 643470; YEAR: 1998
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: specter - abs_tfidf - abs_cbow200
TITLE: Dialogue Act Tagging with Transformation-Based Learning
ABSTRACT: background_label: For the task of recognizing dialogue acts, we are applying the Transformation-Based Learning (TBL) machine learning algorithm.
method_label: To circumvent a sparse data problem, we extract values of well-motivated features of utterances, such as speaker direction, punctuation marks, and a new feature, called dialogue act cues, which we find to be more effective than cue phrases and word n-grams in practice.
method_label: We present strategies for constructing a set of dialogue act cues automatically by minimizing the entropy of the distribution of dialogue acts in a training corpus, filtering out irrelevant dialogue act cues, and clustering semantically-related words.
method_label: In addition, to address limitations of TBL, we introduce a Monte Carlo strategy for training efficiently and a committee method for computing confidence measures.
result_label: These ideas are combined in our working implementation, which labels held-out data as accurately as any other reported system for the dialogue act tagging task.

===================================
paper_id: 12696810; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: A New Corpus and Imitation Learning Framework for Context-Dependent Semantic Parsing
ABSTRACT: background_label: Semantic parsing is the task of translating natural language utterances into a machine-interpretable meaning representation.
background_label: Most approaches to this task have been evaluated on a small number of existing corpora which assume that all utterances must be interpreted according to a database and typically ignore context.
objective_label: In this paper we present a new, publicly available corpus for context-dependent semantic parsing.
method_label: The MRL used for the annotation was designed to support a portable, interactive tourist information system.
method_label: We develop a semantic parser for this corpus by adapting the imitation learning algorithm DAgger without requiring alignment information during training.
result_label: DAgger improves upon independently trained classifiers by 9.0 and 4.8 points in F-score on the development and test sets respectively.

===================================
paper_id: 201657646; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidf
TITLE: DeepCopy: Grounded Response Generation with Hierarchical Pointer Networks
ABSTRACT: background_label: Recent advances in neural sequence-to-sequence models have led to promising results for several language generation-based tasks, including dialogue response generation, summarization, and machine translation.
background_label: However, these models are known to have several problems, especially in the context of chit-chat based dialogue systems: they tend to generate short and dull responses that are often too generic.
background_label: Furthermore, these models do not ground conversational responses on knowledge and facts, resulting in turns that are not accurate, informative and engaging for the users.
objective_label: In this paper, we propose and experiment with a series of response generation models that aim to serve in the general scenario where in addition to the dialogue context, relevant unstructured external knowledge in the form of text is also assumed to be available for models to harness.
method_label: Our proposed approach extends pointer-generator networks (See et al., 2017) by allowing the decoder to hierarchically attend and copy from external knowledge in addition to the dialogue context.
result_label: We empirically show the effectiveness of the proposed model compared to several baselines including (Ghazvininejad et al., 2018; Zhang et al., 2018) through both automatic evaluation metrics and human evaluation on CONVAI2 dataset.

===================================
paper_id: 21701127; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: A Corpus for Modeling Word Importance in Spoken Dialogue Transcripts
ABSTRACT: method_label: Motivated by a project to create a system for people who are deaf or hard-of-hearing that would use automatic speech recognition (ASR) to produce real-time text captions of spoken English during in-person meetings with hearing individuals, we have augmented a transcript of the Switchboard conversational dialogue corpus with an overlay of word-importance annotations, with a numeric score for each word, to indicate its importance to the meaning of each dialogue turn.
method_label: Further, we demonstrate the utility of this corpus by training an automatic word importance labeling model; our best performing model has an F-score of 0.60 in an ordinal 6-class word-importance classification task with an agreement (concordance correlation coefficient) of 0.839 with the human annotators (agreement score between annotators is 0.89).
result_label: Finally, we discuss our intended future applications of this resource, particularly for the task of evaluating ASR performance, i.e.
result_label: creating metrics that predict ASR-output caption text usability for DHH users better thanWord Error Rate (WER).

===================================
paper_id: 52333947; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: specter
TITLE: Towards Exploiting Background Knowledge for Building Conversation Systems
ABSTRACT: background_label: Existing dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them.
background_label: This has resulted in the development of models which treat conversation as a sequence-to-sequence generation task i.e, given a sequence of utterances generate the response sequence).
background_label: This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances).
background_label: For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic.
method_label: To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie.
result_label: We establish baseline results on this dataset (90K utterances from 9K conversations) using three different models: (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.

===================================
paper_id: 173990506; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: "President Vows to CutHair": Dataset and Analysis of Creative Text Editing for Humorous Headlines
ABSTRACT: background_label: We introduce, release, and analyze a new dataset, called Humicroedit, for research in computational humor.
background_label: Our publicly available data consists of regular English news headlines paired with versions of the same headlines that contain simple replacement edits designed to make them funny.
method_label: We carefully curated crowdsourced editors to create funny headlines and judges to score a to a total of 15,095 edited headlines, with five judges per headline.
method_label: The simple edits, usually just a single word replacement, mean we can apply straightforward analysis techniques to determine what makes our edited headlines humorous.
method_label: We show how the data support classic theories of humor, such as incongruity, superiority, and setup/punchline.
result_label: Finally, we develop baseline classifiers that can predict whether or not an edited headline is funny, which is a first step toward automatically generating humorous headlines as an approach to creating topical humor.

===================================
paper_id: 143681547; YEAR: 1996
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: IS IT BETTER TO GIVE THAN TO DONATE ? SYNTACTIC FLEXIBILITY IN LANGUAGE PRODUCTION
ABSTRACT: background_label: This article compares the predictions of two models of grammatical encoding in language production.
background_label: The basis of one model is that alternative syntactic structures compete to determine which structure is eventually used.
background_label: The second model is incremental: Utterances are gradually built up, and the structure emerges from the construction process itself.
method_label: If grammatical encoding is competitive, syntactic choices should pose difficulties; if incremental, syntactic choices should ease the creation of speech.
method_label: These predictions were tested in three experiments where speakers created utterances which sometimes required a syntactic decision.
result_label: When constructing a sentence allowed a syntactic choice, speakers generally constructed that utterance with fewer errors and more quickly.
result_label: This finding supports the notion that language production operates incrementally.

===================================
paper_id: 2057430; YEAR: 2005
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Automatic induction of language model data for a spoken dialogue system
ABSTRACT: background_label: In this paper, we address the issue of generating in-domain language model training data when little or no real user data are available.
method_label: The two-stage approach taken begins with a data induction phase whereby linguistic constructs from out-of-domain sentences are harvested and integrated with artificially constructed in-domain phrases.
method_label: After some syntactic and semantic filtering, a large corpus of synthetically assembled user utterances is induced.
method_label: In the second stage, two sampling methods are explored to filter the synthetic corpus to achieve a desired probability distribution of the semantic content, both on the sentence level and on the class level.
method_label: The first method utilizes user simulation technology, which obtains the probability model via an interplay between a probabilistic user model and the dialogue system.
method_label: The second method synthesizes novel dialogue interactions from the raw data by modelling after a small set of dialogues produced by the developers during the course of system refinement.
result_label: Evaluation is conducted on recognition performance in a restaurant information domain.
result_label: We show that a partial match to usage-appropriate semantic content distribution can be achieved via user simulations.
result_label: Furthermore, word error rate can be reduced when limited amounts of in-domain training data are augmented with synthetic data derived by our methods.

===================================
paper_id: 58981822; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: MOROCO: The Moldavian and Romanian Dialectal Corpus
ABSTRACT: background_label: In this work, we introduce the MOldavian and ROmanian Dialectal COrpus (MOROCO), which is freely available for download at https://github.com/butnaruandrei/MOROCO.
background_label: The corpus contains 33564 samples of text (with over 10 million tokens) collected from the news domain.
background_label: The samples belong to one of the following six topics: culture, finance, politics, science, sports and tech.
method_label: The data set is divided into 21719 samples for training, 5921 samples for validation and another 5924 samples for testing.
method_label: For each sample, we provide corresponding dialectal and category labels.
method_label: This allows us to perform empirical studies on several classification tasks such as (i) binary discrimination of Moldavian versus Romanian text samples, (ii) intra-dialect multi-class categorization by topic and (iii) cross-dialect multi-class categorization by topic.
method_label: We perform experiments using a shallow approach based on string kernels, as well as a novel deep approach based on character-level convolutional neural networks containing Squeeze-and-Excitation blocks.
result_label: We also present and analyze the most discriminative features of our best performing model, before and after named entity removal.

===================================
paper_id: 17859837; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Statistical User Simulation with a Hidden Agenda
ABSTRACT: background_label: Recent work in the area of probabilistic user simulation for training statistical dialogue managers has investigated a new agenda-based user model and presented preliminary experiments with a handcrafted model parameter set.
background_label: Training the model on dialogue data is an important next step, but non-trivial since the user agenda states are not observable in data and the space of possible states and state transitions is intractably large.
method_label: This paper presents a summary-space mapping which greatly reduces the number of state transitions and introduces a tree-based method for representing the space of possible agenda state sequences.
method_label: Treating the user agenda as a hidden variable, the forward/backward algorithm can then be successfully applied to iteratively estimate the model parameters on dialogue data.
other_label:  2007 Association for Computational Linguistics.

===================================
paper_id: 167217963; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: A Self-Attention Joint Model for Spoken Language Understanding in Situational Dialog Applications
ABSTRACT: background_label: Spoken language understanding (SLU) acts as a critical component in goal-oriented dialog systems.
background_label: It typically involves identifying the speakers intent and extracting semantic slots from user utterances, which are known as intent detection (ID) and slot filling (SF).
background_label: SLU problem has been intensively investigated in recent years.
method_label: However, these methods just constrain SF results grammatically, solve ID and SF independently, or do not fully utilize the mutual impact of the two tasks.
method_label: This paper proposes a multi-head self-attention joint model with a conditional random field (CRF) layer and a prior mask.
result_label: The experiments show the effectiveness of our model, as compared with state-of-the-art models.
result_label: Meanwhile, online education in China has made great progress in the last few years.
result_label: But there are few intelligent educational dialog applications for students to learn foreign languages.
result_label: Hence, we design an intelligent dialog robot equipped with different scenario settings to help students learn communication skills.

===================================
paper_id: 85532091; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Learning semantic sentence representations from visually grounded language without lexical knowledge
ABSTRACT: background_label: Current approaches to learning semantic representations of sentences often use prior word-level knowledge.
objective_label: The current study aims to leverage visual information in order to capture sentence level semantics without the need for word embeddings.
method_label: We use a multimodal sentence encoder trained on a corpus of images with matching text captions to produce visually grounded sentence embeddings.
method_label: Deep Neural Networks are trained to map the two modalities to a common embedding space such that for an image the corresponding caption can be retrieved and vice versa.
method_label: We show that our model achieves results comparable to the current state-of-the-art on two popular image-caption retrieval benchmark data sets: MSCOCO and Flickr8k.
result_label: We evaluate the semantic content of the resulting sentence embeddings using the data from the Semantic Textual Similarity benchmark task and show that the multimodal embeddings correlate well with human semantic similarity judgements.
result_label: The system achieves state-of-the-art results on several of these benchmarks, which shows that a system trained solely on multimodal data, without assuming any word representations, is able to capture sentence level semantics.
result_label: Importantly, this result shows that we do not need prior knowledge of lexical level semantics in order to model sentence level semantics.
result_label: These findings demonstrate the importance of visual information in semantics.

===================================
paper_id: 14099256; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Evaluating word embeddings and a revised corpus for part-of-speech tagging in Portuguese
ABSTRACT: background_label: Part-of-speech tagging is an important preprocessing step in many natural language processing applications.
background_label: Despite much work already carried out in this field, there is still room for improvement, especially in Portuguese.
background_label: We experiment here with an architecture based on neural networks and word embeddings, and that has achieved promising results in English.
method_label: We tested our classifier in different corpora: a new revision of the Mac-Morpho corpus, in which we merged some tags and performed corrections and two previous versions of it.
method_label: We evaluate the impact of using different types of word embeddings and explicit features as input.
result_label: We compare our taggers performance with other systems and achieve state-of-the-art results in the new corpus.
result_label: We show how different methods for generating word embeddings and additional features differ in accuracy.
result_label: The work reported here contributes with a new revision of the Mac-Morpho corpus and a state-of-the-art new tagger available for use out-of-the-box.

===================================
paper_id: 19633312; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Music Playlist Continuation by Learning from Hand-Curated Examples and Song Features: Alleviating the Cold-Start Problem for Rare and Out-of-Set Songs
ABSTRACT: background_label: Automated music playlist generation is a specific form of music recommendation.
background_label: Generally stated, the user receives a set of song suggestions defining a coherent listening session.
objective_label: We hypothesize that the best way to convey such playlist coherence to new recommendations is by learning it from actual curated examples, in contrast to imposing ad hoc constraints.
method_label: Collaborative filtering methods can be used to capture underlying patterns in hand-curated playlists.
method_label: However, the scarcity of thoroughly curated playlists and the bias towards popular songs result in the vast majority of songs occurring in very few playlists and thus being poorly recommended.
method_label: To overcome this issue, we propose an alternative model based on a song-to-playlist classifier, which learns the underlying structure from actual playlists while leveraging song features derived from audio, social tags and independent listening logs.
result_label: Experiments on two datasets of hand-curated playlists show competitive performance compared to collaborative filtering when sufficient training data is available and more robust performance when recommending rare and out-of-set songs.
result_label: For example, both approaches achieve a recall@100 of roughly 35% for songs occurring in 5 or more training playists, whereas the proposed model achieves a recall@100 of roughly 15% for songs occurring in 4 or less training playlists, compared to the 3% achieved by collaborative filtering.

===================================
paper_id: 59843099; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidfcbow200 - title_tfidf
TITLE: Models of Visually Grounded Speech Signal Pay Attention To Nouns: a Bilingual Experiment on English and Japanese
ABSTRACT: background_label: We investigate the behaviour of attention in neural models of visually grounded speech trained on two languages: English and Japanese.
background_label: Experimental results show that attention focuses on nouns and this behaviour holds true for two very typologically different languages.
method_label: We also draw parallels between artificial neural attention and human attention and show that neural attention focuses on word endings as it has been theorised for human attention.
method_label: Finally, we investigate how two visually grounded monolingual models can be used to perform cross-lingual speech-to-speech retrieval.
result_label: For both languages, the enriched bilingual (speech-image) corpora with part-of-speech tags and forced alignments are distributed to the community for reproducible research.

===================================
paper_id: 60706198; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: A corpus driven study of the potential for vocabulary learning through watching movies
ABSTRACT: background_label: In this corpus driven study, the scripts of 143 movies consisting of 1,267,236 running words were analyzed using the RANGE program (Heatley et al.
background_label: 2002) to determine the number of encounters with low frequency words.
method_label: Low frequency words were operationalized as items from Nations (2004) 4th to 14th 1,000-word BNC lists.
result_label: The results showed that in a single movie, few words were encountered 10 or more times indicating that only a small number of words may be learned through watching one movie.
result_label: However, as the number of movies analyzed increased, the number of words encountered 10 or more times increased.
result_label: Twenty-three percent of the word families from Nations (2004) 4th 1,000-word list were encountered 10 or more times in a set of 70 movies.
result_label: This indicates that if learners watch movies regularly over a long period of time, there is the potential for significant incidental learning to occur

===================================
paper_id: 7467552; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Learning to Freestyle: Hip Hop Challenge-Response Induction via Transduction Rule Segmentation
ABSTRACT: background_label: AbstractWe present a novel model, Freestyle, that learns to improvise rhyming and fluent responses upon being challenged with a line of hip hop lyrics, by combining both bottomup token based rule induction and top-down rule segmentation strategies to learn a stochastic transduction grammar that simultaneously learns both phrasing and rhyming associations.
method_label: In this attack on the woefully under-explored natural language genre of music lyrics, we exploit a strictly unsupervised transduction grammar induction approach.
method_label: Our task is particularly ambitious in that no use of any a priori linguistic or phonetic information is allowed, even though the domain of hip hop lyrics is particularly noisy and unstructured.
method_label: We evaluate the performance of the learned model against a model learned only using the more conventional bottom-up token based rule induction, and demonstrate the superiority of our combined token based and rule segmentation induction method toward generating higher quality improvised responses, measured on fluency and rhyming criteria as judged by human evaluators.
method_label: To highlight some of the inherent challenges in adapting other algorithms to this novel task, we also compare the quality of the responses generated by our model to those generated by an out-ofthe-box phrase based SMT system.
method_label: We tackle the challenge of selecting appropriate training data for our task via a dedicated rhyme scheme detection module, which is also acquired via unsupervised learning and report improved quality of the generated responses.
result_label: Finally, we report results with Maghrebi French hip hop lyrics indicating that our model performs surprisingly well with no special adaptation to other languages.

===================================
paper_id: 196182613; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Event Knowledge in Sentence Processing: A New Dataset for the Evaluation of Argument Typicality
ABSTRACT: background_label: In the NLP literature, the thematic fit estimation task is defined as the task in which a system has to predict how likely a candidate argument (e.g.
background_label: cop) is to fit a given a verb-specific role (e.g.
background_label: the agent of to arrest) (Santus et al., 2017).
background_label: Because of the scarcity of benchmark datasets, thematic fit models are currently evaluated by measuring the correlation between their output and human ratings for isolated verb-filler pairs (Sayeed et al., 2016).
background_label: However, such evaluation does not account for the dynamic nature of argument expectations: there is robust psycholinguistic evidence that human update their predictions on upcoming arguments during sentence processing, depending on the way other verb arguments are filled (Bicknell et al., 2010; Matsuki et al., 2011).
method_label: Consider, for example, how the expectation for the patient of to check would change if we use journalist or mechanic as agents.
objective_label: In this paper we introduce DTFit (Dynamic Thematic Fit), a dataset of human ratings for verb-role fillers in a given event context, with the aim of providing a rigorous benchmark for context-sensitive argument typicality modeling.
result_label: The dataset accounts for the plausibility of patient, instrument and location roles, given the agent and the predicate.

===================================
paper_id: 15322866; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Human-robot interaction for learning and adaptation of object movements
ABSTRACT: background_label: In this paper we present a new robot control and learning framework.
background_label: By integrating previously presented as well as new methods, the robot is able to learn an invariant and generic movement representation from a human tutor.
objective_label: We argue that in order to apply such generic representations to new situations and thus create a flexible system, the use of interaction is beneficial.
method_label: The interaction is based on a kinematically controlled model of a human tutor, which is used as a model-based filter and also for recognizing postures that influence the interaction.
method_label: In addition, a new movement segmentation scheme is presented that is based on correlating movements by the tutor's hand with the salient objects in the scene.
method_label: The focus of this paper is on the interactive learning aspects of the system and particular emphasis is given to an experiment in which the humanoid robot ASIMO learns from a human tutor.
method_label: The system includes extensive generalization capabilities that result from an online adaption of the robot's body schema and the exploitation of inter-trial variance from multiple demonstrations.
method_label: This enables the robot to reproduce the movement in new situations.
result_label: For example, a stacking task that the tutor performed one-handed can be executed bi-manually by the robot.

===================================
paper_id: 742781; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter - abs_tfidfcbow200
TITLE: Identifying Subjective and Figurative Language in Online Dialogue
ABSTRACT: background_label: More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles.
background_label: In contrast to traditional, monologic resources such as news, highly social dialogue is very frequent in social media.
method_label: We aim to automatically identify sarcastic and nasty utterances in unannotated online dialogue, extending a bootstrapping method previously applied to the classification of monologic subjective sentences in Riloff and Weibe 2003.
method_label: We have adapted the method to fit the sarcastic and nasty dialogic domain.
result_label: Our method is as follows: 1) Explore methods for identifying sarcastic and nasty cue words and phrases in dialogues; 2) Use the learned cues to train a sarcastic (nasty) Cue-Based Classifier; 3) Learn general syntactic extraction patterns from the sarcastic (nasty) utterances and define fine-tuned sarcastic patterns to create a Pattern-Based Classifier; 4) Combine both Cue-Based and fine-tuned Pattern-Based Classifiers to maximize precision at the expense of recall and test on unannotated utterances.

===================================
paper_id: 3426453; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Multimodal Named Entity Recognition for Short Social Media Posts
ABSTRACT: background_label: We introduce a new task called Multimodal Named Entity Recognition (MNER) for noisy user-generated data such as tweets or Snapchat captions, which comprise short text with accompanying images.
background_label: These social media posts often come in inconsistent or incomplete syntax and lexical notations with very limited surrounding textual contexts, bringing significant challenges for NER.
method_label: To this end, we create a new dataset for MNER called SnapCaptions (Snapchat image-caption pairs submitted to public and crowd-sourced stories with fully annotated named entities).
method_label: We then build upon the state-of-the-art Bi-LSTM word/character based NER models with 1) a deep image network which incorporates relevant visual context to augment textual information, and 2) a generic modality-attention module which learns to attenuate irrelevant modalities while amplifying the most informative ones to extract contexts from, adaptive to each sample and token.
result_label: The proposed MNER model with modality attention significantly outperforms the state-of-the-art text-only NER models by successfully leveraging provided visual contexts, opening up potential applications of MNER on myriads of social media platforms.

===================================
paper_id: 3033303; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: MojiTalk: Generating Emotional Responses at Scale
ABSTRACT: background_label: Generating emotional language is a key step towards building empathetic natural language processing agents.
background_label: However, a major challenge for this line of research is the lack of large-scale labeled training data, and previous studies are limited to only small sets of human annotated sentiment labels.
background_label: Additionally, explicitly controlling the emotion and sentiment of generated text is also difficult.
objective_label: In this paper, we take a more radical approach: we exploit the idea of leveraging Twitter data that are naturally labeled with emojis.
method_label: More specifically, we collect a large corpus of Twitter conversations that include emojis in the response, and assume the emojis convey the underlying emotions of the sentence.
method_label: We then introduce a reinforced conditional variational encoder approach to train a deep generative model on these conversations, which allows us to use emojis to control the emotion of the generated text.
result_label: Experimentally, we show in our quantitative and qualitative analyses that the proposed models can successfully generate high-quality abstractive conversation responses in accordance with designated emotions.

===================================
paper_id: 17215201; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidf
TITLE: Perception of artificial agents and utterance friendliness in dialogue
ABSTRACT: objective_label: The present contribution investigates the construction of  dialogue structure for the use in human-machine interaction  especially for robotic systems and embodied conversational  agents.
objective_label: We are going to present a methodology and findings of a  pilot study for the design of task-specific dialogues.
method_label: Specifically, we investigated effects of dialogue complexity on  two levels: First, we examined the perception of the embodied  conversational agent, and second, we studied participants  performance following HRI.
method_label: To do so, we manipulated the agents  friendliness during a brief conversation with the user in a  receptionist scenario.
method_label: The paper presents an overview of the dialogue system, the  process of dialogue construction, and initial evidence from an  evaluation study with naive users (N = 40).
method_label: These users  interacted with the system in a task-based dialogue in which they  had to ask for the way in a building unknown to them.
method_label: Afterwards  participants filled in a questionnaire.
result_label: Our findings show that  the users prefer the friendly version of the dialogue which  scored higher values both in terms of data collected via a  questionnaire and in terms of data collected during the run of  the experiment.
result_label: Implications of the present research for follow-up studies are  discussed, specifically focusing on the effects that dialogue  features have on agent perception and on the users evaluation  and performance.

===================================
paper_id: 54447562; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter - abs_tfidfcbow200
TITLE: Exploring the importance of context and embeddings in neural NER models for task-oriented dialogue systems
ABSTRACT: background_label: Named Entity Recognition (NER), a classic sequence labelling task, is an essential component of natural language understanding (NLU) systems in task-oriented dialog systems for slot filling.
background_label: For well over a decade, different methods from lookup using gazetteers and domain ontology, classifiers over handcrafted features to end-to-end systems involving neural network architectures have been evaluated mostly in language-independent non-conversational settings.
method_label: In this paper, we evaluate a modified version of the recent state of the art neural architecture in a conversational setting where messages are often short and noisy.
method_label: We perform an array of experiments with different combinations of including the previous utterance in the dialogue as a source of additional features and using word and character level embeddings trained on a larger external corpus.
result_label: All methods are evaluated on a combined dataset formed from two public English task-oriented conversational datasets belonging to travel and restaurant domains respectively.
result_label: For additional evaluation, we also repeat some of our experiments after adding automatically translated and transliterated (from translated) versions to the English only dataset.

===================================
paper_id: 15223513; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Do (and Say) as I Say: Linguistic Adaptation in Human-Computer Dialogs
ABSTRACT: background_label: AbstractThere is strong research evidence showing that people naturally align to each other's vocabulary, sentence structure and acoustic features in dialogue, yet little is known about how the alignment mechanism operates in the interaction between users and computer systems let alone how it may be exploited to improve the efficiency of the interaction.
objective_label: This paper provides an account of lexical alignment in human-computer dialogues, based on empirical data collected in a simulated human-computer interaction scenario.
result_label: The results indicate that alignment is present, resulting in the gradual reduction and stabilisation of the vocabulary-in-use, and that it is also reciprocal.
result_label: Further, the results suggest that when system and user errors occur, the development of alignment is temporarily disrupted and users tend to introduce novel words to the dialogue.
result_label: The results also indicate that alignment in human-computer interaction may have a strong strategic component, and is used as a resource to compensate for less optimal (visually impoverished) interaction conditions.
result_label: Moreover, lower alignment is associated with less successful interaction, as measured by user perceptions.
result_label: The paper distils the results of the study into design recommendations for human-computer dialogue systems and uses them to inform a model of dialogue management that supports and exploits alignment through mechanisms for in-use adaptation of the system's grammar and lexicon.2

===================================
paper_id: 55208370; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: The Use of Dictionary and Contextual Guessing Strategies for Vocabulary Learning by Advanced English-Language Learners
ABSTRACT: background_label: The present study provides insight into the use of dictionaries and contextual guessing by advanced English-language learners.
background_label: This report identifies dictionary use and contextual guessing strategies used by these learners most often and least often.
method_label: Participants were 100 international graduate students at a large southwestern U.S. university who completed a vocabulary learning strategy questionnaire.
result_label: The results indicated that these learners consulted a dictionary most often to find out the pronunciation of a new word and least often to learn the frequency of use and appropriate usage of an unknown word.
result_label: Participants most often based their guesses of a words meaning from the paragraphs main ideas and background information.
result_label: Using the meaning of individual parts of an unfamiliar compound word (such as note-book) and the part of speech of a new word were the least-used guessing strategies.

===================================
paper_id: 3706446; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: CAESAR: Context Awareness Enabled Summary-Attentive Reader
ABSTRACT: background_label: Comprehending meaning from natural language is a primary objective of Natural Language Processing (NLP), and text comprehension is the cornerstone for achieving this objective upon which all other problems like chat bots, language translation and others can be achieved.
method_label: We report a Summary-Attentive Reader we designed to better emulate the human reading process, along with a dictiontary-based solution regarding out-of-vocabulary (OOV) words in the data, to generate answer based on machine comprehension of reading passages and question from the SQuAD benchmark.
result_label: Our implementation of these features with two popular models (Match LSTM and Dynamic Coattention) was able to reach close to matching the results obtained from humans.

===================================
paper_id: 9903828; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: The SEMAINE corpus of emotionally coloured character interactions
ABSTRACT: background_label: We have recorded a new corpus of emotionally coloured conversations.
background_label: Users were recorded while holding conversations with an operator who adopts in sequence four roles designed to evoke emotional reactions.
background_label: The operator and the user are seated in separate rooms; they see each other through teleprompter screens, and hear each other through speakers.
method_label: To allow high quality recording, they are recorded by five high-resolution, high framerate cameras, and by four microphones.
method_label: All sensor information is recorded synchronously, with an accuracy of 25 s.
method_label: In total, we have recorded 20 participants, for a total of 100 character conversational and 50 non-conversational recordings of approximately 5 minutes each.
method_label: All recorded conversations have been fully transcribed and annotated for five affective dimensions and partially annotated for 27 other dimensions.
result_label: The corpus has been made available to the scientific community through a web-accessible database.

===================================
paper_id: 61762429; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Alleviating manual feature engineering for part-of-speech tagging of Twitter microposts using distributed word representations
ABSTRACT: background_label: Many algorithms for natural language processing rely on manual feature engineering.
method_label: In this paper, we show that we can achieve state-of-the-art performance for part-of-speech tagging of Twitter microposts by solely relying on automatically inferred word embeddings as features and a neural network.
result_label: By pre-training the neural network with large amounts of automatically labeled Twitter microposts to initialize the weights, we achieve a state-of-the-art accuracy of 88.9% when tagging Twitter microposts with Penn Treebank tags.

===================================
paper_id: 53081318; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: The BQ Corpus: A Large-scale Domain-specific Chinese Corpus For Sentence Semantic Equivalence Identification
ABSTRACT: background_label: AbstractThis paper introduces the Bank Question (BQ) corpus, a Chinese corpus for sentence semantic equivalence identification (SSEI).
background_label: The BQ corpus contains 120,000 question pairs from 1-year online bank custom service logs.
objective_label: To efficiently process and annotate questions from such a large scale of logs, this paper proposes a clustering based annotation method to achieve questions with the same intent.
method_label: First, the deduplicated questions with the same answer are clustered into stacks by the Word Mover's Distance (WMD) based Affinity Propagation (AP) algorithm.
method_label: Then, the annotators are asked to assign the clustered questions into different intent categories.
method_label: Finally, the positive and negative question pairs for SSEI are selected in the same intent category and between different intent categories respectively.
result_label: We also present six SSEI benchmark performance on our corpus, including state-of-the-art algorithms.
result_label: As the largest manually annotated public Chinese SSEI corpus in the bank domain, the BQ corpus is not only useful for Chinese question semantic matching research, but also a significant resource for cross-lingual and crossdomain SSEI research.
other_label: The corpus is available in public 1 .

===================================
paper_id: 13012140; YEAR: 1997
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Analyzing and Predicting Patterns of DAMSL Utterance Tags
ABSTRACT: background_label: We have been annotating TRAINS dialogs with dialog acts in order to produce training data for a dialog act predictor, and to study how language is used in these dialogs.
background_label: We are using DAMSL dialog acts which consist of 15 independent attributes.
method_label: For the purposes of this paper, infrequent attributes such as Unintelligible and Self-Talk were set aside to concentrate on the eight major DAMSL tag sets.
method_label: For five of these eight tag sets, hand constructed decision trees (based solely on the previous utterances DAMSL tags) did better than always guessing the most frequent DAMSL tag values.
result_label: This result suggests that it is possible to automatically build such decision trees especially if other sources of context are added.
objective_label: Our initial efforts to address our second goal (studying language use in the TRAINS dialogs) consist of measuring DAMSL tag cooccurrences and bigrams.
method_label: Some interesting patterns have emerged from this simple analysis such as the fact that signaling non-understanding is often done through questions.
result_label: These patterns suggest that we should also be considering an n-gram dialog act model for use in predicting DAMSL tags.
background_label: Machine learning techniques have been successfully applied to speech recognition, part of speech tagging, word sense disambiguation, and parsing.
background_label: One reason for this success is that researchers have been able to define "correct" answers even for word sense disambiguation (Miller et al.
background_label: 1993) and parsing (Marcus, Santorini, & Marcinkiewicz 1992).
background_label: DAMSL (Dialog Act Markup in Several Layers) is a system for labeling the "correct" dialog acts for an utterance.
method_label: We are annotating dialogs with DAMSL tags in order to produce training data for a dialog act predictor, and to study how language is used in our dialog corpus.
method_label: We start this paper with a brief description of DAMSL as well as a discussion of its suitability for encoding the "correct" dialog acts for an utterance.
method_label: The second section of the paper discusses the motivation for using machine learning to automatically predict DAMSL tags, and the third section describes an initial attempt at constructing decision trees to predict DAMSL tags.
result_label: The fourth section covers interesting tag co-occurrences and bigrams showing a few ways language is used in these dialogs and suggesting that a n-gram dialog act model may be the best approach for predicting DAMSL tags.

===================================
paper_id: 23694187; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: End-to-End Optimization of Task-Oriented Dialogue Model with Deep Reinforcement Learning
ABSTRACT: background_label: In this paper, we present a neural network based task-oriented dialogue system that can be optimized end-to-end with deep reinforcement learning (RL).
method_label: The system is able to track dialogue state, interface with knowledge bases, and incorporate query results into agent's responses to successfully complete task-oriented dialogues.
method_label: Dialogue policy learning is conducted with a hybrid supervised and deep RL methods.
method_label: We first train the dialogue agent in a supervised manner by learning directly from task-oriented dialogue corpora, and further optimize it with deep RL during its interaction with users.
method_label: In the experiments on two different dialogue task domains, our model demonstrates robust performance in tracking dialogue state and producing reasonable system responses.
result_label: We show that deep RL based optimization leads to significant improvement on task success rate and reduction in dialogue length comparing to supervised training model.
result_label: We further show benefits of training task-oriented dialogue model end-to-end comparing to component-wise optimization with experiment results on dialogue simulations and human evaluations.

===================================
paper_id: 1650722; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Parsing entire discourses as very long strings: Capturing topic continuity in grounded language learning
ABSTRACT: background_label: Grounded language learning, the task of mapping from natural language to a representation of meaning, has attracted more and more interest in recent years.
background_label: In most work on this topic, however, utterances in a conversation are treated independently and discourse structure information is largely ignored.
background_label: In the context of language acquisition, this independence assumption discards cues that are important to the learner, e.g., the fact that consecutive utterances are likely to share the same referent (Frank et al., 2013).
objective_label: The current paper describes an approach to the problem of simultaneously modeling grounded language at the sentence and discourse levels.
method_label: We combine ideas from parsing and grammar induction to produce a parser that can handle long input strings with thousands of tokens, creating parse trees that represent full discourses.
method_label: By casting grounded language learning as a grammatical inference task, we use our parser to extend the work of Johnson et al.
method_label: (2012), investigating the importance of discourse continuity in childrens language acquisition and its interaction with social cues.
result_label: Our model boosts performance in a language acquisition task and yields good discourse segmentations compared with human annotators.

===================================
paper_id: 14930866; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 2; annotator4: 0; annotator3: 2
sources: title_tfidf
TITLE: A probabilistic approach to learning a visually grounded language model through human-robot interaction
ABSTRACT: background_label: Language is among the most fascinating and complex cognitive activities that develops rapidly since the early months of infants' life.
objective_label: The aim of the present work is to provide a humanoid robot with cognitive, perceptual and motor skills fundamental for the acquisition of a rudimentary form of language.
objective_label: We present a novel probabilistic model, inspired by the findings in cognitive sciences, able to associate spoken words with their perceptually grounded meanings.
objective_label: The main focus is set on acquiring the meaning of various perceptual categories (e.g.
other_label: red, blue, circle, above, etc.
method_label: ), rather than specific world entities (e.g.
objective_label: an apple, a toy, etc.).
method_label: Our probabilistic model is based on a variant of multi-instance learning technique, and it enables a robotic platform to learn grounded meanings of adjective/noun terms.
result_label: The systems could be used to understand and generate appropriate natural language descriptions of real objects in a scene, and it has been successfully tested on the NAO humanoid robotic platform.

===================================
paper_id: 36772884; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Making sense of big text: a visual-first approach for analysing text data using Leximancer and Discursis
ABSTRACT: background_label: This article reports on Leximancer and Discursis, two visual text analytic software tools developed at the University of Queensland.
background_label: Both analyse spatial and temporal relationships in text data, but in complementary ways: Leximancer focuses on thematic analysis, while Discursis focuses on sequential analysis.
result_label: Our report explains how they work, how to work with them and how visual concepts are relevant to all stages of their use in analytic decision-making.

===================================
paper_id: 940994; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Extracting salient sublexical units from written texts: Emophon, a corpus-based approach to phonological iconicity
ABSTRACT: background_label: A GROWING BODY OF LITERATURE IN PSYCHOLOGY, LINGUISTICS, AND THE NEUROSCIENCES HAS PAID INCREASING ATTENTION TO THE UNDERSTANDING OF THE RELATIONSHIPS BETWEEN PHONOLOGICAL REPRESENTATIONS OF WORDS AND THEIR MEANING: a phenomenon also known as phonological iconicity.
objective_label: In this article, we investigate how a text's intended emotional meaning, particularly in literature and poetry, may be reflected at the level of sublexical phonological salience and the use of foregrounded elements.
method_label: To extract such elements from a given text, we developed a probabilistic model to predict the exceeding of a confidence interval for specific sublexical units concerning their frequency of occurrence within a given text contrasted with a reference linguistic corpus for the German language.
result_label: Implementing this model in a computational application, we provide a text analysis tool which automatically delivers information about sublexical phonological salience allowing researchers, inter alia, to investigate effects of the sublexical emotional tone of texts based on current findings on phonological iconicity.

===================================
paper_id: 1139492; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Stochastic Language Generation in Dialogue using Recurrent Neural Networks with Convolutional Sentence Reranking
ABSTRACT: background_label: The natural language generation (NLG) component of a spoken dialogue system (SDS) usually needs a substantial amount of handcrafting or a well-labeled dataset to be trained on.
background_label: These limitations add significantly to development costs and make cross-domain, multi-lingual dialogue systems intractable.
background_label: Moreover, human languages are context-aware.
background_label: The most natural response should be directly learned from data rather than depending on predefined syntaxes or rules.
objective_label: This paper presents a statistical language generator based on a joint recurrent and convolutional neural network structure which can be trained on dialogue act-utterance pairs without any semantic alignments or predefined grammar trees.
method_label: Objective metrics suggest that this new model outperforms previous methods under the same experimental conditions.
result_label: Results of an evaluation by human judges indicate that it produces not only high quality but linguistically varied utterances which are preferred compared to n-gram and rule-based systems.

===================================
paper_id: 6414781; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 2; annotator4: 0; annotator3: 2
sources: abs_tfidf
TITLE: A system for interactive learning in dialogue with a tutor
ABSTRACT: background_label: In this paper we present representations and mechanisms that facilitate continuous learning of visual concepts in dialogue with a tutor and show the implemented robot system.
objective_label: We present how beliefs about the world are created by processing visual and linguistic information and show how they are used for planning system behaviour with the aim at satisfying its internal drive - to extend its knowledge.
method_label: The system facilitates different kinds of learning initiated by the human tutor or by the system itself.
result_label: We demonstrate these principles in the case of learning about object colours and basic shapes.

===================================
paper_id: 26989649; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - specter
TITLE: Non-Contextual Modeling of Sarcasm using a Neural Network Benchmark
ABSTRACT: background_label: One of the most crucial components of natural human-robot interaction is artificial intuition and its influence on dialog systems.
background_label: The intuitive capability that humans have is undeniably extraordinary, and so remains one of the greatest challenges for natural communicative dialogue between humans and robots.
objective_label: In this paper, we introduce a novel probabilistic modeling framework of identifying, classifying and learning features of sarcastic text via training a neural network with human-informed sarcastic benchmarks.
method_label: This is necessary for establishing a comprehensive sentiment analysis schema that is sensitive to the nuances of sarcasm-ridden text by being trained on linguistic cues.
method_label: We show that our model provides a good fit for this type of real-world informed data, with potential to achieve as accurate, if not more, than alternatives.
result_label: Though the implementation and benchmarking is an extensive task, it can be extended via the same method that we present to capture different forms of nuances in communication and making for much more natural and engaging dialogue systems.

===================================
paper_id: 7018291; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Learning Lexicons From Speech Using a Pronunciation Mixture Model
ABSTRACT: background_label: In many ways, the lexicon remains the Achilles heel of modern automatic speech recognizers.
background_label: Unlike stochastic acoustic and language models that learn the values of their parameters from training data, the baseform pronunciations of words in a recognizer's lexicon are typically specified manually, and do not change, unless they are edited by an expert.
objective_label: Our work presents a novel generative framework that uses speech data to learn stochastic lexicons, thereby taking a step towards alleviating the need for manual intervention and automatically learning high-quality pronunciations for words.
method_label: We test our model on continuous speech in a weather information domain.
result_label: In our experiments, we see significant improvements over a manually specified expert-pronunciation lexicon.
result_label: We then analyze variations of the parameter settings used to achieve these gains.

===================================
paper_id: 37833484; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - title_tfidfcbow200 - abs_cbow200
TITLE: Automatic Linguistic Annotation ofLarge Scale L2 Databases: The EF-Cambridge Open Language Database(EFCamDat)
ABSTRACT: background_label: Naturalistic learner productions are an important empirical resource for SLA research.
background_label: Some pioneering works have produced valuable second language (L2) resources supporting SLA research.1 One common limitation of these resources is the absence of individual longitudinal data for numerous speakers with different backgrounds across the proficiency spectrum, which is vital for understanding the nature of individual variation in longitudinal development.2 A second limitation is the relatively restricted amounts of data annotated with linguistic information (e.g., lexical, morphosyntactic, semantic features, etc.)
background_label: to support investigation of SLA hypotheses and obtain patterns of development for different linguistic phenomena.
background_label: Where available, annotations tend to be manually obtained, a situation posing immediate limitations to the quantity of data that could be annotated with reasonable human resources and within reasonable time.
method_label: Natural Language Processing (NLP) tools can provide automatic annotations for parts-of-speech (POS) and syntactic structure and are indeed increasingly applied to learner language in various contexts.
method_label: Systems in computer-assisted language learning (CALL) have used a parser and other NLP tools to automatically detect learner errors and provide feedback accordingly.3 Some work aimed at adapting annotations provided by parsing tools to accurately describe learner syntax (Dickinson & Lee, 2009) or evaluated parser performance on learner language and the effect of learner errors on the parser.
result_label: Krivanek and Meurers (2011) compared two parsing methods, one using a hand-crafted lexicon and one trained on a corpus.
background_label: They found that the former is more successful in recovering the main grammatical dependency relations whereas the latter is more successful in recovering optional, adjunction relations.
background_label: Ott and Ziai (2010) evaluated the performance of a dependency parser trained on native German (MaltParser; Nivre et al., 2007) on 106 learner answers to a comprehension task in L2 German.
background_label: Their study indicates that while some errors can be problematic for the parser (e.g., omission of finite verbs) many others (e.g., wrong word order) can be parsed robustly, resulting in overall high performance scores.
objective_label: In this paper we have two goals.
method_label: First, we introduce a new English L2 database, the EF Cambridge Open Language Database, henceforth EFCAMDAT.
method_label: EFCAMDAT was developed by the Department of Theoretical and Applied Linguistics at the University of Cambridge in collaboration with EF Education First, an international educational organization.
result_label: It contains writings submitted to Englishtown, the

===================================
paper_id: 121327708; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - specter
TITLE: Towards Open Intent Discovery for Conversational Text
ABSTRACT: background_label: Detecting and identifying user intent from text, both written and spoken, plays an important role in modelling and understand dialogs.
background_label: Existing research for intent discovery model it as a classification task with a predefined set of known categories.
objective_label: To generailze beyond these preexisting classes, we define a new task of \textit{open intent discovery}.
method_label: We investigate how intent can be generalized to those not seen during training.
method_label: To this end, we propose a two-stage approach to this task - predicting whether an utterance contains an intent, and then tagging the intent in the input utterance.
background_label: Our model consists of a bidirectional LSTM with a CRF on top to capture contextual semantics, subject to some constraints.
method_label: Self-attention is used to learn long distance dependencies.
method_label: Further, we adapt an adversarial training approach to improve robustness and perforamce across domains.
method_label: We also present a dataset of 25k real-life utterances that have been labelled via crowd sourcing.
result_label: Our experiments across different domains and real-world datasets show the effectiveness of our approach, with less than 100 annotated examples needed per unique domain to recognize diverse intents.
result_label: The approach outperforms state-of-the-art baselines by 5-15% F1 score points.

===================================
paper_id: 675997; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Solving Verbal Comprehension Questions in IQ Test by Knowledge-Powered Word Embedding
ABSTRACT: background_label: Intelligence Quotient (IQ) Test is a set of standardized questions designed to evaluate human intelligence.
background_label: Verbal comprehension questions appear very frequently in IQ tests, which measure human's verbal ability including the understanding of the words with multiple senses, the synonyms and antonyms, and the analogies among words.
background_label: In this work, we explore whether such tests can be solved automatically by artificial intelligence technologies, especially the deep learning technologies that are recently developed and successfully applied in a number of fields.
background_label: However, we found that the task was quite challenging, and simply applying existing technologies (e.g., word embedding) could not achieve a good performance, mainly due to the multiple senses of words and the complex relations among words.
method_label: To tackle these challenges, we propose a novel framework consisting of three components.
method_label: First, we build a classifier to recognize the specific type of a verbal question (e.g., analogy, classification, synonym, or antonym).
method_label: Second, we obtain distributed representations of words and relations by leveraging a novel word embedding method that considers the multi-sense nature of words and the relational knowledge among words (or their senses) contained in dictionaries.
method_label: Third, for each type of questions, we propose a specific solver based on the obtained distributed word representations and relation representations.
result_label: Experimental results have shown that the proposed framework can not only outperform existing methods for solving verbal comprehension questions but also exceed the average performance of the Amazon Mechanical Turk workers involved in the study.
result_label: The results indicate that with appropriate uses of the deep learning technologies we might be a further step closer to the human intelligence.

===================================
paper_id: 14177520; YEAR: 2004
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Sphinx-4: A flexible open source framework for speech recognition
ABSTRACT: background_label: Sphinx-4 is a flexible, modular and pluggable framework to help foster new innovations in the core research of hidden Markov model (HMM) speech recognition systems.
background_label: The design of Sphinx-4 is based on patterns that have emerged from the design of past systems as well as new requirements based on areas that researchers currently want to explore.
method_label: To exercise this framework, and to provide researchers with a "researchready" system, Sphinx-4 also includes several implementations of both simple and state-of-the-art techniques.
result_label: The framework and the implementations are all freely available via open source.

===================================
paper_id: 198806032; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: The use of task-based language teaching method to teach terms and phrases for those learning Turkish as a second language and sample activities
ABSTRACT: background_label: Human beings, since they first met different languages and cultures, have had an urge to learn those languages and cultures.
background_label: In modern societies, this urge has currently turned into a necessity.
background_label: As a result of this necessity, the supply-demand balance has changed and the rate of language learning and acquiring new cultures have increased parallel to the rising world population.
background_label: All these developments required the language teaching and learning process to be implemented as a scientific discipline.
method_label: A plethora of different methods have emerged and shaped on the basis of scientific data.
method_label: One of these methods is Task-based Language Teaching (TBLT).
background_label: This method was introduced in the last quarter of 20th century and has still been widely used in language teaching today.
method_label: In this study, we tried to teach new terms and phrases to C1 level learners learning Turkish as a second language with task-centered activities formed in compliance with the principles of task-based language teaching method.
method_label: Terms and phrases are vital for C1 level learners to be an independent performer of the language in the four basic skills of the language.
method_label: Two discrete sections form up this study.
method_label: In the first section, literature review and general information about task-based language teaching method are introduced.
method_label: In the latter, there are seven sample activities formed with regard to the instructional design of task-based language teaching method.
result_label: In these activities, we tried to teach terms and phrases through various tasks.

===================================
paper_id: 59710599; YEAR: 2001
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Automatic Summarization of Spoken Dialogues in Unrestricted Domains
ABSTRACT: background_label: While the majority of summarization research so far has focused on written documents (mostly news articles or scientific papers), this thesis addresses for the first time the challenge of automatically summarizing spoken dialogues in a variety of genres and without any restriction on domain.
method_label: To achieve the goal of spoken dialogue summarization, we implement a system (DiaSumm) using a multi-stage architecture with trainable components which addresses the dialogue-specific issues of summarization and which involves (i) speech disfluency detection and removal, (ii) identification and insertion of sentence boundaries, (iii) identification and linking of question-answer regions, (iv) topical segmentation, and (v) information condensation (ranking of relevant pieces of information with the maximum marginal relevance technique (MMR)).
method_label: We can also optionally reduce the summary content in an orthogonal dimension by rendering only a subset of the phrases within a relevant sentence (typically, noun phrases).
method_label: For system development and evaluation, we use a corpus of 23 dialogue excerpts from four different text genres, totalling 80 topical segments, about 47000 words, or about 4 hours of recorded speech: English CallHome (informal, colloquial style), Group Meetings (task oriented, rather informal, colloquial), and dialogue oriented television shows: NewsHour and CrossFire (more formal, potentially partially scripted).
method_label: The corpus had been manually transcribed and was annotated for topical boundaries and relevant text spans by six human annotators.
method_label: Further, it was annotated for speech disfluencies and questions and their corresponding answers.
method_label: We devise a word-based evaluation criterion, relative summary accuracy, which reflects how well the summary captures passages that were placed in man-made summaries by the largest number of annotators.
result_label: The global evaluation, performed on human transcripts, shows that for the two more informal genres (CallHome and Group Meetings), DiaSumm significantly outperforms a baseline using TF*IDF term weighting with MMR ranking only, while tying with the MMR baseline for the two more formal genres.
method_label: Furthermore, except for the NewsHour corpus, both the MMR baseline and our DiaSumm system are significantly better than a LEAD baseline (first N words of each segment).
result_label: Finally, when using speech recognizer output, our system can make successful use of speech recognizer confidence scores to focus on sentences which are more likely to be correctly recognized; thereby, the word error rate in summaries can be reduced significantly while relative summary accuracy improves on average.

===================================
paper_id: 20160335; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Sentiment analysis methods for understanding large-scale texts: a case for using continuum-scored words and word shift graphs
ABSTRACT: background_label: The emergence and global adoption of social media has rendered possible the real-time estimation of population-scale sentiment, an extraordinary capacity which has profound implications for our understanding of human behavior.
background_label: Given the growing assortment of sentiment-measuring instruments, it is imperative to understand which aspects of sentiment dictionaries contribute to both their classification accuracy and their ability to provide richer understanding of texts.
method_label: Here, we perform detailed, quantitative tests and qualitative assessments of 6 dictionary-based methods applied to 4 different corpora, and briefly examine a further 20 methods.
method_label: We show that while inappropriate for sentences, dictionary-based methods are generally robust in their classification accuracy for longer texts.
result_label: Most importantly they can aid understanding of texts with reliable and meaningful word shift graphs if (1) the dictionary covers a sufficiently large portion of a given texts lexicon when weighted by word usage frequency; and (2) words are scored on a continuous scale.

===================================
paper_id: 269828; YEAR: 1983
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: The NOMAD System: Expectation-Based Detection And Correction Of Errors During Understanding Of Syntactically And Semantically Ill-Formed Text
ABSTRACT: background_label: Most large text-understanding systems have been designed under the assumption that the input text will be in reasonably "neat" form (for example, newspaper stories and other edited texts).However, a great deal of natural language text (for example, memos, messages, rough drafts, conversation transcripts, etc.)
background_label: have features that differ significantly from "neat" texts, posing special problems for readers, such as misspelled words, missing words, poor syntactic construction, unclear or ambiguous interpretation, missing crucial punctuation, etc.
objective_label: Our solution to these problems is to make use of expectations, based both on knowledge of surface English and on world knowledge of the situation being described.
method_label: These syntactic and semantic expectations can be used to figure out unknown words from context, constrain the possible word senses of words with multiple meanings (ambiguity), fill in missing words (ellipsis), and resolve referents (anaphora).
method_label: This method of using expectations to aid the understanding of "scruffy" texts has been incorporated into a working computer program called NOMAD, which understands scruffy texts in the domain of Navy ship-to-shore messages.

===================================
paper_id: 14780577; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: CFGs-2-NLU: Sequence-to-Sequence Learning for Mapping Utterances to Semantics and Pragmatics
ABSTRACT: objective_label: In this paper, we present a novel approach to natural language understanding that utilizes context-free grammars (CFGs) in conjunction with sequence-to-sequence (seq2seq) deep learning.
method_label: Specifically, we take a CFG authored to generate dialogue for our target application for NLU, a videogame, and train a long short-term memory (LSTM) recurrent neural network (RNN) to map the surface utterances that it produces to traces of the grammatical expansions that yielded them.
method_label: Critically, this CFG was authored using a tool we have developed that supports arbitrary annotation of the nonterminal symbols in the grammar.
method_label: Because we already annotated the symbols in this grammar for the semantic and pragmatic considerations that our game's dialogue manager operates over, we can use the grammatical trace associated with any surface utterance to infer such information.
method_label: During gameplay, we translate player utterances into grammatical traces (using our RNN), collect the mark-up attributed to the symbols included in that trace, and pass this information to the dialogue manager, which updates the conversation state accordingly.
result_label: From an offline evaluation task, we demonstrate that our trained RNN translates surface utterances to grammatical traces with great accuracy.
result_label: To our knowledge, this is the first usage of seq2seq learning for conversational agents (our game's characters) who explicitly reason over semantic and pragmatic considerations.

===================================
paper_id: 58469022; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Pronunciation Learning for Automatic Speech Recognition
ABSTRACT: background_label: In many ways, the lexicon remains the Achilles heel of modern automatic speech recognizers (ASRs).
background_label: Unlike stochastic acoustic and language models that learn the values of their parameters from training data, the baseform pronunciations of words in an ASR vocabulary are typically specified manually, and do not change, unless they are edited by an expert.
objective_label: Our work presents a novel generative framework that uses speech data to learn stochastic lexicons, thereby taking a step towards alleviating the need for manual intervention and automatically learning high-quality baseform pronunciations for words.
method_label: We test our model on a variety of domains: an isolated-word telephone speech corpus, a weather query corpus and an academic lecture corpus.
result_label: We show significant improvements of 25%, 15% and 2% over expert-pronunciation lexicons, respectively.
result_label: We also show that further improvements can be made by combining our pronunciation learning framework with acoustic model training.
other_label: Thesis Supervisor: James Glass Title: Principal Research Scientist

===================================
paper_id: 2617; YEAR: 1998
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Computing Dialogue Acts from Features with Transformation-Based Learning
ABSTRACT: background_label: To interpret natural language at the discourse level, it is very useful to accurately recognize dialogue acts, such as SUGGEST, in identifying speaker intentions.
objective_label: Our research explores the utility of a machine learning method called Transformation-Based Learning (TBL) in computing dialogue acts, because TBL has a number of advantages over alternative approaches for this application.
method_label: We have identified some extensions to TBL that are necessary in order to address the limitations of the original algorithm and the particular demands of discourse processing.
method_label: We use a Monte Carlo strategy to increase the applicability of the TBL method, and we select features of utterances that can be used as input to improve the performance of TBL.
result_label: Our system is currently being tested on the VerbMobil corpora of spoken dialogues, producing promising preliminary results.

===================================
paper_id: 125238702; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: A Generative Montagovian Lexicon for Polysemous Deverbal Nouns
ABSTRACT: background_label: We propose a computational formalization of some forms of polysemy.
method_label: Here we focus on the resultative/processual polysemy of deverbal nouns like assinatura ("signing/signature") or abertura ("opening/aperture") in Por- tuguese -- we also study similar constructs in French, Italian, and English.
method_label: We follow the Montagovian Generative Lexicon (MGL) introduced in Bassac, Mery & Retor e (2010) based on second-order Girard's F system with several entity types -- including at least one type t for propositions and several entity types, as v (event), s (state)  (physical object).
result_label: Our for- malization produces the readings involving one aspect of the polysemous noun, and it also handles properly co-predication phenomena.

===================================
paper_id: 31065956; YEAR: 2005
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: AutoTutor: an intelligent tutoring system with mixed-initiative dialogue
ABSTRACT: background_label: AutoTutor simulates a human tutor by holding a conversation with the learner in natural language.
background_label: The dialogue is augmented by an animated conversational agent and three-dimensional (3-D) interactive simulations in order to enhance the learner's engagement and the depth of the learning.
method_label: Grounded in constructivist learning theories and tutoring research, AutoTutor achieves learning gains of approximately 0.8 sigma (nearly one letter grade), depending on the learning measure and comparison condition.
method_label: The computational architecture of the system uses the .NET framework and has simplified deployment for classroom trials.

===================================
paper_id: 202676699; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Large-scale representation learning from visually grounded untranscribed speech
ABSTRACT: background_label: Systems that can associate images with their spoken audio captions are an important step towards visually grounded language learning.
method_label: We describe a scalable method to automatically generate diverse audio for image captioning datasets.
method_label: This supports pretraining deep networks for encoding both audio and images, which we do via a dual encoder that learns to align latent representations from both modalities.
method_label: We show that a masked margin softmax loss for such models is superior to the standard triplet loss.
method_label: We fine-tune these models on the Flickr8k Audio Captions Corpus and obtain state-of-the-art results---improving recall in the top 10 from 29.6% to 49.5%.
result_label: We also obtain human ratings on retrieval outputs to better assess the impact of incidentally matching image-caption pairs that were not associated in the data, finding that automatic evaluation substantially underestimates the quality of the retrieved results.

===================================
paper_id: 2559095; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: LingSync & the Online Linguistic Database: New Models for the Collection and Management of Data for Language Communities, Linguists and Language Learners
ABSTRACT: background_label: LingSync and the Online Linguistic Database (OLD) are new models for the collection and management of data in endangered language settings.
background_label: The LingSync and OLD projects seek to close a feedback loop between field linguists, language communities, software developers, and computational linguists by creating web services and user interfaces (UIs) which facilitate collaborative and inclusive language documentation.
objective_label: This paper presents the architectures of these tools and the resources generated thus far.
method_label: We also briefly discuss some of the features of the systems which are particularly helpful to endangered languages fieldwork and which should also be of interest to computational linguists, these being a service that automates the identification of utterances within audio/video, another that automates the alignment of audio recordings and transcriptions, and a number of services that automate the morphological parsing task.
result_label: The paper discusses the requirements of software used for endangered language documentation, and presents novel data which demonstrates that users are actively seeking alternatives despite existing software.

===================================
paper_id: 15303282; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidf
TITLE: Combining Chat and Task-Based Multimodal Dialogue for More Engaging HRI: A Scalable Method Using Reinforcement Learning
ABSTRACT: background_label: We develop the first system to combine task-based and chatbot-style dialogue in a multimodal system for Human-Robot Interaction.
method_label: We show that Reinforcement Learning is beneficial for training dialogue management (DM) in such systems -- providing a scalable method for training from data and/or simulated users.
method_label: We first train in simulation, and evaluate the benefits of a combined chat/task policy over systems which can only perform chat or task-based conversation.
result_label: In a real user evaluation, we then show that a trained combined chat/task multimodal dialogue policy results in longer dialogue interactions than a rule-based approach, suggesting that the learned dialogue policy provides a more engaging mixture of chat and task interaction than a rule-based DM method.

===================================
paper_id: 6395504; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Neural Emoji Recommendation in Dialogue Systems
ABSTRACT: background_label: Emoji is an essential component in dialogues which has been broadly utilized on almost all social platforms.
background_label: It could express more delicate feelings beyond plain texts and thus smooth the communications between users, making dialogue systems more anthropomorphic and vivid.
objective_label: In this paper, we focus on automatically recommending appropriate emojis given the contextual information in multi-turn dialogue systems, where the challenges locate in understanding the whole conversations.
method_label: More specifically, we propose the hierarchical long short-term memory model (H-LSTM) to construct dialogue representations, followed by a softmax classifier for emoji classification.
method_label: We evaluate our models on the task of emoji classification in a real-world dataset, with some further explorations on parameter sensitivity and case study.
result_label: Experimental results demonstrate that our method achieves the best performances on all evaluation metrics.
result_label: It indicates that our method could well capture the contextual information and emotion flow in dialogues, which is significant for emoji recommendation.

===================================
paper_id: 82456167; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Janeway's Immunobiology
ABSTRACT: background_label: Part I An Introduction to Immunobiology and Innate Immunity 1.
background_label: Basic Concepts in Immunology 2.
background_label: Innate Immunity Part II The Recognition of Antigen 3.
background_label: Antigen Recognition by B-cell and T-cell Receptors 4.
method_label: The Generation of Lymphocyte Antigen Receptors 5.
method_label: Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6.
method_label: Signaling Through Immune System Receptors 7.
result_label: The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8.
background_label: T Cell-Mediated Immunity 9.
background_label: The Humoral Immune Response 10.
background_label: Dynamics of Adaptive Immunity 11.
other_label: The Mucosal Immune System Part V The Immune System in Health and Disease 12.
background_label: Failures of Host Defense Mechanism 13.
other_label: Allergy and Hypersensitivity 14.
other_label: Autoimmunity and Transplantation 15.
other_label: Manipulation of the Immune Response Part VI The Origins of Immune Responses 16.
other_label: Evolution of the Immune System Appendix I Immunologists' Toolbox Appendix II CD Antigens Appendix III Cytokines and their Receptors Appendix IV Chemokines and their Receptors Appendix V Immunological Constants

===================================
paper_id: 18939887; YEAR: 2003
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200
TITLE: The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text.
ABSTRACT: background_label: Interpretation of semantic propositions in free-text documents such as MEDLINE citations would provide valuable support for biomedical applications, and several approaches to semantic interpretation are being pursued in the biomedical informatics community.
objective_label: In this paper, we describe a methodology for interpreting linguistic structures that encode hypernymic propositions, in which a more specific concept is in a taxonomic relationship with a more general concept.
method_label: In order to effectively process these constructions, we exploit underspecified syntactic analysis and structured domain knowledge from the Unified Medical Language System (UMLS).
method_label: After introducing the syntactic processing on which our system depends, we focus on the UMLS knowledge that supports interpretation of hypernymic propositions.
method_label: We first use semantic groups from the Semantic Network to ensure that the two concepts involved are compatible; hierarchical information in the Metathesaurus then determines which concept is more general and which more specific.
method_label: A preliminary evaluation of a sample based on the semantic group Chemicals and Drugs provides 83% precision.
method_label: An error analysis was conducted and potential solutions to the problems encountered are presented.
result_label: The research discussed here serves as a paradigm for investigating the interaction between domain knowledge and linguistic structure in natural language processing, and could also make a contribution to research on automatic processing of discourse structure.
result_label: Additional implications of the system we present include its integration in advanced semantic interpretation processors for biomedical text and its use for information extraction in specific domains.
result_label: The approach has the potential to support a range of applications, including information retrieval and ontology engineering.

===================================
paper_id: 8413785; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 2; annotator4: 0; annotator3: 2
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Attribute based object identification
ABSTRACT: background_label: Over the last years, the robotics community has made substantial progress in detection and 3D pose estimation of known and unknown objects.
background_label: However, the question of how to identify objects based on language descriptions has not been investigated in detail.
background_label: While the computer vision community recently started to investigate the use of attributes for object recognition, these approaches do not consider the task settings typically observed in robotics, where a combination of appearance attributes and object names might be used in referral language to identify specific objects in a scene.
objective_label: In this paper, we introduce an approach for identifying objects based on natural language containing appearance and name attributes.
method_label: To learn rich RGB-D features needed for attribute classification, we extend recently introduced sparse coding techniques so as to automatically learn attribute-dependent features.
method_label: We introduce a large data set of attribute descriptions of objects in the RGB-D object dataset.
method_label: Experiments on this data set demonstrate the strong performance of our approach to language based object identification.
result_label: We also show that our attribute-dependent features provide significantly better generalization to previously unseen attribute values, thereby enabling more rapid learning of new attribute values.

===================================
paper_id: 53874417; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: DALI: a large Dataset of synchronized Audio, LyrIcs and notes, automatically created using teacher-student machine learning paradigm
ABSTRACT: objective_label: The goal of this paper is twofold.
objective_label: First, we introduce DALI, a large and rich multimodal dataset containing 5358 audio tracks with their time-aligned vocal melody notes and lyrics at four levels of granularity.
objective_label: The second goal is to explain our methodology where dataset creation and learning models interact using a teacher-student machine learning paradigm that benefits each other.
method_label: We start with a set of manual annotations of draft time-aligned lyrics and notes made by non-expert users of Karaoke games.
method_label: This set comes without audio.
result_label: Therefore, we need to find the corresponding audio and adapt the annotations to it.
background_label: To that end, we retrieve audio candidates from the Web.
method_label: Each candidate is then turned into a singing-voice probability over time using a teacher, a deep convolutional neural network singing-voice detection system (SVD), trained on cleaned data.
method_label: Comparing the time-aligned lyrics and the singing-voice probability, we detect matches and update the time-alignment lyrics accordingly.
method_label: From this, we obtain new audio sets.
method_label: They are then used to train new SVD students used to perform again the above comparison.
method_label: The process could be repeated iteratively.
result_label: We show that this allows to progressively improve the performances of our SVD and get better audio-matching and alignment.

===================================
paper_id: 11928084; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Sample-efficient batch reinforcement learning for dialogue management optimization
ABSTRACT: background_label: Spoken Dialogue Systems (SDS) are systems which have the ability to interact with human beings using natural language as the medium of interaction.
background_label: A dialogue policy plays a crucial role in determining the functioning of the dialogue management module.
background_label: Handcrafting the dialogue policy is not always an option, considering the complexity of the dialogue task and the stochastic behavior of users.
method_label: In recent years approaches based on Reinforcement Learning (RL) for policy optimization in dialogue management have been proved to be an efficient approach for dialogue policy optimization.
result_label: Yet most of the conventional RL algorithms are data intensive and demand techniques such as user simulation.
background_label: Doing so, additional modeling errors are likely to occur.
objective_label: This paper explores the possibility of using a set of approximate dynamic programming algorithms for policy optimization in SDS.
method_label: Moreover, these algorithms are combined to a method for learning a sparse representation of the value function.
result_label: Experimental results show that these algorithms when applied to dialogue management optimization are particularly sample efficient, since they learn from few hundreds of dialogue examples.
method_label: These algorithms learn in an off-policy manner, meaning that they can learn optimal policies with dialogue examples generated with a quite simple strategy.
result_label: Thus they can learn good dialogue policies directly from data, avoiding user modeling errors.

===================================
paper_id: 54434421; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Flexible and Scalable State Tracking Framework for Goal-Oriented Dialogue Systems
ABSTRACT: background_label: Goal-oriented dialogue systems typically rely on components specifically developed for a single task or domain.
background_label: This limits such systems in two different ways: If there is an update in the task domain, the dialogue system usually needs to be updated or completely re-trained.
background_label: It is also harder to extend such dialogue systems to different and multiple domains.
background_label: The dialogue state tracker in conventional dialogue systems is one such component - it is usually designed to fit a well-defined application domain.
result_label: For example, it is common for a state variable to be a categorical distribution over a manually-predefined set of entities (Henderson et al., 2013), resulting in an inflexible and hard-to-extend dialogue system.
objective_label: In this paper, we propose a new approach for dialogue state tracking that can generalize well over multiple domains without incorporating any domain-specific knowledge.
method_label: Under this framework, discrete dialogue state variables are learned independently and the information of a predefined set of possible values for dialogue state variables is not required.
method_label: Furthermore, it enables adding arbitrary dialogue context as features and allows for multiple values to be associated with a single state variable.
method_label: These characteristics make it much easier to expand the dialogue state space.
result_label: We evaluate our framework using the widely used dialogue state tracking challenge data set (DSTC2) and show that our framework yields competitive results with other state-of-the-art results despite incorporating little domain knowledge.
result_label: We also show that this framework can benefit from widely available external resources such as pre-trained word embeddings.

===================================
paper_id: 2381275; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter - title_cbow200 - abs_tfidfcbow200
TITLE: The LAMBADA dataset: Word prediction requiring a broad discourse context
ABSTRACT: background_label: We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task.
background_label: LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word.
method_label: To succeed on LAMBADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse.
result_label: We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark.
result_label: We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text.

===================================
paper_id: 718342; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Are distributional representations ready for the real world? Evaluating word vectors for grounded perceptual meaning
ABSTRACT: background_label: Distributional word representation methods exploit word co-occurrences to build compact vector encodings of words.
background_label: While these representations enjoy widespread use in modern natural language processing, it is unclear whether they accurately encode all necessary facets of conceptual meaning.
objective_label: In this paper, we evaluate how well these representations can predict perceptual and conceptual features of concrete concepts, drawing on two semantic norm datasets sourced from human participants.
result_label: We find that several standard word representations fail to encode many salient perceptual features of concepts, and show that these deficits correlate with word-word similarity prediction errors.
result_label: Our analyses provide motivation for grounded and embodied language learning approaches, which may help to remedy these deficits.

===================================
paper_id: 184486818; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Reinforcement Learning of Minimalist Numeral Grammars
ABSTRACT: background_label: Speech-controlled user interfaces facilitate the operation of devices and household functions to laymen.
background_label: State-of-the-art language technology scans the acoustically analyzed speech signal for relevant keywords that are subsequently inserted into semantic slots to interpret the user's intent.
method_label: In order to develop proper cognitive information and communication technologies, simple slot-filling should be replaced by utterance meaning transducers (UMT) that are based on semantic parsers and a \emph{mental lexicon}, comprising syntactic, phonetic and semantic features of the language under consideration.
method_label: This lexicon must be acquired by a cognitive agent during interaction with its users.
method_label: We outline a reinforcement learning algorithm for the acquisition of the syntactic morphology and arithmetic semantics of English numerals, based on minimalist grammar (MG), a recent computational implementation of generative linguistics.
method_label: Number words are presented to the agent by a teacher in form of utterance meaning pairs (UMP) where the meanings are encoded as arithmetic terms from a suitable term algebra.
result_label: Since MG encodes universal linguistic competence through inference rules, thereby separating innate linguistic knowledge from the contingently acquired lexicon, our approach unifies generative grammar and reinforcement learning, hence potentially resolving the still pending Chomsky-Skinner controversy.

===================================
paper_id: 25185992; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Improving Visually Grounded Sentence Representations with Self-Attention
ABSTRACT: background_label: Sentence representation models trained only on language could potentially suffer from the grounding problem.
background_label: Recent work has shown promising results in improving the qualities of sentence representations by jointly training them with associated image features.
background_label: However, the grounding capability is limited due to distant connection between input sentences and image features by the design of the architecture.
method_label: In order to further close the gap, we propose applying self-attention mechanism to the sentence encoder to deepen the grounding effect.
result_label: Our results on transfer tasks show that self-attentive encoders are better for visual grounding, as they exploit specific words with strong visual associations.

===================================
paper_id: 173187861; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: Effective writing style imitation via combinatorial paraphrasing
ABSTRACT: background_label: Stylometry can be used to profile authors based on their written text.
background_label: Transforming text to imitate someone else's writing style while retaining meaning constitutes a defence.
background_label: A variety of deep learning methods for style imitation have been proposed in recent research literature.
method_label: Via empirical evaluation of three state-of-the-art models on four datasets, we illustrate that none succeed in semantic retainment, often drastically changing the original meaning or removing important parts of the text.
method_label: To mitigate this problem we present ParChoice: an alternative approach based on the combinatorial application of multiple paraphrasing techniques.
method_label: ParChoice first produces a large number of possible candidate paraphrases, from which it then chooses the candidate that maximizes proximity to a target corpus.
result_label: Through systematic automated and manual evaluation as well as a user study, we demonstrate that ParChoice significantly outperforms prior methods in its ability to retain semantic content.
result_label: Using state-of-the art deep learning author profiling tools, we additionally show that ParChoice accomplishes better imitation success than A$^4$NT, the state-of-the-art style imitation technique with the best semantic retainment.

===================================
paper_id: 56657855; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf - specter
TITLE: Symbolic inductive bias for visually grounded learning of spoken language
ABSTRACT: background_label: A widespread approach to processing spoken language is to first automatically transcribe it into text.
background_label: An alternative is to use an end-to-end approach: recent works have proposed to learn semantic embeddings of spoken language from images with spoken captions, without an intermediate transcription step.
objective_label: We propose to use multitask learning to exploit existing transcribed speech within the end-to-end setting.
method_label: We describe a three-task architecture which combines the objectives of matching spoken captions with corresponding images, speech with text, and text with images.
method_label: We show that the addition of the speech/text task leads to substantial performance improvements on image retrieval when compared to training the speech/image task in isolation.
result_label: We conjecture that this is due to a strong inductive bias transcribed speech provides to the model, and offer supporting evidence for this.

===================================
paper_id: 62612600; YEAR: 1995
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: The challenge of sociocybernetics
ABSTRACT: background_label: Summarizes some of the important concepts and developments in cybernetics and general systems theory, especially during the last two decades.
background_label: Shows how they can indeed be a challenge to sociological thinking.
method_label: Cybernetics is used here as an umbrella term for a great variety of related disciplines: general systems theory, information theory, system dynamics, dynamic systems theory, including catastrophe theory, chaos theory.
method_label: Also considers the emerging science of complexity, which includes neural networks, artificial intelligence and artificial life, and discusses the methodological drawbacks of secondorder cybernetics.

===================================
paper_id: 201125328; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: A Multi-Turn Emotionally Engaging Dialog Model
ABSTRACT: background_label: Open-domain dialog systems (also known as chatbots) have increasingly drawn attention in natural language processing.
background_label: Some of the recent work aims at incorporating affect information into sequence-to-sequence neural dialog modeling, making the response emotionally richer, while others use hand-crafted rules to determine the desired emotion response.
background_label: However, they do not explicitly learn the subtle emotional interactions captured in human dialogs.
objective_label: In this paper, we propose a multi-turn dialog system aimed at learning and generating emotional responses that so far only humans know how to do.
method_label: Compared with two baseline models, offline experiments show that our method performs the best in perplexity scores.
result_label: Further human evaluations confirm that our chatbot can keep track of the conversation context and generate emotionally more appropriate responses while performing equally well on grammar.

===================================
paper_id: 23163324; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Semantics derived automatically from language corpora contain human-like biases
ABSTRACT: background_label: Artificial intelligence and machine learning are in a period of astounding growth.
background_label: However, there are concerns that these technologies may be used, either with or without intention, to perpetuate the prejudice and unfairness that unfortunately characterizes many human institutions.
background_label: Here we show for the first time that human-like semantic biases result from the application of standard machine learning to ordinary language---the same sort of language humans are exposed to every day.
method_label: We replicate a spectrum of standard human biases as exposed by the Implicit Association Test and other well-known psychological studies.
method_label: We replicate these using a widely used, purely statistical machine-learning model---namely, the GloVe word embedding---trained on a corpus of text from the Web.
result_label: Our results indicate that language itself contains recoverable and accurate imprints of our historic biases, whether these are morally neutral as towards insects or flowers, problematic as towards race or gender, or even simply veridical, reflecting the {\em status quo} for the distribution of gender with respect to careers or first names.
result_label: These regularities are captured by machine learning along with the rest of semantics.
method_label: In addition to our empirical findings concerning language, we also contribute new methods for evaluating bias in text, the Word Embedding Association Test (WEAT) and the Word Embedding Factual Association Test (WEFAT).
result_label: Our results have implications not only for AI and machine learning, but also for the fields of psychology, sociology, and human ethics, since they raise the possibility that mere exposure to everyday language can account for the biases we replicate here.

===================================
paper_id: 20963738; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Edina: Building an Open Domain Socialbot with Self-dialogues
ABSTRACT: background_label: We present Edina, the University of Edinburgh's social bot for the Amazon Alexa Prize competition.
background_label: Edina is a conversational agent whose responses utilize data harvested from Amazon Mechanical Turk (AMT) through an innovative new technique we call self-dialogues.
background_label: These are conversations in which a single AMT Worker plays both participants in a dialogue.
background_label: Such dialogues are surprisingly natural, efficient to collect and reflective of relevant and/or trending topics.
method_label: These self-dialogues provide training data for a generative neural network as well as a basis for soft rules used by a matching score component.
method_label: Each match of a soft rule against a user utterance is associated with a confidence score which we show is strongly indicative of reply quality, allowing this component to self-censor and be effectively integrated with other components.
method_label: Edina's full architecture features a rule-based system backing off to a matching score, backing off to a generative neural network.
result_label: Our hybrid data-driven methodology thus addresses both coverage limitations of a strictly rule-based approach and the lack of guarantees of a strictly machine-learning approach.

===================================
paper_id: 3257353; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: That's So Annoying!!!: A Lexical and Frame-Semantic Embedding Based Data Augmentation Approach to Automatic Categorization of Annoying Behaviors using #petpeeve Tweets
ABSTRACT: objective_label: We propose a novel data augmentation approach to enhance computational behavioral analysis using social media text.
method_label: In particular, we collect a Twitter corpus of the descriptions of annoying behaviors using the #petpeeve hashtags.
method_label: In the qualitative analysis, we study the language use in these tweets, with a special focus on the fine-grained categories and the geographic variation of the language.
result_label: In quantitative analysis, we show that lexical and syntactic features are useful for automatic categorization of annoying behaviors, and frame-semantic features further boost the performance; that leveraging large lexical embeddings to create additional training instances significantly improves the lexical model; and incorporating frame-semantic embedding achieves the best overall performance.

===================================
paper_id: 52982926; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Discursive Landscapes and Unsupervised Topic Modeling in IR: A Validation of Text-As-Data Approaches through a New Corpus of UN Security Council Speeches on Afghanistan
ABSTRACT: background_label: The recent turn towards quantitative text-as-data approaches in IR brought new ways to study the discursive landscape of world politics.
background_label: Here seen as complementary to qualitative approaches, quantitative assessments have the advantage of being able to order and make comprehensible vast amounts of text.
background_label: However, the validity of unsupervised methods applied to the types of text available in large quantities needs to be established before they can speak to other studies relying on text and discourse as data.
objective_label: In this paper, we introduce a new text corpus of United Nations Security Council (UNSC) speeches on Afghanistan between 2001 and 2017; we study this corpus through unsupervised topic modeling (LDA) with the central aim to validate the topic categories that the LDA identifies; and we discuss the added value, and complementarity, of quantitative text-as-data approaches.
method_label: We set-up two tests using mixed- method approaches.
method_label: Firstly, we evaluate the identified topics by assessing whether they conform with previous qualitative work on the development of the situation in Afghanistan.
method_label: Secondly, we use network analysis to study the underlying social structures of what we will call 'speaker-topic relations' to see whether they correspondent to know divisions and coalitions in the UNSC.
result_label: In both cases we find that the unsupervised LDA indeed provides valid and valuable outputs.
result_label: In addition, the mixed-method approaches themselves reveal interesting patterns deserving future qualitative research.
result_label: Amongst these are the coalition and dynamics around the 'women and human rights' topic as part of the UNSC debates on Afghanistan.

===================================
paper_id: 52802182; YEAR: 2000
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidf
TITLE: Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech
ABSTRACT: background_label: We describe a statistical approach for modeling dialogue acts in conversational speech, i.e., speech-act-like units such as Statement, Question, Backchannel, Agreement, Disagreement, and Apology.
method_label: Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence.
method_label: The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states.
method_label: Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram.
method_label: The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act.
method_label: We develop a probabilistic integration of speech recognition with dialogue modeling, to improve both speech recognition and dialogue act classification accuracy.
method_label: Models are trained and evaluated using a large hand-labeled database of 1,155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech.
result_label: We achieved good dialogue act labeling accuracy (65% based on errorful, automatically recognized words and prosody, and 71% based on word transcripts, compared to a chance baseline accuracy of 35% and human accuracy of 84%) and a small reduction in word recognition error.

===================================
paper_id: 2055258; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Facilitating Development of Pragmatic Competence through a Voice-driven Video Learning Interface
ABSTRACT: background_label: Authentic foreign language videos are effective for developing pragmatic competence, or sensitivity to meanings expressed by tone and word choice, and the ability to effectively express these meanings.
background_label: However, established methods for learning from foreign language videos are primarily text-based (e.g.captioning).
background_label: Using text, learners do not practice aspects of oral performance (e.g.
background_label: intonation, pausing, and pitch) that are important to pragmatic competence.
method_label: In this paper we present a voice-driven system where learners practice and learn a foreign language by repeating phrases out loud from any video.
method_label: Utterances are transcribed and translated and, if captions are available, the system indicates the correctness of the utterance.
result_label: In an evaluation with 27 participants, we show that participants more frequently used the voice-driven system than a comparison text-based system.
result_label: Furthermore, ina field study of 130 independent learners, we show potential for community-driven resource collection.

===================================
paper_id: 14199015; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Semantics derived automatically from language corpora necessarily contain human biases
ABSTRACT: background_label: ABSTRACTArtificial intelligence and machine learning are in a period of astounding growth.
background_label: However, there are concerns that these technologies may be used, either with or without intention, to perpetuate the prejudice and unfairness that unfortunately characterizes many human institutions.
background_label: Here we show for the first time that human-like semantic biases result from the application of standard machine learning to ordinary language-the same sort of language humans are exposed to every day.
method_label: We replicate a spectrum of standard human biases as exposed by the Implicit Association Test and other well-known psychological studies.
method_label: We replicate these using a widely used, purely statistical machine-learning model-namely, the GloVe word embedding-trained on a corpus of text from the Web.
result_label: Our results indicate that language itself contains recoverable and accurate imprints of our historic biases, whether these are morally neutral as towards insects or flowers, problematic as towards race or gender, or even simply veridical, reflecting the status quo for the distribution of gender with respect to careers or first names.
result_label: These regularities are captured by machine learning along with the rest of semantics.
method_label: In addition to our empirical findings concerning language, we also contribute new methods for evaluating bias in text, the Word Embedding Association Test (WEAT) and the Word Embedding Factual Association Test (WEFAT).
result_label: Our results have implications not only for AI and machine learning, but also for the fields of psychology, sociology, and human ethics, since they raise the possibility that mere exposure to everyday language can account for the biases we replicate here.

===================================
paper_id: 13389019; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf - specter
TITLE: Semi-supervised learning of dialogue acts using sentence similarity based on word embeddings
ABSTRACT: background_label: This paper describes a methodology for semi-supervised learning of dialogue acts using the similarity between sentences.
background_label: We suppose that the dialogue sentences with the same dialogue act are more similar in terms of semantic and syntactic information.
background_label: However, previous work on sentence similarity mainly modeled a sentence as bag-of-words and then compared different groups of words using corpus-based or knowledge-based measurements of word semantic similarity.
method_label: Novelly, we present a vector-space sentence representation, composed of word embeddings, that is, the related word distributed representations, and these word embeddings are organised in a sentence syntactic structure.
method_label: Given the vectors of the dialogue sentences, a distance measurement can be well-defined to compute the similarity between them.
method_label: Finally, a seeded k-means clustering algorithm is implemented to classify the dialogue sentences into several categories corresponding to particular dialogue acts.
method_label: This constitutes the semi-supervised nature of the approach, which aims to ameliorate the reliance of the availability of annotated corpora.
result_label: Experiments with Switchboard Dialog Act corpus show that classification accuracy is improved by 14%, compared to the state-of-art methods based on Support Vector Machine.

===================================
paper_id: 102353817; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations
ABSTRACT: background_label: By design, word embeddings are unable to model the dynamic nature of words' semantics, i.e., the property of words to correspond to potentially different meanings.
background_label: To address this limitation, dozens of specialized meaning representation techniques such as sense or contextualized embeddings have been proposed.
background_label: However, despite the popularity of research on this topic, very few evaluation benchmarks exist that specifically focus on the dynamic semantics of words.
method_label: In this paper we show that existing models have surpassed the performance ceiling of the standard evaluation dataset for the purpose, i.e., Stanford Contextual Word Similarity, and highlight its shortcomings.
method_label: To address the lack of a suitable benchmark, we put forward a large-scale Word in Context dataset, called WiC, based on annotations curated by experts, for generic evaluation of context-sensitive representations.
other_label: WiC is released in https://pilehvar.github.io/wic/.

===================================
paper_id: 33749311; YEAR: 1977
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Data Space Animation for Learning the Semantics of C + + Pointers
ABSTRACT: background_label: We incorporated animation of the data space into a web-based tutor for solving problems on C++ pointers and made the tutor available to students.
result_label: In evaluation of the tutor, we found that data space animation indeed helps students learn the semantics of pointers.
result_label: But, it is no more effective at this than text explanation of the step-by-step execution of the program.

===================================
paper_id: 17050614; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200 - specter
TITLE: The Generation of Textual Entailment with NLML in an Intelligent Dialogue system for Language Learning CSIEC
ABSTRACT: background_label: This research report introduces the generation of textual entailment within the project CSIEC (Computer Simulation in Educational Communication), an interactive web-based human-computer dialogue system with natural language for English instruction.
background_label: The generation of textual entailment (GTE) is critical to the further improvement of CSIEC project.
background_label: Up to now we have found few literatures related with GTE.
method_label: Simulating the process that a human being learns English as a foreign language we explore our naive approach to tackle the GTE problem and its algorithm within the framework of CSIEC, i.e.
method_label: rule annotation in NLML, pattern recognition (matching), and entailment transformation.
method_label: The time and space complexity of our algorithm is tested with some entailment examples.
result_label: Further works include the rules annotation based on the English textbooks and a GUI interface for normal users to edit the entailment rules.

===================================
paper_id: 24551110; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: The CLIN27 Shared Task: Translating Historical Text to Contemporary Language for Improving Automatic Linguistic Annotation
ABSTRACT: objective_label: The CLIN27 shared task evaluates the effect of translating historical text to modern text with the goal of improving the quality of the output of contemporary natural language processing tools applied to the text.
objective_label: We focus on improving part-of-speech tagging analysis of seventeenth-century Dutch.
method_label: Eight teams took part in the shared task.
result_label: The best results were obtained by teams employing character-based machine translation.
result_label: The best system obtained an error reduction of 51% in comparison with the baseline of tagging unmodified text.
result_label: This is close to the error reduction obtained by human translation (57%).

===================================
paper_id: 3461974; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidf
TITLE: Generative Models of Visually Grounded Imagination
ABSTRACT: background_label: It is easy for people to imagine what a man with pink hair looks like, even if they have never seen such a person before.
background_label: We call the ability to create images of novel semantic concepts visually grounded imagination.
method_label: In this paper, we show how we can modify variational auto-encoders to perform this task.
method_label: Our method uses a novel training objective, and a novel product-of-experts inference network, which can handle partially specified (abstract) concepts in a principled and efficient way.
method_label: We also propose a set of easy-to-compute evaluation metrics that capture our intuitive notions of what it means to have good visual imagination, namely correctness, coverage, and compositionality (the 3 C's).
method_label: Finally, we perform a detailed comparison of our method with two existing joint image-attribute VAE methods (the JMVAE method of Suzuki et.al.
method_label: and the BiVCCA method of Wang et.al.)
method_label: by applying them to two datasets: the MNIST-with-attributes dataset (which we introduce here), and the CelebA dataset.

===================================
paper_id: 41759879; YEAR: 2000
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Personalized courseware construction based on Web data mining
ABSTRACT: method_label: In order to adapt the teaching in accordance to an individual student's ability in a distance learning environment, a method to construct personalized courseware is proposed by building a personalized Web tutor tree and mining both context and structure of the courseware.
method_label: The concept of Web tutor objects and the notion of similarity are proposed.
result_label: Five algorithms, including Naive Algorithm for tutor topic tree and Level-generate Algorithm to generate a Web tutor topic of K+1 levels, and the experimental results are presented.

===================================
paper_id: 11709892; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Codeopticon: Real-Time, One-To-Many Human Tutoring for Computer Programming
ABSTRACT: background_label: One-on-one tutoring from a human expert is an effective way for novices to overcome learning barriers in complex domains such as computer programming.
background_label: But there are usually far fewer experts than learners.
objective_label: To enable a single expert to help more learners at once, we built Codeopticon, an interface that enables a programming tutor to monitor and chat with dozens of learners in real time.
method_label: Each learner codes in a workspace that consists of an editor, compiler, and visual debugger.
method_label: The tutor sees a real-time view of each learner's actions on a dashboard, with each learner's workspace summarized in a tile.
method_label: At a glance, the tutor can see how learners are editing and debugging their code, and what errors they are encountering.
method_label: The dashboard automatically reshuffles tiles so that the most active learners are always in the tutor's main field of view.
method_label: When the tutor sees that a particular learner needs help, they can open an embedded chat window to start a one-on-one conversation.
result_label: A user study showed that 8 first-time Codeopticon users successfully tutored anonymous learners from 54 countries in a naturalistic online setting.
result_label: On average, in a 30-minute session, each tutor monitored 226 learners, started 12 conversations, exchanged 47 chats, and helped 2.4 learners.

===================================
paper_id: 606669; YEAR: 2012
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Towards a Watson that sees: Language-guided action recognition for robots
ABSTRACT: background_label: For robots of the future to interact seamlessly with humans, they must be able to reason about their surroundings and take actions that are appropriate to the situation.
background_label: Such reasoning is only possible when the robot has knowledge of how the World functions, which must either be learned or hard-coded.
objective_label: In this paper, we propose an approach that exploits language as an important resource of high-level knowledge that a robot can use, akin to IBM's Watson in Jeopardy!.
objective_label: In particular, we show how language can be leveraged to reduce the ambiguity that arises from recognizing actions involving hand-tools from video data.
method_label: Starting from the premise that tools and actions are intrinsically linked, with one explaining the existence of the other, we trained a language model over a large corpus of English newswire text so that we can extract this relationship directly.
method_label: This model is then used as a prior to select the best tool and action that explains the video.
method_label: We formalize the approach in the context of 1) an unsupervised recognition and 2) a supervised classification scenario by an EM formulation for the former and integrating language features for the latter.
result_label: Results are validated over a new hand-tool action dataset, and comparisons with state of the art STIP features showed significantly improved results when language is used.
result_label: In addition, we discuss the implications of these results and how it provides a framework for integrating language into vision on other robotic applications.

===================================
paper_id: 30758763; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200
TITLE: The RepEval 2017 Shared Task: Multi-Genre Natural Language Inference with Sentence Representations
ABSTRACT: background_label: This paper presents the results of the RepEval 2017 Shared Task, which evaluated neural network sentence representation learning models on the Multi-Genre Natural Language Inference corpus (MultiNLI) recently introduced by Williams et al.
background_label: (2017).
background_label: All of the five participating teams beat the bidirectional LSTM (BiLSTM) and continuous bag of words baselines reported in Williams et al..
method_label: The best single model used stacked BiLSTMs with residual connections to extract sentence features and reached 74.5% accuracy on the genre-matched test set.
result_label: Surprisingly, the results of the competition were fairly consistent across the genre-matched and genre-mismatched test sets, and across subsets of the test data representing a variety of linguistic phenomena, suggesting that all of the submitted systems learned reasonably domain-independent representations for sentence meaning.

===================================
paper_id: 4236207; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Robots Show Us How to Teach Them: Feedback from Robots Shapes Tutoring Behavior during Action Learning
ABSTRACT: background_label: Robot learning by imitation requires the detection of a tutor's action demonstration and its relevant parts.
background_label: Current approaches implicitly assume a unidirectional transfer of knowledge from tutor to learner.
background_label: The presented work challenges this predominant assumption based on an extensive user study with an autonomously interacting robot.
method_label: We show that by providing feedback, a robot learner influences the human tutor's movement demonstrations in the process of action learning.
result_label: We argue that the robot's feedback strongly shapes how tutors signal what is relevant to an action and thus advocate a paradigm shift in robot action learning research toward truly interactive systems learning in and benefiting from interaction.

===================================
paper_id: 196176000; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_cbow200
TITLE: OpenDialKG: Explainable Conversational Reasoning with Attention-based Walks over Knowledge Graphs
ABSTRACT: background_label: AbstractWe study a conversational reasoning model that strategically traverses through a largescale common fact knowledge graph (KG) to introduce engaging and contextually diverse entities and attributes.
method_label: For this study, we collect a new Open-ended Dialog  KG parallel corpus called OpenDialKG, where each utterance from 15K human-to-human roleplaying dialogs is manually annotated with ground-truth reference to corresponding entities and paths from a large-scale KG with 1M+ facts.
method_label: We then propose the DialKG Walker model that learns the symbolic transitions of dialog contexts as structured traversals over KG, and predicts natural entities to introduce given previous dialog contexts via a novel domain-agnostic, attention-based graph path decoder.
result_label: Automatic and human evaluations show that our model can retrieve more natural and human-like responses than the state-ofthe-art baselines or rule-based models, in both in-domain and cross-domain tasks.
result_label: The proposed model also generates a KG walk path for each entity retrieved, providing a natural way to explain conversational reasoning.

===================================
paper_id: 52815560; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task
ABSTRACT: background_label: We present Spider, a large-scale, complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 college students.
background_label: It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables, covering 138 different domains.
method_label: We define a new complex and cross-domain semantic parsing and text-to-SQL task where different complex SQL queries and databases appear in train and test sets.
method_label: In this way, the task requires the model to generalize well to both new SQL queries and new database schemas.
method_label: Spider is distinct from most of the previous semantic parsing tasks because they all use a single database and the exact same programs in the train set and the test set.
result_label: We experiment with various state-of-the-art models and the best model achieves only 12.4% exact matching accuracy on a database split setting.
result_label: This shows that Spider presents a strong challenge for future research.
other_label: Our dataset and task are publicly available at https://yale-lily.github.io/spider

===================================
paper_id: 18808329; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: SimpleDS: A Simple Deep Reinforcement Learning Dialogue System
ABSTRACT: background_label: This paper presents 'SimpleDS', a simple and publicly available dialogue system trained with deep reinforcement learning.
method_label: In contrast to previous reinforcement learning dialogue systems, this system avoids manual feature engineering by performing action selection directly from raw text of the last system and (noisy) user responses.
result_label: Our initial results, in the restaurant domain, show that it is indeed possible to induce reasonable dialogue behaviour with an approach that aims for high levels of automation in dialogue control for intelligent interactive agents.

===================================
paper_id: 805082; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter - abs_tfidfcbow200
TITLE: Acquiring Word-Meaning Mappings for Natural Language Interfaces
ABSTRACT: objective_label: This paper focuses on a system, WOLFIE (WOrd Learning From Interpreted Examples), that acquires a semantic lexicon from a corpus of sentences paired with semantic representations.
background_label: The lexicon learned consists of phrases paired with meaning representations.
method_label: WOLFIE is part of an integrated system that learns to transform sentences into representations such as logical database queries.
result_label: Experimental results are presented demonstrating WOLFIE's ability to learn useful lexicons for a database interface in four different natural languages.
result_label: The usefulness of the lexicons learned by WOLFIE are compared to those acquired by a similar system, with results favorable to WOLFIE.
background_label: A second set of experiments demonstrates WOLFIE's ability to scale to larger and more difficult, albeit artificially generated, corpora.
background_label: In natural language acquisition, it is difficult to gather the annotated data needed for supervised learning; however, unannotated data is fairly plentiful.
method_label: Active learning methods attempt to select for annotation and training only the most informative examples, and therefore are potentially very useful in natural language applications.
method_label: However, most results to date for active learning have only considered standard classification tasks.
method_label: To reduce annotation effort while maintaining accuracy, we apply active learning to semantic lexicons.
result_label: We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance.

===================================
paper_id: 2835513; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Effective handling of dialogue state in the hidden information state POMDP-based dialogue manager
ABSTRACT: background_label: Effective dialogue management is critically dependent on the information that is encoded in the dialogue state.
background_label: In order to deploy reinforcement learning for policy optimization, dialogue must be modeled as a Markov Decision Process.
background_label: This requires that the dialogue state must encode all relevent information obtained during the dialogue prior to that state.
background_label: This can be achieved by combining the user goal, the dialogue history, and the last user action to form the dialogue state.
method_label: In addition, to gain robustness to input errors, dialogue must be modeled as a Partially Observable Markov Decision Process (POMDP) and hence, a distribution over all possible states must be maintained at every dialogue turn.
background_label: This poses a potential computational limitation since there can be a very large number of dialogue states.
method_label: The Hidden Information State model provides a principled way of ensuring tractability in a POMDP-based dialogue model.
method_label: The key feature of this model is the grouping of user goals into partitions that are dynamically built during the dialogue.
method_label: In this article, we extend this model further to incorporate the notion of complements.
method_label: This allows for a more complex user goal to be represented, and it enables an effective pruning technique to be implemented that preserves the overall system performance within a limited computational resource more effectively than existing approaches.

===================================
paper_id: 201646065; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: Don't paraphrase, detect! Rapid and Effective Data Collection for Semantic Parsing
ABSTRACT: background_label: A major hurdle on the road to conversational interfaces is the difficulty in collecting data that maps language utterances to logical forms.
background_label: One prominent approach for data collection has been to automatically generate pseudo-language paired with logical forms, and paraphrase the pseudo-language to natural language through crowdsourcing (Wang et al., 2015).
background_label: However, this data collection procedure often leads to low performance on real data, due to a mismatch between the true distribution of examples and the distribution induced by the data collection procedure.
method_label: In this paper, we thoroughly analyze two sources of mismatch in this process: the mismatch in logical form distribution and the mismatch in language distribution between the true and induced distributions.
method_label: We quantify the effects of these mismatches, and propose a new data collection approach that mitigates them.
method_label: Assuming access to unlabeled utterances from the true distribution, we combine crowdsourcing with a paraphrase model to detect correct logical forms for the unlabeled utterances.
result_label: On two datasets, our method leads to 70.6 accuracy on average on the true distribution, compared to 51.3 in paraphrasing-based data collection.

===================================
paper_id: 1630355; YEAR: 2005
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - title_tfidf - abs_tfidf - title_tfidfcbow200 - title_cbow200 - abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Human-computer dialogue simulation using hidden Markov models
ABSTRACT: objective_label: This paper presents a probabilistic method to simulate task-oriented human-computer dialogues at the intention level, that may be used to improve or to evaluate the performance of spoken dialogue systems.
method_label: Our method uses a network of hidden Markov models (HMMs) to predict system and user intentions, where a "language model" predicts sequences of goals and the component HMMs predict sequences of intentions.
method_label: We compare standard HMMs, input HMMs and input-output HMMs in an effort to better predict sequences of intentions.
method_label: In addition, we propose a dialogue similarity measure to evaluate the realism of the simulated dialogues.
result_label: We performed experiments using the DARPA communicator corpora and report results with three different metrics: dialogue length, dialogue similarity and precision-recall

===================================
paper_id: 17842912; YEAR: 2005
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Improved identification of noun phrases in clinical radiology reports using a high-performance statistical natural language parser augmented with the UMLS specialist lexicon.
ABSTRACT: objective_label: OBJECTIVE The aim of this study was to develop and evaluate a method of extracting noun phrases with full phrase structures from a set of clinical radiology reports using natural language processing (NLP) and to investigate the effects of using the UMLS(R) Specialist Lexicon to improve noun phrase identification within clinical radiology documents.
method_label: DESIGN The noun phrase identification (NPI) module is composed of a sentence boundary detector, a statistical natural language parser trained on a nonmedical domain, and a noun phrase (NP) tagger.
method_label: The NPI module processed a set of 100 XML-represented clinical radiology reports in Health Level 7 (HL7)(R) Clinical Document Architecture (CDA)-compatible format.
result_label: Computed output was compared with manual markups made by four physicians and one author for maximal (longest) NP and those made by one author for base (simple) NP, respectively.
result_label: An extended lexicon of biomedical terms was created from the UMLS Specialist Lexicon and used to improve NPI performance.
background_label: RESULTS The test set was 50 randomly selected reports.
background_label: The sentence boundary detector achieved 99.0% precision and 98.6% recall.
background_label: The overall maximal NPI precision and recall were 78.9% and 81.5% before using the UMLS Specialist Lexicon and 82.1% and 84.6% after.
result_label: The overall base NPI precision and recall were 88.2% and 86.8% before using the UMLS Specialist Lexicon and 93.1% and 92.6% after, reducing false-positives by 31.1% and false-negatives by 34.3%.
result_label: CONCLUSION The sentence boundary detector performs excellently.
result_label: After the adaptation using the UMLS Specialist Lexicon, the statistical parser's NPI performance on radiology reports increased to levels comparable to the parser's native performance in its newswire training domain and to that reported by other researchers in the general nonmedical domain.

===================================
paper_id: 5345485; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Medical text simplification using synonym replacement: Adapting assessment of word difficulty to a compounding language
ABSTRACT: background_label: AbstractMedical texts can be difficult to understand for laymen, due to a frequent occurrence of specialised medical terms.
background_label: Replacing these difficult terms with easier synonyms can, however, lead to improved readability.
method_label: In this study, we have adapted a method for assessing difficulty of words to make it more suitable to medical Swedish.
method_label: The difficulty of a word was assessed not only by measuring the frequency of the word in a general corpus, but also by measuring the frequency of substrings of words, thereby adapting the method to the compounding nature of Swedish.
method_label: All words having a MeSH synonym that was assessed as easier, were replaced in a corpus of medical text.
result_label: According to the readability measure LIX, the replacement resulted in a slightly more difficult text, while the readability increased according to the OVIX measure and to a preliminary reader study.

===================================
paper_id: 84846745; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Russian Language Datasets in the Digitial Humanities Domain and Their Evaluation with Word Embeddings
ABSTRACT: background_label: In this paper, we present Russian language datasets in the digital humanities domain for the evaluation of word embedding techniques or similar language modeling and feature learning algorithms.
background_label: The datasets are split into two task types, word intrusion and word analogy, and contain 31362 task units in total.
method_label: The characteristics of the tasks and datasets are that they build upon small, domain-specific corpora, and that the datasets contain a high number of named entities.
method_label: The datasets were created manually for two fantasy novel book series ("A Song of Ice and Fire"and"Harry Potter").
result_label: We provide baseline evaluations with popular word embedding models trained on the book corpora for the given tasks, both for the Russian and English language versions of the datasets.
result_label: Finally, we compare and analyze the results and discuss specifics of Russian language with regards to the problem setting.

===================================
paper_id: 7324328; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Emotion Recognition from Text Based on Automatically Generated Rules
ABSTRACT: background_label: With the growth of the Internet community, textual data has proven to be the main tool of communication in human-machine and human-human interaction.
background_label: This communication is constantly evolving towards the goal of making it as human and real as possible.
objective_label: One way of humanizing such interaction is to provide a framework that can recognize the emotions present in the communication or the emotions of the involved users in order to enrich user experience.
method_label: For example, by providing insights to users for personal preferences and automated recommendations based on their emotional state.
objective_label: In this work, we propose a framework for emotion classification in English sentences where emotions are treated as generalized concepts extracted from the sentences.
method_label: We start by generating an intermediate emotional data representation of a given input sentence based on its syntactic and semantic structure.
method_label: We then generalize this representation using various ontologies such as Word Net and Concept Net, which results in an emotion seed that we call an emotion recognition rule (ERR).
method_label: Finally, we use a suite of classifiers to compare the generated ERR with a set of reference ERRs extracted from a training set in a similar fashion.
method_label: The used classifiers are k-nearest neighbors (KNN) with handcrafted similarity measure, Point Mutual Information (PMI), and PMI with Information Retrieval (PMI-IR).
result_label: When applied on different datasets, the proposed approach significantly outperformed the existing state-of-the art machine learning and rule-based classifiers with an average F-Score of 84%.

===================================
paper_id: 10444482; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Computational Model to Generate Case-Inflected Forms of Masculine Nouns for Word Search in Sanskrit E-Text
ABSTRACT: background_label: The problem of word search in Sanskrit is inseparable from complexities that include those caused by euphonic conjunctions and case-inflections.
background_label: The case-inflectional forms of a noun normally number 24 owing to the fact that in Sanskrit there are eight cases and three numbers-singular, dual and plural.
background_label: The traditional method of generating these inflectional forms is rather elaborate owing to the fact that there are differences in the forms generated between even very similar words and there are subtle nuances involved.
background_label: Further, it would be a cumbersome exercise to generate and search for 24 forms of a word during a word search in a large text, using the currently available case-inflectional form generators.
objective_label: This study presents a new approach to generating case-inflectional forms that is simpler to compute.
result_label: Further, an optimized model that is sufficient for generating only those word forms that are required in a word search and is more than 80% efficient compared to the complete case-inflectional forms generator, is presented in this study for the first time.

===================================
paper_id: 28031850; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: A Preliminary Study for Building an Arabic Corpus of Pair Questions-Texts from the Web: AQA-Webcorp
ABSTRACT: background_label: With the development of electronic media and the heterogeneity of Arabic data on the Web, the idea of building a clean corpus for certain applications of natural language processing, including machine translation, information retrieval, question answer, become more and more pressing.
objective_label: In this manuscript, we seek to create and develop our own corpus of pair's questions-texts.
method_label: This constitution then will provide a better base for our experimentation step.
method_label: Thus, we try to model this constitution by a method for Arabic insofar as it recovers texts from the web that could prove to be answers to our factual questions.
method_label: To do this, we had to develop a java script that can extract from a given query a list of html pages.
method_label: Then clean these pages to the extent of having a data base of texts and a corpus of pair's question-texts.
result_label: In addition, we give preliminary results of our proposal method.
result_label: Some investigations for the construction of Arabic corpus are also presented in this document.

===================================
paper_id: 1224220; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes
ABSTRACT: objective_label: We propose a model to learn visually grounded word embeddings (vis-w2v) to capture visual notions of semantic relatedness.
background_label: While word embeddings trained using text have been extremely successful, they cannot uncover notions of semantic relatedness implicit in our visual world.
background_label: For instance, although"eats"and"stares at"seem unrelated in text, they share semantics visually.
background_label: When people are eating something, they also tend to stare at the food.
background_label: Grounding diverse relations like"eats"and"stares at"into vision remains challenging, despite recent progress in vision.
method_label: We note that the visual grounding of words depends on semantics, and not the literal pixels.
method_label: We thus use abstract scenes created from clipart to provide the visual grounding.
result_label: We find that the embeddings we learn capture fine-grained, visually grounded notions of semantic relatedness.
result_label: We show improvements over text-only word embeddings (word2vec) on three tasks: common-sense assertion classification, visual paraphrasing and text-based image retrieval.
other_label: Our code and datasets are available online.

===================================
paper_id: 59316969; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter - abs_cbow200
TITLE: Toward Unsupervised Text Content Manipulation
ABSTRACT: background_label: Controlled generation of text is of high practical use.
background_label: Recent efforts have made impressive progress in generating or editing sentences with given textual attributes (e.g., sentiment).
background_label: This work studies a new practical setting of text content manipulation.
objective_label: Given a structured record, such as `(PLAYER: Lebron, POINTS: 20, ASSISTS: 10)', and a reference sentence, such as `Kobe easily dropped 30 points', we aim to generate a sentence that accurately describes the full content in the record, with the same writing style (e.g., wording, transitions) of the reference.
method_label: The problem is unsupervised due to lack of parallel data in practice, and is challenging to minimally yet effectively manipulate the text (by rewriting/adding/deleting text portions) to ensure fidelity to the structured content.
method_label: We derive a dataset from a basketball game report corpus as our testbed, and develop a neural method with unsupervised competing objectives and explicit content coverage constraints.
result_label: Automatic and human evaluations show superiority of our approach over competitive methods including a strong rule-based baseline and prior approaches designed for style transfer.

===================================
paper_id: 197837520; YEAR: 1984
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Unspeakable sentences : narration and representation in the language of fiction
ABSTRACT: other_label: Preface Introduction 1.
background_label: The expression of subjectivity and the sentences of direct and indirect speech 2.
background_label: The sentence of represented speech and thought 3.
background_label: Communication and the sentence of discourse 4.
background_label: The sentences of narration and discourse 5.
method_label: The sentence representing non-reflective consciousness and the absence of the narrator 6.
other_label: The historical development of narrative style Conclusion: Narration and representation: the knowledge of the clock and the lens Notes Bibliography Name index Subject index

===================================
paper_id: 14875383; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - specter - abs_tfidfcbow200
TITLE: Stochastic Language Generation in Dialogue using Factored Language Models
ABSTRACT: background_label: Most previous work on trainable language generation has focused on two paradigms: (a) using a generation decisions of an existing generator.
background_label: Both approaches rely on the existence of a handcrafted generation component, which is likely to limit their scalability to new domains.
method_label: The first contribution of this article is to present Bagel, a fully data-driven generation method that treats the language generation task as a search for the most likely sequence of semantic concepts and realization phrases, according to Factored Language Models (FLMs).
method_label: As domain utterances are not readily available for most natural language generation tasks, a large creative effort is required to produce the data necessary to represent human linguistic variation for nontrivial domains.
method_label: This article is based on the assumption that learning to produce paraphrases can be facilitated by collecting data from a large sample of untrained annotators using crowdsourcingrather than a few domain expertsby relying on a coarse meaning representation.
result_label: A second contribution of this article is to use crowdsourced data to show how dialogue naturalness can be improved by learning to vary the output utterances generated for a given semantic input.
method_label: Two data-driven methods for generating paraphrases in dialogue are presented: (a) by sampling from the n-best list of realizations produced by Bagel's FLM reranker; and (b) by learning a structured perceptron predicting whether candidate realizations are valid paraphrases.
method_label: We train Bagel on a set of 1,956 utterances produced by 137 annotators, which covers 10 types of dialogue acts and 128 semantic concepts in a tourist information system for Cambridge.
result_label: An automated evaluation shows that Bagel outperforms utterance class LM baselines on this domain.
result_label: A human evaluation of 600 resynthesized dialogue extracts shows that Bagel's FLM output produces utterances comparable to a handcrafted baseline, whereas the perceptron classifier performs worse.
result_label: Interestingly, human judges find the system sampling from the n-best list to be more natural than a system always returning the first-best utterance.
result_label: The judges are also more willing to interact with the n-best system in the future.
result_label: These results suggest that capturing the large variation found in human language using data-driven methods is beneficial for dialogue interaction.

