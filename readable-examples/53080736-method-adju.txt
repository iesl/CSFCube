======================================================================
paper_id: 53080736; YEAR: 2018
TITLE: FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation
ABSTRACT: background_label: We present a Few-Shot Relation Classification Dataset (FewRel), consisting of 70, 000 sentences on 100 relations derived from Wikipedia and annotated by crowdworkers.
method_label: The relation of each sentence is first recognized by distant supervision methods, and then filtered by crowdworkers.
method_label: We adapt the most recent state-of-the-art few-shot learning methods for relation classification and conduct a thorough evaluation of these methods.
result_label: Empirical results show that even the most competitive few-shot learning models struggle on this task, especially as compared with humans.
result_label: We also show that a range of different reasoning skills are needed to solve our task.
result_label: These results indicate that few-shot relation classification remains an open problem and still requires further research.
result_label: Our detailed analysis points multiple directions for future research.
other_label: All details and resources about the dataset and baselines are released on http://zhuhao.me/fewrel.
===================================
paper_id: 1325997; YEAR: 2015
adju relevance: Similar (+2)
difference: 1; annotator1: 0; annotator2: 1
sources: title_tfidfcbow200 - title_cbow200
TITLE: Fine-grained Categorization and Dataset Bootstrapping using Deep Metric Learning with Humans in the Loop
ABSTRACT: background_label: Existing fine-grained visual categorization methods often suffer from three challenges: lack of training data, large number of fine-grained categories, and high intraclass vs. low inter-class variance.
objective_label: In this work we propose a generic iterative framework for fine-grained categorization and dataset bootstrapping that handles these three challenges.
method_label: Using deep metric learning with humans in the loop, we learn a low dimensional feature embedding with anchor points on manifolds for each category.
method_label: These anchor points capture intra-class variances and remain discriminative between classes.
method_label: In each round, images with high confidence scores from our model are sent to humans for labeling.
background_label: By comparing with exemplar images, labelers mark each candidate image as either a"true positive"or a"false positive".
method_label: True positives are added into our current dataset and false positives are regarded as"hard negatives"for our metric learning model.
method_label: Then the model is retrained with an expanded dataset and hard negatives for the next round.
method_label: To demonstrate the effectiveness of the proposed framework, we bootstrap a fine-grained flower dataset with 620 categories from Instagram images.
result_label: The proposed deep metric learning scheme is evaluated on both our dataset and the CUB-200-2001 Birds dataset.
result_label: Experimental evaluations show significant performance gain using dataset bootstrapping and demonstrate state-of-the-art results achieved by the proposed deep metric learning methods.

===================================
paper_id: 201667738; YEAR: 2019
adju relevance: Similar (+2)
difference: 1; annotator1: 1; annotator2: 2
sources: specter - abs_tfidf - title_tfidf
TITLE: Neural Snowball for Few-Shot Relation Learning
ABSTRACT: background_label: Knowledge graphs typically undergo open-ended growth of new relations.
background_label: This cannot be well handled by relation extraction that focuses on pre-defined relations with sufficient training data.
objective_label: To address new relations with few-shot instances, we propose a novel bootstrapping approach, Neural Snowball, to learn new relations by transferring semantic knowledge about existing relations.
method_label: More specifically, we design Relation Siamese Networks (RelSN) to learn the metric of relational similarities between instances based on existing relations and their labeled data.
method_label: Afterwards, given a new relation and its few-shot instances, we use RelSN to accumulate reliable instances from unlabeled corpora; these instances are used to train a relation classifier, which can further identify new facts of the new relation.
method_label: The process is conducted iteratively like a snowball.
result_label: Experiments show that our model can gather high-quality instances for better few-shot relation learning and achieves significant improvement compared to baselines.
result_label: Codes and datasets will be released soon.

===================================
paper_id: 3782112; YEAR: 2017
adju relevance: Similar (+2)
difference: 3; annotator1: 3; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Position-aware Attention and Supervised Data Improve Slot Filling
ABSTRACT: background_label: AbstractOrganized relational knowledge in the form of "knowledge graphs" is important for many applications.
background_label: However, the ability to populate knowledge bases with facts automatically extracted from documents has improved frustratingly slowly.
objective_label: This paper simultaneously addresses two issues that have held back prior work.
objective_label: We first propose an effective new model, which combines an LSTM sequence model with a form of entity position-aware attention that is better suited to relation extraction.
method_label: Then we build TACRED, a large (119,474 examples) supervised relation extraction dataset, obtained via crowdsourcing and targeted towards TAC KBP relations.
method_label: The combination of better supervised data and a more appropriate high-capacity model enables much better relation extraction performance.
result_label: When the model trained on this new dataset replaces the previous relation extraction component of the best TAC KBP 2015 slot filling system, its F 1 score increases markedly from 22.2% to 26.7%.

===================================
paper_id: 2386383; YEAR: 2010
adju relevance: Similar (+2)
difference: 0; annotator1: 2; annotator2: 2
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Modeling relations and their mentions without labeled text
ABSTRACT: other_label: Abstract.
background_label: Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision.
background_label: Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation.
objective_label: Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with.
method_label: We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB.
method_label: We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base.
result_label: When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction.

===================================
paper_id: 19100390; YEAR: 2018
adju relevance: Similar (+2)
difference: 3; annotator1: 2; annotator2: -1
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Reinforcement Learning for Relation Classification from Noisy Data
ABSTRACT: background_label: Existing relation classification methods that rely on distant supervision assume that a bag of sentences mentioning an entity pair are all describing a relation for the entity pair.
background_label: Such methods, performing classification at the bag level, cannot identify the mapping between a relation and a sentence, and largely suffers from the noisy labeling problem.
objective_label: In this paper, we propose a novel model for relation classification at the sentence level from noisy data.
method_label: The model has two modules: an instance selector and a relation classifier.
method_label: The instance selector chooses high-quality sentences with reinforcement learning and feeds the selected sentences into the relation classifier, and the relation classifier makes sentence level prediction and provides rewards to the instance selector.
method_label: The two modules are trained jointly to optimize the instance selection and relation classification processes.
result_label: Experiment results show that our model can deal with the noise of data effectively and obtains better performance for relation classification at the sentence level.

===================================
paper_id: 8317437; YEAR: 2015
adju relevance: Similar (+2)
difference: 1; annotator1: 0; annotator2: 1
sources: title_tfidfcbow200 - title_cbow200
TITLE: LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop
ABSTRACT: background_label: While there has been remarkable progress in the performance of visual recognition algorithms, the state-of-the-art models tend to be exceptionally data-hungry.
background_label: Large labeled training datasets, expensive and tedious to produce, are required to optimize millions of parameters in deep network models.
background_label: Lagging behind the growth in model capacity, the available datasets are quickly becoming outdated in terms of size and density.
objective_label: To circumvent this bottleneck, we propose to amplify human effort through a partially automated labeling scheme, leveraging deep learning with humans in the loop.
method_label: Starting from a large set of candidate images for each category, we iteratively sample a subset, ask people to label them, classify the others with a trained model, split the set into positives, negatives, and unlabeled based on the classification confidence, and then iterate with the unlabeled set.
method_label: To assess the effectiveness of this cascading procedure and enable further progress in visual recognition research, we construct a new image dataset, LSUN.
method_label: It contains around one million labeled images for each of 10 scene categories and 20 object categories.
result_label: We experiment with training popular convolutional networks and find that they achieve substantial performance gains when trained on this dataset.

===================================
paper_id: 44144625; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator1: 0; annotator2: 1
sources: specter
TITLE: Robust Distant Supervision Relation Extraction via Deep Reinforcement Learning
ABSTRACT: background_label: Distant supervision has become the standard method for relation extraction.
background_label: However, even though it is an efficient method, it does not come at no cost---The resulted distantly-supervised training samples are often very noisy.
background_label: To combat the noise, most of the recent state-of-the-art approaches focus on selecting one-best sentence or calculating soft attention weights over the set of the sentences of one specific entity pair.
background_label: However, these methods are suboptimal, and the false positive problem is still a key stumbling bottleneck for the performance.
background_label: We argue that those incorrectly-labeled candidate sentences must be treated with a hard decision, rather than being dealt with soft attention weights.
method_label: To do this, our paper describes a radical solution---We explore a deep reinforcement learning strategy to generate the false-positive indicator, where we automatically recognize false positives for each relation type without any supervised information.
method_label: Unlike the removal operation in the previous studies, we redistribute them into the negative examples.
result_label: The experimental results show that the proposed strategy significantly improves the performance of distant supervision comparing to state-of-the-art systems.

===================================
paper_id: 201645140; YEAR: 2019
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: specter - abs_tfidfcbow200 - abs_tfidf - title_tfidf
TITLE: Improving Few-shot Text Classification via Pretrained Language Representations
ABSTRACT: background_label: Text classification tends to be difficult when the data is deficient or when it is required to adapt to unseen classes.
background_label: In such challenging scenarios, recent studies have often used meta-learning to simulate the few-shot task, thus negating explicit common linguistic features across tasks.
background_label: Deep language representations have proven to be very effective forms of unsupervised pretraining, yielding contextualized features that capture linguistic properties and benefit downstream natural language understanding tasks.
background_label: However, the effect of pretrained language representation for few-shot learning on text classification tasks is still not well understood.
method_label: In this study, we design a few-shot learning model with pretrained language representations and report the empirical results.
method_label: We show that our approach is not only simple but also produces state-of-the-art performance on a well-studied sentiment classification dataset.
result_label: It can thus be further suggested that pretraining could be a promising solution for few shot learning of many other NLP tasks.
other_label: The code and the dataset to replicate the experiments are made available at https://github.com/zxlzr/FewShotNLP.

===================================
paper_id: 199442384; YEAR: 2019
adju relevance: Related (+1)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_cbow200
TITLE: Beyond English-Only Reading Comprehension: Experiments in Zero-Shot Multilingual Transfer for Bulgarian
ABSTRACT: background_label: Recently, reading comprehension models achieved near-human performance on large-scale datasets such as SQuAD, CoQA, MS Macro, RACE, etc.
background_label: This is largely due to the release of pre-trained contextualized representations such as BERT and ELMo, which can be fine-tuned for the target task.
background_label: Despite those advances and the creation of more challenging datasets, most of the work is still done for English.
objective_label: Here, we study the effectiveness of multilingual BERT fine-tuned on large-scale English datasets for reading comprehension (e.g., for RACE), and we apply it to Bulgarian multiple-choice reading comprehension.
method_label: We propose a new dataset containing 2,221 questions from matriculation exams for twelfth grade in various subjects -history, biology, geography and philosophy-, and 412 additional questions from online quizzes in history.
method_label: While the quiz authors gave no relevant context, we incorporate knowledge from Wikipedia, retrieving documents matching the combination of question + each answer option.
result_label: Moreover, we experiment with different indexing and pre-training strategies.
result_label: The evaluation results show accuracy of 42.23%, which is well above the baseline of 24.89%.

===================================
paper_id: 195717148; YEAR: 2003
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Kernel methods for relation extraction
ABSTRACT: background_label: We present an application of kernel methods to extracting relations from unstructured natural language sources.
method_label: We introduce kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels.
method_label: We use the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text.
result_label: We experimentally evaluate the proposed methods and compare them with feature-based learning algorithms, with promising results.

===================================
paper_id: 67855846; YEAR: 2019
adju relevance: Related (+1)
difference: 1; annotator1: 1; annotator2: 0
sources: abs_cbow200
TITLE: DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs
ABSTRACT: background_label: Reading comprehension has recently seen rapid progress, with systems matching humans on the most popular datasets for the task.
background_label: However, a large body of work has highlighted the brittleness of these systems, showing that there is much work left to be done.
background_label: We introduce a new English reading comprehension benchmark, DROP, which requires Discrete Reasoning Over the content of Paragraphs.
method_label: In this crowdsourced, adversarially-created, 96k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting).
method_label: These operations require a much more comprehensive understanding of the content of paragraphs than what was necessary for prior datasets.
method_label: We apply state-of-the-art methods from both the reading comprehension and semantic parsing literature on this dataset and show that the best systems only achieve 32.7% F1 on our generalized accuracy metric, while expert human performance is 96.0%.
result_label: We additionally present a new model that combines reading comprehension methods with simple numerical reasoning to achieve 47.0% F1.

===================================
paper_id: 397533; YEAR: 2016
adju relevance: Related (+1)
difference: 1; annotator1: 1; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Neural Relation Extraction with Selective Attention over Instances
ABSTRACT: background_label: AbstractDistant supervised relation extraction has been widely used to find novel relational facts from text.
background_label: However, distant supervision inevitably accompanies with the wrong labelling problem, and these noisy data will substantially hurt the performance of relation extraction.
objective_label: To alleviate this issue, we propose a sentence-level attention-based model for relation extraction.
method_label: In this model, we employ convolutional neural networks to embed the semantics of sentences.
method_label: Afterwards, we build sentence-level attention over multiple instances, which is expected to dynamically reduce the weights of those noisy instances.
result_label: Experimental results on real-world datasets show that, our model can make full use of all informative sentences and effectively reduce the influence of wrong labelled instances.
result_label: Our model achieves significant and consistent improvements on relation extraction as compared with baselines.
other_label: The source code of this paper can be obtained from https: //github.com/thunlp/NRE.

===================================
paper_id: 67749964; YEAR: 2019
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Adaptive Cross-Modal Few-Shot Learning
ABSTRACT: background_label: Metric-based meta-learning techniques have successfully been applied to few-shot classification problems.
objective_label: In this paper, we propose to leverage cross-modal information to enhance metric-based few-shot learning methods.
objective_label: Visual and semantic feature spaces have different structures by definition.
background_label: For certain concepts, visual features might be richer and more discriminative than text ones.
background_label: While for others, the inverse might be true.
method_label: Moreover, when the support from visual information is limited in image classification, semantic representations (learned from unsupervised text corpora) can provide strong prior knowledge and context to help learning.
method_label: Based on these two intuitions, we propose a mechanism that can adaptively combine information from both modalities according to new image categories to be learned.
method_label: Through a series of experiments, we show that by this adaptive combination of the two modalities, our model outperforms current uni-modality few-shot learning methods and modality-alignment methods by a large margin on all benchmarks and few-shot scenarios tested.
result_label: Experiments also show that our model can effectively adjust its focus on the two modalities.
result_label: The improvement in performance is particularly large when the number of shots is very small.

===================================
paper_id: 2778800; YEAR: 2015
adju relevance: Related (+1)
difference: 1; annotator1: 2; annotator2: 1
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks
ABSTRACT: background_label: Two problems arise when using distant supervision for relation extraction.
background_label: First, in this method, an already existing knowledge base is heuristically aligned to texts, and the alignment results are treated as labeled data.
background_label: However, the heuristic alignment can fail, resulting in wrong label problem.
background_label: In addition, in previous approaches, statistical models have typically been applied to ad hoc features.
background_label: The noise that originates from the feature extraction process can cause poor performance.
method_label: In this paper, we propose a novel model dubbed the Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address these two problems.
method_label: To solve the first problem, distant supervised relation extraction is treated as a multi-instance problem in which the uncertainty of instance labels is taken into account.
method_label: To address the latter problem, we avoid feature engineering and instead adopt convolutional architecture with piecewise max pooling to automatically learn relevant features.
result_label: Experiments show that our method is effective and outperforms several competitive baseline methods.

===================================
paper_id: 44098963; YEAR: 2018
adju relevance: Related (+1)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidf - specter - title_tfidf
TITLE: Object-Level Representation Learning for Few-Shot Image Classification
ABSTRACT: background_label: Few-shot learning that trains image classifiers over few labeled examples per category is a challenging task.
objective_label: In this paper, we propose to exploit an additional big dataset with different categories to improve the accuracy of few-shot learning over our target dataset.
method_label: Our approach is based on the observation that images can be decomposed into objects, which may appear in images from both the additional dataset and our target dataset.
method_label: We use the object-level relation learned from the additional dataset to infer the similarity of images in our target dataset with unseen categories.
method_label: Nearest neighbor search is applied to do image classification, which is a non-parametric model and thus does not need fine-tuning.
result_label: We evaluate our algorithm on two popular datasets, namely Omniglot and MiniImagenet.
result_label: We obtain 8.5\% and 2.7\% absolute improvements for 5-way 1-shot and 5-way 5-shot experiments on MiniImagenet, respectively.
result_label: Source code will be published upon acceptance.

===================================
paper_id: 173990853; YEAR: 2019
adju relevance: Related (+1)
difference: 1; annotator1: 0; annotator2: 1
sources: title_tfidf - specter - abs_tfidf
TITLE: Learning to Self-Train for Semi-Supervised Few-Shot Classification
ABSTRACT: background_label: Few-shot classification (FSC) is challenging due to the scarcity of labeled training data (e.g.
background_label: only one labeled data point per class).
background_label: Meta-learning has shown to achieve promising results by learning to initialize a classification model for FSC.
method_label: In this paper we propose a novel semi-supervised meta-learning method called learning to self-train (LST) that leverages unlabeled data and specifically meta-learns how to cherry-pick and label such unsupervised data to further improve performance.
method_label: To this end, we train the LST model through a large number of semi-supervised few-shot tasks.
method_label: On each task, we train a few-shot model to predict pseudo labels for unlabeled data, and then iterate the self-training steps on labeled and pseudo-labeled data with each step followed by fine-tuning.
method_label: We additionally learn a soft weighting network (SWN) to optimize the self-training weights of pseudo labels so that better ones can contribute more to gradient descent optimization.
result_label: We evaluate our LST method on two ImageNet benchmarks for semi-supervised few-shot classification and achieve large improvements over the state-of-the-art method.
other_label: Code is at https://github.com/xinzheli1217/learning-to-self-train.

===================================
paper_id: 5869747; YEAR: 2012
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Multi-instance Multi-label Learning for Relation Extraction
ABSTRACT: background_label: AbstractDistant supervision for relation extraction (RE) -gathering training data by aligning a database of facts with text -is an efficient approach to scale RE to thousands of different relations.
background_label: However, this introduces a challenging learning scenario where the relation expressed by a pair of entities found in a sentence is unknown.
background_label: For example, a sentence containing Balzac and France may express BornIn or Died, an unknown relation, or no relation at all.
background_label: Because of this, traditional supervised learning, which assumes that each example is explicitly mapped to a label, is not appropriate.
method_label: We propose a novel approach to multi-instance multi-label learning for RE, which jointly models all the instances of a pair of entities in text and all their labels using a graphical model with latent variables.
result_label: Our model performs competitively on two difficult domains.

===================================
paper_id: 34190303; YEAR: 2017
adju relevance: Related (+1)
difference: 1; annotator1: 1; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Adversarial Training for Relation Extraction
ABSTRACT: background_label: AbstractAdversarial training is a mean of regularizing classification algorithms by generating adversarial noise to the training data.
method_label: We apply adversarial training in relation extraction within the multi-instance multi-label learning framework.
method_label: We evaluate various neural network architectures on two different datasets.
result_label: Experimental results demonstrate that adversarial training is generally effective for both CNN and RNN models and significantly improves the precision of predicted relations.

===================================
paper_id: 202540839; YEAR: 2019
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: abs_cbow200 - abs_tfidfcbow200 - specter - abs_tfidf
TITLE: Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach
ABSTRACT: background_label: Zero-shot text classification (0Shot-TC) is a challenging NLU problem to which little attention has been paid by the research community.
background_label: 0Shot-TC aims to associate an appropriate label with a piece of text, irrespective of the text domain and the aspect (e.g., topic, emotion, event, etc.)
background_label: described by the label.
background_label: And there are only a few articles studying 0Shot-TC, all focusing only on topical categorization which, we argue, is just the tip of the iceberg in 0Shot-TC.
background_label: In addition, the chaotic experiments in literature make no uniform comparison, which blurs the progress.
method_label: This work benchmarks the 0Shot-TC problem by providing unified datasets, standardized evaluations, and state-of-the-art baselines.
method_label: Our contributions include: i) The datasets we provide facilitate studying 0Shot-TC relative to conceptually different and diverse aspects: the ``topic'' aspect includes ``sports'' and ``politics'' as labels; the ``emotion'' aspect includes ``joy'' and ``anger''; the ``situation'' aspect includes ``medical assistance'' and ``water shortage''.
method_label: ii) We extend the existing evaluation setup (label-partially-unseen) -- given a dataset, train on some labels, test on all labels -- to include a more challenging yet realistic evaluation label-fully-unseen 0Shot-TC (Chang et al., 2008), aiming at classifying text snippets without seeing task specific training data at all.
method_label: iii) We unify the 0Shot-TC of diverse aspects within a textual entailment formulation and study it this way.
other_label: Code&Data: https://github.com/yinwenpeng/BenchmarkingZeroShot

===================================
paper_id: 195218732; YEAR: 2019
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: abs_tfidfcbow200 - abs_tfidf
TITLE: Few-Shot Sequence Labeling with Label Dependency Transfer and Pair-wise Embedding
ABSTRACT: background_label: While few-shot classification has been widely explored with similarity based methods, few-shot sequence labeling poses a unique challenge as it also calls for modeling the label dependencies.
objective_label: To consider both the item similarity and label dependency, we propose to leverage the conditional random fields (CRFs) in few-shot sequence labeling.
method_label: It calculates emission score with similarity based methods and obtains transition score with a specially designed transfer mechanism.
method_label: When applying CRF in the few-shot scenarios, the discrepancy of label sets among different domains makes it hard to use the label dependency learned in prior domains.
method_label: To tackle this, we introduce the dependency transfer mechanism that transfers abstract label transition patterns.
method_label: In addition, the similarity methods rely on the high quality sample representation, which is challenging for sequence labeling, because sense of a word is different when measuring its similarity to words in different sentences.
method_label: To remedy this, we take advantage of recent contextual embedding technique, and further propose a pair-wise embedder.
method_label: It provides additional certainty for word sense by embedding query and support sentence pairwisely.
result_label: Experimental results on slot tagging and named entity recognition show that our model significantly outperforms the strongest few-shot learning baseline by 11.76 (21.2%) and 12.18 (97.7%) F1 scores respectively in the one-shot setting.

===================================
paper_id: 3406403; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: title_tfidf - abs_tfidf
TITLE: Few-shot learning for short text classification
ABSTRACT: background_label: Due to the limited length and freely constructed sentence structures, it is a difficult classification task for short text classification.
objective_label: In this paper, a short text classification framework based on Siamese CNNs and few-shot learning is proposed.
method_label: The Siamese CNNs will learn the discriminative text encoding so as to help classifiers distinguish those obscure or informal sentence.
method_label: The different sentence structures and different descriptions of a topic are viewed as ‘prototypes’, which will be learned by few-shot learning strategy to improve the classifier’s generalization.
result_label: Our experimental results show that the proposed framework leads to better results in accuracies on twitter classifications and outperforms some popular traditional text classification methods and a few deep network approaches.

===================================
paper_id: 16483125; YEAR: 2011
adju relevance: Related (+1)
difference: 1; annotator1: 1; annotator2: 2
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations
ABSTRACT: background_label: AbstractInformation extraction (IE) holds the promise of generating a large-scale knowledge base from the Web's natural language text.
background_label: Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors.
background_label: Recently, researchers have developed multiinstance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint -for example they cannot extract the pair Founded(Jobs, Apple) and CEO-of(Jobs, Apple).
method_label: This paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts.
method_label: We apply our model to learn extractors for NY Times text using weak supervision from Freebase.
result_label: Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level.

===================================
paper_id: 4412459; YEAR: 2017
adju relevance: Related (+1)
difference: 1; annotator1: 1; annotator2: 2
sources: abs_tfidf - abs_tfidfcbow200 - specter - title_tfidf
TITLE: Learning to Compare: Relation Network for Few-Shot Learning
ABSTRACT: background_label: We present a conceptually simple, flexible, and general framework for few-shot learning, where a classifier must learn to recognise new classes given only few examples from each.
method_label: Our method, called the Relation Network (RN), is trained end-to-end from scratch.
method_label: During meta-learning, it learns to learn a deep distance metric to compare a small number of images within episodes, each of which is designed to simulate the few-shot setting.
method_label: Once trained, a RN is able to classify images of new classes by computing relation scores between query images and the few examples of each new class without further updating the network.
method_label: Besides providing improved performance on few-shot learning, our framework is easily extended to zero-shot learning.
result_label: Extensive experiments on five benchmarks demonstrate that our simple approach provides a unified and effective approach for both of these two tasks.

===================================
paper_id: 4797043; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: title_tfidf - abs_tfidfcbow200 - abs_cbow200 - specter - abs_tfidf
TITLE: A Large-scale Attribute Dataset for Zero-shot Learning
ABSTRACT: objective_label: Zero-Shot Learning (ZSL) has attracted huge research attention over the past few years; it aims to learn the new concepts that have never been seen before.
method_label: In classical ZSL algorithms, attributes are introduced as the intermediate semantic representation to realize the knowledge transfer from seen classes to unseen classes.
background_label: Previous ZSL algorithms are tested on several benchmark datasets annotated with attributes.
background_label: However, these datasets are defective in terms of the image distribution and attribute diversity.
result_label: In addition, we argue that the"co-occurrence bias problem"of existing datasets, which is caused by the biased co-occurrence of objects, significantly hinders models from correctly learning the concept.
result_label: To overcome these problems, we propose a Large-scale Attribute Dataset (LAD).
background_label: Our dataset has 78,017 images of 5 super-classes, 230 classes.
background_label: The image number of LAD is larger than the sum of the four most popular attribute datasets.
background_label: 359 attributes of visual, semantic and subjective properties are defined and annotated in instance-level.
method_label: We analyze our dataset by conducting both supervised learning and zero-shot learning tasks.
method_label: Seven state-of-the-art ZSL algorithms are tested on this new dataset.
result_label: The experimental results reveal the challenge of implementing zero-shot learning on our dataset.

===================================
paper_id: 10084087; YEAR: 2009
adju relevance: Related (+1)
difference: 1; annotator1: 1; annotator2: 2
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Coupling Semi-Supervised Learning of Categories and Relations
ABSTRACT: background_label: We consider semi-supervised learning of information extraction methods, especially for extracting instances of noun categories (e.g., 'athlete', 'team') and relations (e.g., 'playsForTeam(athlete, team)').
background_label: Semi-supervised approaches using a small number of labeled examples together with many un-labeled examples are often unreliable as they frequently produce an internally consistent, but nevertheless incorrect set of extractions.
method_label: We propose that this problem can be overcome by simultaneously learning classifiers for many different categories and relations in the presence of an ontology defining constraints that couple the training of these classifiers.
result_label: Experimental results show that simultaneously learning a coupled collection of classifiers for 30 categories and relations results in much more accurate extractions than training classifiers individually.

===================================
paper_id: 7548895; YEAR: 2010
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: title_tfidf
TITLE: Large Scale Relation Detection
ABSTRACT: background_label: AbstractWe present a technique for reading sentences and producing sets of hypothetical relations that the sentence may be expressing.
method_label: The technique uses large amounts of instance-level background knowledge about the relations in order to gather statistics on the various ways the relation may be expressed in language, and was inspired by the observation that half of the linguistic forms used to express relations occur very infrequently and are simply not considered by systems that use too few seed examples.
result_label: Some very early experiments are presented that show promising results.

===================================
paper_id: 189928148; YEAR: 2019
adju relevance: Related (+1)
difference: 1; annotator1: 1; annotator2: 0
sources: title_tfidf
TITLE: Multi-Level Matching and Aggregation Network for Few-Shot Relation Classification
ABSTRACT: background_label: This paper presents a multi-level matching and aggregation network (MLMAN) for few-shot relation classification.
background_label: Previous studies on this topic adopt prototypical networks, which calculate the embedding vector of a query instance and the prototype vector of each support set independently.
method_label: In contrast, our proposed MLMAN model encodes the query instance and each support set in an interactive way by considering their matching information at both local and instance levels.
method_label: The final class prototype for each support set is obtained by attentive aggregation over the representations of its support instances, where the weights are calculated using the query instance.
result_label: Experimental results demonstrate the effectiveness of our proposed methods, which achieve a new state-of-the-art performance on the FewRel dataset.

===================================
paper_id: 71145737; YEAR: 2019
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: specter - abs_tfidf - title_tfidf
TITLE: Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples
ABSTRACT: background_label: Few-shot classification refers to learning a classifier for new classes given only a few examples.
background_label: While a plethora of models have emerged to tackle this recently, we find the current procedure and datasets that are used to systematically assess progress in this setting lacking.
objective_label: To address this, we propose Meta-Dataset: a new benchmark for training and evaluating few-shot classifiers that is large-scale, consists of multiple datasets, and presents more natural and realistic tasks.
objective_label: The aim is to measure the ability of state-of-the-art models to leverage diverse sources of data to achieve higher generalization, and to evaluate that generalization ability in a more challenging setting.
method_label: We additionally measure robustness of current methods to variations in the number of available examples and the number of classes.
result_label: Finally our extensive empirical evaluation leads us to identify weaknesses in Prototypical Networks and MAML, two popular few-shot classification methods, and to propose a new method, Proto-MAML, which achieves improved performance on our benchmark.

===================================
paper_id: 25691390; YEAR: 2017
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Few-Shot Learning Through an Information Retrieval Lens
ABSTRACT: background_label: Few-shot learning refers to understanding new concepts from only a few examples.
objective_label: We propose an information retrieval-inspired approach for this problem that is motivated by the increased importance of maximally leveraging all the available information in this low-data regime.
objective_label: We define a training objective that aims to extract as much information as possible from each training batch by effectively optimizing over all relative orderings of the batch points simultaneously.
method_label: In particular, we view each batch point as a `query' that ranks the remaining ones based on its predicted relevance to them and we define a model within the framework of structured prediction to optimize mean Average Precision over these rankings.
result_label: Our method achieves impressive results on the standard few-shot classification benchmarks while is also capable of few-shot retrieval.

===================================
paper_id: 27410115; YEAR: 2017
adju relevance: Related (+1)
difference: 1; annotator1: 1; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Learning with Noise: Enhance Distantly Supervised Relation Extraction with Dynamic Transition Matrix
ABSTRACT: background_label: Distant supervision significantly reduces human efforts in building training data for many classification tasks.
background_label: While promising, this technique often introduces noise to the generated training data, which can severely affect the model performance.
objective_label: In this paper, we take a deep look at the application of distant supervision in relation extraction.
method_label: We show that the dynamic transition matrix can effectively characterize the noise in the training data built by distant supervision.
method_label: The transition matrix can be effectively trained using a novel curriculum learning based method without any direct supervision about the noise.
result_label: We thoroughly evaluate our approach under a wide range of extraction scenarios.
result_label: Experimental results show that our approach consistently improves the extraction results and outperforms the state-of-the-art in various evaluation scenarios.

===================================
paper_id: 12873739; YEAR: 2014
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Relation Classification via Convolutional Deep Neural Network
ABSTRACT: background_label: AbstractThe state-of-the-art methods used for relation classification are primarily based on statistical machine learning, and their performance strongly depends on the quality of the extracted features.
background_label: The extracted features are often derived from the output of pre-existing natural language processing (NLP) systems, which leads to the propagation of the errors in the existing tools and hinders the performance of these systems.
method_label: In this paper, we exploit a convolutional deep neural network (DNN) to extract lexical and sentence level features.
method_label: Our method takes all of the word tokens as input without complicated pre-processing.
method_label: First, the word tokens are transformed to vectors by looking up word embeddings 1 .
method_label: Then, lexical level features are extracted according to the given nouns.
method_label: Meanwhile, sentence level features are learned using a convolutional approach.
method_label: These two level features are concatenated to form the final extracted feature vector.
method_label: Finally, the features are fed into a softmax classifier to predict the relationship between two marked nouns.
result_label: The experimental results demonstrate that our approach significantly outperforms the state-of-the-art methods.

===================================
paper_id: 53211033; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator1: 1; annotator2: 1
sources: specter - title_tfidf
TITLE: Few-shot learning with attention-based sequence-to-sequence models
ABSTRACT: background_label: End-to-end approaches have recently become popular as a means of simplifying the training and deployment of speech recognition systems.
background_label: However, they often require large amounts of data to perform well on large vocabulary tasks.
objective_label: With the aim of making end-to-end approaches usable by a broader range of researchers, we explore the potential to use end-to-end methods in small vocabulary contexts where smaller datasets may be used.
method_label: A significant drawback of small-vocabulary systems is the difficulty of expanding the vocabulary beyond the original training samples -- therefore we also study strategies to extend the vocabulary with only few examples per new class (few-shot learning).
result_label: Our results show that an attention-based encoder-decoder can be competitive against a strong baseline on a small vocabulary keyword classification task, reaching 97.5% of accuracy on Tensorflow's Speech Commands dataset.
result_label: It also shows promising results on the few-shot learning problem where a simple strategy achieved 68.8\% of accuracy on new keywords with only 10 examples for each new class.
result_label: This score goes up to 88.4\% with a larger set of 100 examples.

===================================
paper_id: 128345548; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: specter - abs_tfidfcbow200 - abs_tfidf
TITLE: Few-Shot NLG with Pre-Trained Language Model
ABSTRACT: background_label: Neural-based end-to-end approaches to natural language generation (NLG) from structured data or knowledge are data-hungry, making their adoption for real-world applications difficult with limited data.
objective_label: In this work, we propose the new task of \textit{few-shot natural language generation}.
objective_label: Motivated by how humans tend to summarize tabular data, we propose a simple yet effective approach and show that it not only demonstrates strong performance but also provides good generalization across domains.
method_label: The design of the model architecture is based on two aspects: content selection/copying from input data and language modeling to compose coherent sentences, which can be acquired from prior knowledge.
method_label: Accordingly, we employ a pre-trained domain-independent language model to serve as the prior, while the content selection/copying can be learned with only a few in-domain training instances, thus attaining the few-shot learning objective.
method_label: To demonstrate that our approach generalizes across domains, we curated table-to-text data from multiple domains.
result_label: With just 200 training examples, we show that our approach achieves very reasonable performances and outperforms the strongest baseline by an average of over 8.0 BLEU points improvement.
other_label: Our code and data is publicly available at https://github.com/czyssrs/Few-Shot-NLG

===================================
paper_id: 174799547; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_tfidfcbow200 - abs_cbow200 - abs_tfidf
TITLE: Baby steps towards few-shot learning with multiple semantics
ABSTRACT: background_label: Learning from one or few visual examples is one of the key capabilities of humans since early infancy, but is still a significant challenge for modern AI systems.
background_label: While considerable progress has been achieved in few-shot learning from a few image examples, much less attention has been given to the verbal descriptions that are usually provided to infants when they are presented with a new object.
objective_label: In this paper, we focus on the role of additional semantics that can significantly facilitate few-shot visual learning.
method_label: Building upon recent advances in few-shot learning with additional semantic information, we demonstrate that further improvements are possible using richer semantics and multiple semantic sources.
result_label: Using these ideas, we offer the community a new result on the one-shot test of the popular miniImageNet benchmark, comparing favorably to the previous state-of-the-art results for both visual only and visual plus semantics-based approaches.
result_label: We also performed an ablation study investigating the components and design choices of our approach.

===================================
paper_id: 54461705; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200
TITLE: A Deep Analysis of the Existing Datasets for Traffic Light State Recognition
ABSTRACT: background_label: Traffic lights classification is a very important task that should be accomplish using computer vision techniques.
background_label: RADAR or LIDAR sensors are suitable to detect traffic lights.
background_label: However, they are not able to distinguish between traffic light states.
background_label: This critical task embraces passengers safety during autonomous driving and it can only be solved using computer vision approaches.
objective_label: In this paper, a wide analysis of the state of the art regarding traffic lights classification is performed.
method_label: The proposed approach is based on a ResNet architecture and it is compared against a more complex architecture (MobilNet) and also against a traditional feature-based classifier (Random Trees).
method_label: Due to the importance of high quality training data, a comparative analyisis of the existing datasets related with traffic light classification is presented.
result_label: The analysis take into account image patch size, number of labels and number of samples for each label.

===================================
paper_id: 11790493; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Human-level concept learning through probabilistic program induction
ABSTRACT: background_label: People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy.
background_label: People can also use learned concepts in richer ways than conventional algorithms—for action, imagination, and explanation.
objective_label: We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world’s alphabets.
method_label: The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion.
method_label: On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches.
result_label: We also present several “visual Turing tests” probing the model’s creative generalization abilities, which in many cases are indistinguishable from human behavior.

===================================
paper_id: 186206588; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidf - specter - title_tfidf
TITLE: Boosting Few-Shot Visual Learning with Self-Supervision
ABSTRACT: background_label: Few-shot learning and self-supervised learning address different facets of the same problem: how to train a model with little or no labeled data.
method_label: Few-shot learning aims for optimization methods and models that can learn efficiently to recognize patterns in the low data regime.
method_label: Self-supervised learning focuses instead on unlabeled data and looks into it for the supervisory signal to feed high capacity deep neural networks.
objective_label: In this work we exploit the complementarity of these two domains and propose an approach for improving few-shot learning through self-supervision.
method_label: We use self-supervision as an auxiliary task in a few-shot learning pipeline, enabling feature extractors to learn richer and more transferable visual representations while still using few annotated samples.
method_label: Through self-supervision, our approach can be naturally extended towards using diverse unlabeled data from other datasets in the few-shot setting.
result_label: We report consistent improvements across an array of architectures, datasets and self-supervision techniques.

===================================
paper_id: 6161478; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition
ABSTRACT: background_label: We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks.
background_label: Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks.
method_label: We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges.
result_label: We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges.
result_label: We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.

===================================
paper_id: 49873046; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidf - specter - title_tfidf
TITLE: Few-Shot Adaptation for Multimedia Semantic Indexing
ABSTRACT: background_label: We propose a few-shot adaptation framework, which bridges zero-shot learning and supervised many-shot learning, for semantic indexing of image and video data.
method_label: Few-shot adaptation provides robust parameter estimation with few training examples, by optimizing the parameters of zero-shot learning and supervised many-shot learning simultaneously.
method_label: In this method, first we build a zero-shot detector, and then update it by using the few examples.
method_label: Our experiments show the effectiveness of the proposed framework on three datasets: TRECVID Semantic Indexing 2010, 2014, and ImageNET.
result_label: On the ImageNET dataset, we show that our method outperforms recent few-shot learning methods.
result_label: On the TRECVID 2014 dataset, we achieve 15.19% and 35.98% in Mean Average Precision under the zero-shot condition and the supervised condition, respectively.
result_label: To the best of our knowledge, these are the best results on this dataset.

===================================
paper_id: 53215378; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator1: 1; annotator2: 0
sources: abs_tfidfcbow200
TITLE: AttentionXML: Extreme Multi-Label Text Classification with Multi-Label Attention Based Recurrent Neural Networks
ABSTRACT: background_label: Extreme multi-label text classification (XMTC) is a task for tagging each given text with the most relevant multiple labels from an extremely large-scale label set.
background_label: This task can be found in many applications, such as product categorization,web page tagging, news annotation and so on.
background_label: Many methods have been proposed so far for solving XMTC, while most of the existing methods use traditional bag-of-words (BOW) representation, ignoring word context as well as deep semantic information.
method_label: XML-CNN, a state-of-the-art deep learning-based method, uses convolutional neural network (CNN) with dynamic pooling to process the text, going beyond the BOW-based appraoches but failing to capture 1) the long-distance dependency among words and 2) different levels of importance of a word for each label.
method_label: We propose a new deep learning-based method, AttentionXML, which uses bidirectional long short-term memory (LSTM) and a multi-label attention mechanism for solving the above 1st and 2nd problems, respectively.
method_label: We empirically compared AttentionXML with other six state-of-the-art methods over five benchmark datasets.
method_label: AttentionXML outperformed all competing methods under all experimental settings except only a couple of cases.
result_label: In addition, a consensus ensemble of AttentionXML with the second best method, Parabel, could further improve the performance over all five benchmark datasets.

===================================
paper_id: 16508014; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidfcbow200 - title_cbow200 - title_tfidf
TITLE: Hierarchical, Multi-Sensor Based Classification of Daily Life Activities: Comparison with State-of-the-Art Algorithms Using a Benchmark Dataset
ABSTRACT: background_label: Insufficient physical activity is the 4th leading risk factor for mortality.
background_label: Methods for assessing the individual daily life activity (DLA) are of major interest in order to monitor the current health status and to provide feedback about the individual quality of life.
method_label: The conventional assessment of DLAs with self-reports induces problems like reliability, validity, and sensitivity.
background_label: The assessment of DLAs with small and light-weight wearable sensors (e.g.
method_label: inertial measurement units) provides a reliable and objective method.
result_label: State-of-the-art human physical activity classification systems differ in e.g.
background_label: the number and kind of sensors, the performed activities, and the sampling rate.
background_label: Hence, it is difficult to compare newly proposed classification algorithms to existing approaches in literature and no commonly used dataset exists.
method_label: We generated a publicly available benchmark dataset for the classification of DLAs.
method_label: Inertial data were recorded with four sensor nodes, each consisting of a triaxial accelerometer and a triaxial gyroscope, placed on wrist, hip, chest, and ankle.
method_label: Further, we developed a novel, hierarchical, multi-sensor based classification system for the distinction of a large set of DLAs.
method_label: Our hierarchical classification system reached an overall mean classification rate of 89.6% and was diligently compared to existing state-of-the-art algorithms using our benchmark dataset.
result_label: For future research, the dataset can be used in the evaluation process of new classification algorithms and could speed up the process of getting the best performing and most appropriate DLA classification system.

===================================
paper_id: 27101089; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Evaluation of the deep nonlinear metric learning based speaker identification on the large scale of voiceprint corpus
ABSTRACT: background_label: Speaker recognition is a valuable biometric recognition technology.
background_label: Recently, with the development of deep learning, many deep network based speaker recognition algorithms are proposed.
background_label: However, the evaluations on the speaker recognition algorithms are always performed on a small or middle scale of voiceprint corpus.
background_label: There are few evaluation reports of speaker recognition on a large scale of voiceprint corpus.
objective_label: In this paper, we try to introduce a deep nonlinear metric learning based speaker identification algorithm and construct a larger scale of voiceprint corpus consisting of about 440 thousand people.
method_label: We perform the evaluation of the deep nonlinear metric learning based method on the large scale corpus and give the recognition rate results in different scales.
result_label: The evaluation results prove that, the performance is surely decreased when the scale of the corpus is increased.
result_label: But for the scale of 400 thousand, the recognition rate of Top 50 is stable at about 95%, which means that it could be used in some real applications.

===================================
paper_id: 53080998; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator1: 1; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Put It Back: Entity Typing with Language Model Enhancement
ABSTRACT: background_label: AbstractEntity typing aims to classify semantic types of an entity mention in a specific context.
background_label: Most existing models obtain training data using distant supervision, and inevitably suffer from the problem of noisy labels.
objective_label: To address this issue, we propose entity typing with language model enhancement.
method_label: It utilizes a language model to measure the compatibility between context sentences and labels, and thereby automatically focuses more on context-dependent labels.
result_label: Experiments on benchmark datasets demonstrate that our method is capable of enhancing the entity typing model with information from the language model, and significantly outperforms the stateof-the-art baseline.
other_label: Code and data for this paper can be found from https://github.
other_label: com/thunlp/LME.

===================================
paper_id: 5476; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 1; annotator1: 2; annotator2: 1
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Incorporating Relation Paths in Neural Relation Extraction
ABSTRACT: background_label: Distantly supervised relation extraction has been widely used to find novel relational facts from plain text.
background_label: To predict the relation between a pair of two target entities, existing methods solely rely on those direct sentences containing both entities.
background_label: In fact, there are also many sentences containing only one of the target entities, which provide rich and useful information for relation extraction.
method_label: To address this issue, we build inference chains between two target entities via intermediate entities, and propose a path-based neural relation extraction model to encode the relational semantics from both direct sentences and inference chains.
result_label: Experimental results on real-world datasets show that, our model can make full use of those sentences containing only one target entity, and achieves significant and consistent improvements on relation extraction as compared with baselines.
other_label: The source code of this paper can be obtained from https: //github.com/thunlp/PathNRE.

===================================
paper_id: 10098085; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: ATR4S: Toolkit with State-of-the-art Automatic Terms Recognition Methods in Scala
ABSTRACT: background_label: Automatically recognized terminology is widely used for various domain-specific texts processing tasks, such as machine translation, information retrieval or sentiment analysis.
background_label: However, there is still no agreement on which methods are best suited for particular settings and, moreover, there is no reliable comparison of already developed methods.
background_label: We believe that one of the main reasons is the lack of state-of-the-art methods implementations, which are usually non-trivial to recreate.
method_label: In order to address these issues, we present ATR4S, an open-source software written in Scala that comprises more than 15 methods for automatic terminology recognition (ATR) and implements the whole pipeline from text document preprocessing, to term candidates collection, term candidates scoring, and finally, term candidates ranking.
method_label: It is highly scalable, modular and configurable tool with support of automatic caching.
method_label: We also compare 10 state-of-the-art methods on 7 open datasets by average precision and processing time.
result_label: Experimental comparison reveals that no single method demonstrates best average precision for all datasets and that other available tools for ATR do not contain the best methods.

===================================
paper_id: 4662035; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200 - title_tfidf
TITLE: BigHand2.2M Benchmark: Hand Pose Dataset and State of the Art Analysis
ABSTRACT: background_label: In this paper we introduce a large-scale hand pose dataset, collected using a novel capture method.
background_label: Existing datasets are either generated synthetically or captured using depth sensors: synthetic datasets exhibit a certain level of appearance difference from real depth images, and real datasets are limited in quantity and coverage, mainly due to the difficulty to annotate them.
method_label: We propose a tracking system with six 6D magnetic sensors and inverse kinematics to automatically obtain 21-joints hand pose annotations of depth maps captured with minimal restriction on the range of motion.
method_label: The capture protocol aims to fully cover the natural hand pose space.
result_label: As shown in embedding plots, the new dataset exhibits a significantly wider and denser range of hand poses compared to existing benchmarks.
result_label: Current state-of-the-art methods are evaluated on the dataset, and we demonstrate significant improvements in cross-benchmark performance.
result_label: We also show significant improvements in egocentric hand pose estimation with a CNN trained on the new dataset.

===================================
paper_id: 3945803; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Weakly Supervised Object Localization on grocery shelves using simple FCN and Synthetic Dataset
ABSTRACT: method_label: We propose a weakly supervised method using two algorithms to predict object bounding boxes given only an image classification dataset.
method_label: First algorithm is a simple Fully Convolutional Network (FCN) trained to classify object instances.
method_label: We use the property of FCN to return a mask for images larger than training images to get a primary output segmentation mask during test time by passing an image pyramid to it.
method_label: We enhance the FCN output mask into final output bounding boxes by a Convolutional Encoder-Decoder (ConvAE) viz.
method_label: the second algorithm.
method_label: ConvAE is trained to localize objects on an artificially generated dataset of output segmentation masks.
method_label: We demonstrate the effectiveness of this method in localizing objects in grocery shelves where annotating data for object detection is hard due to variety of objects.
result_label: This method can be extended to any problem domain where collecting images of objects is easy and annotating their coordinates is hard.

===================================
paper_id: 202565610; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200 - specter
TITLE: Frustratingly Easy Natural Question Answering
ABSTRACT: background_label: Existing literature on Question Answering (QA) mostly focuses on algorithmic novelty, data augmentation, or increasingly large pre-trained language models like XLNet and RoBERTa.
background_label: Additionally, a lot of systems on the QA leaderboards do not have associated research documentation in order to successfully replicate their experiments.
method_label: In this paper, we outline these algorithmic components such as Attention-over-Attention, coupled with data augmentation and ensembling strategies that have shown to yield state-of-the-art results on benchmark datasets like SQuAD, even achieving super-human performance.
result_label: Contrary to these prior results, when we evaluate on the recently proposed Natural Questions benchmark dataset, we find that an incredibly simple approach of transfer learning from BERT outperforms the previous state-of-the-art system trained on 4 million more examples than ours by 1.9 F1 points.
result_label: Adding ensembling strategies further improves that number by 2.3 F1 points.

===================================
paper_id: 1511800; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Unsupervised Category Discovery via Looped Deep Pseudo-Task Optimization Using a Large Scale Radiology Image Database
ABSTRACT: background_label: Obtaining semantic labels on a large scale radiology image database (215,786 key images from 61,845 unique patients) is a prerequisite yet bottleneck to train highly effective deep convolutional neural network (CNN) models for image recognition.
background_label: Nevertheless, conventional methods for collecting image labels (e.g., Google search followed by crowd-sourcing) are not applicable due to the formidable difficulties of medical annotation tasks for those who are not clinically trained.
background_label: This type of image labeling task remains non-trivial even for radiologists due to uncertainty and possible drastic inter-observer variation or inconsistency.
method_label: In this paper, we present a looped deep pseudo-task optimization procedure for automatic category discovery of visually coherent and clinically semantic (concept) clusters.
method_label: Our system can be initialized by domain-specific (CNN trained on radiology images and text report derived labels) or generic (ImageNet based) CNN models.
method_label: Afterwards, a sequence of pseudo-tasks are exploited by the looped deep image feature clustering (to refine image labels) and deep CNN training/classification using new labels (to obtain more task representative deep features).
method_label: Our method is conceptually simple and based on the hypothesized"convergence"of better labels leading to better trained CNN models which in turn feed more effective deep image features to facilitate more meaningful clustering/labels.
result_label: We have empirically validated the convergence and demonstrated promising quantitative and qualitative results.
method_label: Category labels of significantly higher quality than those in previous work are discovered.
result_label: This allows for further investigation of the hierarchical semantic nature of the given large-scale radiology image database.

===================================
paper_id: 198147625; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_tfidf - specter - title_tfidf
TITLE: TARN: Temporal Attentive Relation Network for Few-Shot and Zero-Shot Action Recognition
ABSTRACT: objective_label: In this paper we propose a novel Temporal Attentive Relation Network (TARN) for the problems of few-shot and zero-shot action recognition.
method_label: At the heart of our network is a meta-learning approach that learns to compare representations of variable temporal length, that is, either two videos of different length (in the case of few-shot action recognition) or a video and a semantic representation such as word vector (in the case of zero-shot action recognition).
method_label: By contrast to other works in few-shot and zero-shot action recognition, we a) utilise attention mechanisms so as to perform temporal alignment, and b) learn a deep-distance measure on the aligned representations at video segment level.
method_label: We adopt an episode-based training scheme and train our network in an end-to-end manner.
method_label: The proposed method does not require any fine-tuning in the target domain or maintaining additional representations as is the case of memory networks.
result_label: Experimental results show that the proposed architecture outperforms the state of the art in few-shot action recognition, and achieves competitive results in zero-shot action recognition.

===================================
paper_id: 13654422; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidfcbow200 - abs_cbow200 - abs_tfidf
TITLE: Explore Efficient Local Features from RGB-D Data for One-Shot Learning Gesture Recognition
ABSTRACT: background_label: Availability of handy RGB-D sensors has brought about a surge of gesture recognition research and applications.
background_label: Among various approaches, one shot learning approach is advantageous because it requires minimum amount of data.
objective_label: Here, we provide a thorough review about one-shot learning gesture recognition from RGB-D data and propose a novel spatiotemporal feature extracted from RGB-D data, namely mixed features around sparse keypoints (MFSK).
method_label: In the review, we analyze the challenges that we are facing, and point out some future research directions which may enlighten researchers in this field.
method_label: The proposed MFSK feature is robust and invariant to scale, rotation and partial occlusions.
method_label: To alleviate the insufficiency of one shot training samples, we augment the training samples by artificially synthesizing versions of various temporal scales, which is beneficial for coping with gestures performed at varying speed.
method_label: We evaluate the proposed method on the Chalearn gesture dataset (CGD).
result_label: The results show that our approach outperforms all currently published approaches on the challenging data of CGD, such as translated, scaled and occluded subsets.
result_label: When applied to the RGB-D datasets that are not one-shot (e.g., the Cornell Activity Dataset-60 and MSR Daily Activity 3D dataset), the proposed feature also produces very promising results under leave-one-out cross validation or one-shot learning.

===================================
paper_id: 10680010; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Automatic sports genre categorization and view-type classification over large-scale dataset
ABSTRACT: background_label: This paper presents a framework with two automatic tasks targeting large-scale and low quality sports video archives collected from online video streams.
method_label: The framework is based on the bag of visual-words model using speeded-up robust features (SURF).
method_label: The first task is sports genre categorization based on hierarchical structure.
method_label: Following on the second task which is based on automatically obtained genre, views are classified using support vector machines (SVMs).
method_label: As a consequence, the views classification result can be used in video parsing and highlight extraction.
method_label: As compared with state-of-the-art methods, our approach is fully automatic as well as domain knowledge free and thus provides a better extensibility.
result_label: Furthermore, our dataset consists of 14 sport genres with 6850 minutes in total.
result_label: Both sport genre categorization and view type classification have more than 80% accuracy rates, which validate this framework's robustness and potential in web-based applications.

===================================
paper_id: 5708782; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Chinese Zero Pronoun Resolution: A Joint Unsupervised Discourse-Aware Model Rivaling State-of-the-Art Resolvers
ABSTRACT: background_label: We propose an unsupervised probabilistic model for zero pronoun resolution.
method_label: To our knowledge, this is the first such model that (1) is trained on zero pronouns in an unsupervised manner; (2) jointly identifies and resolves anaphoric zero pronouns; and (3) exploits discourse information provided by a salience model.
result_label: Experiments demonstrate that our unsupervised model significantly outperforms its state-of-the-art unsupervised counterpart when resolving the Chinese zero pronouns in the OntoNotes corpus.

===================================
paper_id: 102352238; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: specter - title_tfidf
TITLE: Semi-Supervised Few-Shot Learning for Dual Question-Answer Extraction
ABSTRACT: background_label: This paper addresses the problem of key phrase extraction from sentences.
background_label: Existing state-of-the-art supervised methods require large amounts of annotated data to achieve good performance and generalization.
background_label: Collecting labeled data is, however, often expensive.
method_label: In this paper, we redefine the problem as question-answer extraction, and present SAMIE: Self-Asking Model for Information Ixtraction, a semi-supervised model which dually learns to ask and to answer questions by itself.
method_label: Briefly, given a sentence $s$ and an answer $a$, the model needs to choose the most appropriate question $\hat q$; meanwhile, for the given sentence $s$ and same question $\hat q$ selected in the previous step, the model will predict an answer $\hat a$.
method_label: The model can support few-shot learning with very limited supervision.
method_label: It can also be used to perform clustering analysis when no supervision is provided.
result_label: Experimental results show that the proposed method outperforms typical supervised methods especially when given little labeled data.

===================================
paper_id: 1447435; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Comparison and Combination of State-of-the-art Techniques for Handwritten Character Recognition: Topping the MNIST Benchmark
ABSTRACT: background_label: Although the recognition of isolated handwritten digits has been a research topic for many years, it continues to be of interest for the research community and for commercial applications.
background_label: We show that despite the maturity of the field, different approaches still deliver results that vary enough to allow improvements by using their combination.
method_label: We do so by choosing four well-motivated state-of-the-art recognition systems for which results on the standard MNIST benchmark are available.
method_label: When comparing the errors made, we observe that the errors made differ between all four systems, suggesting the use of classifier combination.
method_label: We then determine the error rate of a hypothetical system that combines the output of the four systems.
result_label: The result obtained in this manner is an error rate of 0.35% on the MNIST data, the best result published so far.
result_label: We furthermore discuss the statistical significance of the combined result and of the results of the individual classifiers.

===================================
paper_id: 202542497; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: specter - abs_tfidfcbow200 - abs_tfidf - title_tfidf
TITLE: PARN: Position-Aware Relation Networks for Few-Shot Learning
ABSTRACT: background_label: Few-shot learning presents a challenge that a classifier must quickly adapt to new classes that do not appear in the training set, given only a few labeled examples of each new class.
objective_label: This paper proposes a position-aware relation network (PARN) to learn a more flexible and robust metric ability for few-shot learning.
background_label: Relation networks (RNs), a kind of architectures for relational reasoning, can acquire a deep metric ability for images by just being designed as a simple convolutional neural network (CNN) [23].
background_label: However, due to the inherent local connectivity of CNN, the CNN-based relation network (RN) can be sensitive to the spatial position relationship of semantic objects in two compared images.
method_label: To address this problem, we introduce a deformable feature extractor (DFE) to extract more efficient features, and design a dual correlation attention mechanism (DCA) to deal with its inherent local connectivity.
method_label: Successfully, our proposed approach extents the potential of RN to be position-aware of semantic objects by introducing only a small number of parameters.
method_label: We evaluate our approach on two major benchmark datasets, i.e., Omniglot and Mini-Imagenet, and on both of the datasets our approach achieves state-of-the-art performance with the setting of using a shallow feature extraction network.
result_label: It's worth noting that our 5-way 1-shot result on Omniglot even outperforms the previous 5-way 5-shot results.

===================================
paper_id: 43937873; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200
TITLE: Quantum classification of the MNIST dataset via Slow Feature Analysis
ABSTRACT: background_label: Quantum machine learning carries the promise to revolutionize information and communication technologies.
background_label: While a number of quantum algorithms with potential exponential speedups have been proposed already, it is quite difficult to provide convincing evidence that quantum computers with quantum memories will be in fact useful to solve real-world problems.
objective_label: Our work makes considerable progress towards this goal.
objective_label: We design quantum techniques for Dimensionality Reduction and for Classification, and combine them to provide an efficient and high accuracy quantum classifier that we test on the MNIST dataset.
method_label: More precisely, we propose a quantum version of Slow Feature Analysis (QSFA), a dimensionality reduction technique that maps the dataset in a lower dimensional space where we can apply a novel quantum classification procedure, the Quantum Frobenius Distance (QFD).
method_label: We simulate the quantum classifier (including errors) and show that it can provide classification of the MNIST handwritten digit dataset, a widely used dataset for benchmarking classification algorithms, with $98.5\%$ accuracy, similar to the classical case.
method_label: The running time of the quantum classifier is polylogarithmic in the dimension and number of data points.
result_label: We also provide evidence that the other parameters on which the running time depends (condition number, Frobenius norm, error threshold, etc.)
result_label: scale favorably in practice, thus ascertaining the efficiency of our algorithm.

===================================
paper_id: 6719686; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
ABSTRACT: background_label: We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning.
objective_label: The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples.
method_label: In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task.
method_label: In effect, our method trains the model to be easy to fine-tune.
result_label: We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.

===================================
paper_id: 52195410; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200
TITLE: Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization with Medical Applications
ABSTRACT: background_label: Medical applications challenge today's text categorization techniques by demanding both high accuracy and ease-of-interpretation.
background_label: Although deep learning has provided a leap ahead in accuracy, this leap comes at the sacrifice of interpretability.
objective_label: To address this accuracy-interpretability challenge, we here introduce, for the first time, a text categorization approach that leverages the recently introduced Tsetlin Machine.
method_label: In all brevity, we represent the terms of a text as propositional variables.
method_label: From these, we capture categories using simple propositional formulae, such as: if"rash"and"reaction"and"penicillin"then Allergy.
method_label: The Tsetlin Machine learns these formulae from a labelled text, utilizing conjunctive clauses to represent the particular facets of each category.
background_label: Indeed, even the absence of terms (negated features) can be used for categorization purposes.
background_label: Our empirical comparison with Na\"ive Bayes, decision trees, linear support vector machines (SVMs), random forest, long short-term memory (LSTM) neural networks, and other techniques, is quite conclusive.
method_label: The Tsetlin Machine either performs on par with or outperforms all of the evaluated methods on both the 20 Newsgroups and IMDb datasets, as well as on a non-public clinical dataset.
method_label: On average, the Tsetlin Machine delivers the best recall and precision scores across the datasets.
result_label: Finally, our GPU implementation of the Tsetlin Machine executes 5 to 15 times faster than the CPU implementation, depending on the dataset.
result_label: We thus believe that our novel approach can have a significant impact on a wide range of text analysis applications, forming a promising starting point for deeper natural language understanding with the Tsetlin Machine.

===================================
paper_id: 65161700; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_tfidfcbow200
TITLE: An Analysis of Feature Regularization for Low-shot Learning
ABSTRACT: background_label: Low-shot visual learning, the ability to recognize novel object categories from very few, or even one example, is a hallmark of human visual intelligence.
background_label: Though successful on many tasks, deep learning approaches tends to be notoriously data-hungry.
background_label: Recently, feature penalty regularization has been proved effective on capturing new concepts.
objective_label: In this work, we provide both empirical evidence and theoretical analysis on how and why these methods work.
method_label: We also propose a better design of cost function with improved performance.
method_label: Close scrutiny reveals the centering effect of feature representation, as well as the intrinsic connection with batch normalization.
result_label: Extensive experiments on synthetic datasets, the one-shot learning benchmark “Omniglot”, and large-scale ImageNet validate our analysis.

===================================
paper_id: 51723509; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: General-purpose Tagging of Freesound Audio with AudioSet Labels: Task Description, Dataset, and Baseline
ABSTRACT: background_label: This paper describes Task 2 of the DCASE 2018 Challenge, titled"General-purpose audio tagging of Freesound content with AudioSet labels".
background_label: This task was hosted on the Kaggle platform as"Freesound General-Purpose Audio Tagging Challenge".
objective_label: The goal of the task is to build an audio tagging system that can recognize the category of an audio clip from a subset of 41 diverse categories drawn from the AudioSet Ontology.
result_label: We present the task, the dataset prepared for the competition, and a baseline system.

===================================
paper_id: 16188142; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200
TITLE: A Comprehensive Benchmark of Kernel Methods to Extract Protein–Protein Interactions from Literature
ABSTRACT: background_label: The most important way of conveying new findings in biomedical research is scientific publication.
background_label: Extraction of protein-protein interactions (PPIs) reported in scientific publications is one of the core topics of text mining in the life sciences.
background_label: Recently, a new class of such methods has been proposed - convolution kernels that identify PPIs using deep parses of sentences.
background_label: However, comparing published results of different PPI extraction methods is impossible due to the use of different evaluation corpora, different evaluation metrics, different tuning procedures, etc.
objective_label: In this paper, we study whether the reported performance metrics are robust across different corpora and learning settings and whether the use of deep parsing actually leads to an increase in extraction quality.
result_label: Our ultimate goal is to identify the one method that performs best in real-life scenarios, where information extraction is performed on unseen text and not on specifically prepared evaluation data.
background_label: We performed a comprehensive benchmarking of nine different methods for PPI extraction that use convolution kernels on rich linguistic information.
method_label: Methods were evaluated on five different public corpora using cross-validation, cross-learning, and cross-corpus evaluation.
method_label: Our study confirms that kernels using dependency trees generally outperform kernels based on syntax trees.
method_label: However, our study also shows that only the best kernel methods can compete with a simple rule-based approach when the evaluation prevents information leakage between training and test corpora.
result_label: Our results further reveal that the F-score of many approaches drops significantly if no corpus-specific parameter optimization is applied and that methods reaching a good AUC score often perform much worse in terms of F-score.
result_label: We conclude that for most kernels no sensible estimation of PPI extraction performance on new text is possible, given the current heterogeneity in evaluation data.
result_label: Nevertheless, our study shows that three kernels are clearly superior to the other methods.

===================================
paper_id: 53233708; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Large-Scale Semantic Classification: Outcome of the First Year of Inria Aerial Image Labeling Benchmark
ABSTRACT: background_label: Over the recent years, there has been an increasing interest in large-scale classification of remote sensing images.
background_label: In this context, the Inria Aerial Image Labeling Benchmark has been released online in December 2016.
objective_label: In this paper, we discuss the outcomes of the first year of the benchmark contest, which consisted in dense labeling of aerial images into building / not building classes, covering areas of five cities not present in the training set.
method_label: We present four methods with the highest numerical accuracies, all four being convolutional neural network approaches.
result_label: It is remarkable that three of these methods use the U-net architecture, which has thus proven to become a new standard in image dense labeling.

===================================
paper_id: 2746158; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: A survey of noise reduction methods for distant supervision
ABSTRACT: background_label: We survey recent approaches to noise reduction in distant supervision learning for relation extraction.
method_label: We group them according to the principles they are based on: at-least-one constraints, topic-based models, or pattern correlations.
method_label: Besides describing them, we illustrate the fundamental differences and attempt to give an outlook to potentially fruitful further research.
result_label: In addition, we identify related work in sentiment analysis which could profit from approaches to noise reduction.

===================================
paper_id: 195833540; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidf - abs_tfidfcbow200 - specter - title_tfidf
TITLE: Revisiting Metric Learning for Few-Shot Image Classification
ABSTRACT: objective_label: The goal of few-shot learning is to recognize new visual concepts with just a few amount of labeled samples in each class.
background_label: Recent effective metric-based few-shot approaches employ neural networks to learn a feature similarity comparison between query and support examples.
background_label: However, the importance of feature embedding, i.e., exploring the relationship among training samples, is neglected.
objective_label: In this work, we present a simple yet powerful baseline for few-shot classification by emphasizing the importance of feature embedding.
method_label: Specifically, we revisit the classical triplet network from deep metric learning, and extend it into a deep K-tuplet network for few-shot learning, utilizing the relationship among the input samples to learn a general representation learning via episode-training.
method_label: Once trained, our network is able to extract discriminative features for unseen novel categories and can be seamlessly incorporated with a non-linear distance metric function to facilitate the few-shot classification.
result_label: Our result on the miniImageNet benchmark outperforms other metric-based few-shot classification methods.
result_label: More importantly, when evaluated on completely different datasets (Caltech-101, CUB-200, Stanford Dogs and Cars) using the model trained with miniImageNet, our method significantly outperforms prior methods, demonstrating its superior capability to generalize to unseen classes.

===================================
paper_id: 5288798; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 2; annotator1: 2; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Label Embedding for Zero-shot Fine-grained Named Entity Typing
ABSTRACT: background_label: AbstractNamed entity typing is the task of detecting the types of a named entity in context.
objective_label: For instance, given "Eric is giving a presentation", our goal is to infer that 'Eric' is a speaker or a presenter and a person.
background_label: Existing approaches to named entity typing cannot work with a growing type set and fails to recognize entity mentions of unseen types.
method_label: In this paper, we present a label embedding method that incorporates prototypical and hierarchical information to learn pre-trained label embeddings.
method_label: In addition, we adapt a zero-shot framework that can predict both seen and previously unseen entity types.
method_label: We perform evaluation on three benchmark datasets with two settings: 1) few-shots recognition where all types are covered by the training set; and 2) zero-shot recognition where fine-grained types are assumed absent from training set.
result_label: Results show that prior knowledge encoded using our label embedding methods can significantly boost the performance of classification for both cases.

===================================
paper_id: 75135497; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_tfidf - title_tfidfcbow200 - title_tfidf
TITLE: Dense Classification and Implanting for Few-Shot Learning
ABSTRACT: background_label: Training deep neural networks from few examples is a highly challenging and key problem for many computer vision tasks.
background_label: In this context, we are targeting knowledge transfer from a set with abundant data to other sets with few available examples.
method_label: We propose two simple and effective solutions: (i) dense classification over feature maps, which for the first time studies local activations in the domain of few-shot learning, and (ii) implanting, that is, attaching new neurons to a previously trained network to learn new, task-specific features.
result_label: On miniImageNet, we improve the prior state-of-the-art on few-shot classification, i.e., we achieve 62.5%, 79.8% and 83.8% on 5-way 1-shot, 5-shot and 10-shot settings respectively.

===================================
paper_id: 201646434; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidfcbow200
TITLE: Large-Scale Historical Watermark Recognition: dataset and a new consistency-based approach
ABSTRACT: background_label: Historical watermark recognition is a highly practical, yet unsolved challenge for archivists and historians.
background_label: With a large number of well-defined classes, cluttered and noisy samples, different types of representations, both subtle differences between classes and high intra-class variation, historical watermarks are also challenging for pattern recognition.
method_label: In this paper, overcoming the difficulty of data collection, we present a large public dataset with more than 6k new photographs, allowing for the first time to tackle at scale the scenarios of practical interest for scholars: one-shot instance recognition and cross-domain one-shot instance recognition amongst more than 16k fine-grained classes.
method_label: We demonstrate that this new dataset is large enough to train modern deep learning approaches, and show that standard methods can be improved considerably by using mid-level deep features.
method_label: More precisely, we design both a matching score and a feature fine-tuning strategy based on filtering local matches using spatial consistency.
method_label: This consistency-based approach provides important performance boost compared to strong baselines.
result_label: Our model achieves 55% top-1 accuracy on our very challenging 16,753-class one-shot cross-domain recognition task, each class described by a single drawing from the classic Briquet catalog.
result_label: In addition to watermark classification, we show our approach provides promising results on fine-grained sketch-based image retrieval.

===================================
paper_id: 18702258; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Meta Networks
ABSTRACT: background_label: Neural networks have been successfully applied in applications with a large amount of labeled data.
background_label: However, the task of rapid generalization on new concepts with small training data while preserving performances on previously learned ones still presents a significant challenge to neural network models.
method_label: In this work, we introduce a novel meta learning method, Meta Networks (MetaNet), that learns a meta-level knowledge across tasks and shifts its inductive biases via fast parameterization for rapid generalization.
result_label: When evaluated on Omniglot and Mini-ImageNet benchmarks, our MetaNet models achieve a near human-level performance and outperform the baseline approaches by up to 6% accuracy.
result_label: We demonstrate several appealing properties of MetaNet relating to generalization and continual learning.

===================================
paper_id: 6430506; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: 2D Human Pose Estimation: New Benchmark and State of the Art Analysis
ABSTRACT: background_label: Human pose estimation has made significant progress during the last years.
background_label: However current datasets are limited in their coverage of the overall pose estimation challenges.
background_label: Still these serve as the common sources to evaluate, train and compare different models on.
objective_label: In this paper we introduce a novel benchmark "MPII Human Pose" that makes a significant advance in terms of diversity and difficulty, a contribution that we feel is required for future developments in human body models.
method_label: This comprehensive dataset was collected using an established taxonomy of over 800 human activities [1].
method_label: The collected images cover a wider variety of human activities than previous datasets including various recreational, occupational and householding activities, and capture people from a wider range of viewpoints.
method_label: We provide a rich set of labels including positions of body joints, full 3D torso and head orientation, occlusion labels for joints and body parts, and activity labels.
method_label: For each image we provide adjacent video frames to facilitate the use of motion information.
result_label: Given these rich annotations we perform a detailed analysis of leading human pose estimation approaches and gaining insights for the success and failures of these methods.

===================================
paper_id: 35417796; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidf
TITLE: Make SVM great again with Siamese kernel for few-shot learning
ABSTRACT: background_label: While deep neural networks have shown outstanding results in a wide range of applications, learning from a very limited number of examples is still a challenging task.
background_label: Despite the difficulties of the few-shot learning, metric-learning techniques showed the potential of the neural networks for this task.
background_label: While these methods perform well, they don’t provide satisfactory results.
method_label: In this work, the idea of metric-learning is extended with Support Vector Machines (SVM) working mechanism, which is well known for generalization capabilities on a small dataset.
method_label: Furthermore, this paper presents an end-to-end learning framework for training adaptive kernel SVMs, which eliminates the problem of choosing a correct kernel and good features for SVMs.
method_label: Next, the one-shot learning problem is redefined for audio signals.
method_label: Then the model was tested on vision task (using Omniglot dataset) and speech task (using TIMIT dataset) as well.
result_label: Actually, the algorithm using Omniglot dataset improved accuracy from 98.1% to 98.5% on the one-shot classification task and from 98.9% to 99.3% on the few-shot classification task.

===================================
paper_id: 309759; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Prototypical Networks for Few-shot Learning
ABSTRACT: background_label: We propose prototypical networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class.
background_label: Prototypical networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class.
background_label: Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results.
method_label: We provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning.
result_label: We further extend prototypical networks to zero-shot learning and achieve state-of-the-art results on the CU-Birds dataset.

===================================
paper_id: 53716898; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidf - specter
TITLE: Deep Comparison: Relation Columns for Few-Shot Learning
ABSTRACT: background_label: Few-shot deep learning is a topical challenge area for scaling visual recognition to open-ended growth in the space of categories to recognise.
background_label: A promising line work towards realising this vision is deep networks that learn to match queries with stored training images.
method_label: However, methods in this paradigm usually train a deep embedding followed by a single linear classifier.
method_label: Our insight is that effective general-purpose matching requires discrimination with regards to features at multiple abstraction levels.
method_label: We therefore propose a new framework termed \modelnamefull that decomposes embedding learning into a sequence of modules, and pairs each with a relation module.
method_label: The relation modules compute a non-linear metric to score the match using the corresponding embedding module's representation.
method_label: To ensure that all embedding module's features are used, the relation modules are deeply supervised.
method_label: Finally generalisation is further improved by a learned noise regulariser.
result_label: The resulting network achieves state of the art performance on both miniImageNet and tieredImageNet, while retaining the appealing simplicity and efficiency of deep metric learning approaches.

===================================
paper_id: 3485252; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200 - abs_tfidfcbow200 - specter
TITLE: Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks
ABSTRACT: background_label: In this paper, we study the challenging problem of categorizing videos according to high-level semantics such as the existence of a particular human action or a complex event.
background_label: Although extensive efforts have been devoted in recent years, most existing works combined multiple video features using simple fusion strategies and neglected the utilization of inter-class semantic relationships.
objective_label: This paper proposes a novel unified framework that jointly exploits the feature relationships and the class relationships for improved categorization performance.
method_label: Specifically, these two types of relationships are estimated and utilized by rigorously imposing regularizations in the learning process of a deep neural network (DNN).
method_label: Such a regularized DNN (rDNN) can be efficiently realized using a GPU-based implementation with an affordable training cost.
method_label: Through arming the DNN with better capability of harnessing both the feature and the class relationships, the proposed rDNN is more suitable for modeling video semantics.
result_label: With extensive experimental evaluations, we show that rDNN produces superior performance over several state-of-the-art approaches.
result_label: On the well-known Hollywood2 and Columbia Consumer Video benchmarks, we obtain very competitive results: 66.9\% and 73.5\% respectively in terms of mean average precision.
result_label: In addition, to substantially evaluate our rDNN and stimulate future research on large scale video categorization, we collect and release a new benchmark dataset, called FCVID, which contains 91,223 Internet videos and 239 manually annotated categories.

===================================
paper_id: 13751202; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: specter - abs_cbow200
TITLE: Exploring the Limits of Weakly Supervised Pretraining
ABSTRACT: background_label: State-of-the-art visual perception models for a wide range of tasks rely on supervised pretraining.
background_label: ImageNet classification is the de facto pretraining task for these models.
background_label: Yet, ImageNet is now nearly ten years old and is by modern standards"small".
background_label: Even so, relatively little is known about the behavior of pretraining with datasets that are multiple orders of magnitude larger.
background_label: The reasons are obvious: such datasets are difficult to collect and annotate.
objective_label: In this paper, we present a unique study of transfer learning with large convolutional networks trained to predict hashtags on billions of social media images.
result_label: Our experiments demonstrate that training for large-scale hashtag prediction leads to excellent results.
result_label: We show improvements on several image classification and object detection tasks, and report the highest ImageNet-1k single-crop, top-1 accuracy to date: 85.4% (97.6% top-5).
result_label: We also perform extensive experiments that provide novel empirical data on the relationship between large-scale pretraining and transfer learning performance.

===================================
paper_id: 166228405; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: specter - abs_tfidfcbow200 - abs_cbow200 - abs_tfidf
TITLE: Finding Task-Relevant Features for Few-Shot Learning by Category Traversal
ABSTRACT: background_label: Few-shot learning is an important area of research.
background_label: Conceptually, humans are readily able to understand new concepts given just a few examples, while in more pragmatic terms, limited-example training situations are common in practice.
background_label: Recent effective approaches to few-shot learning employ a metric-learning framework to learn a feature similarity comparison between a query (test) example, and the few support (training) examples.
background_label: However, these approaches treat each support class independently from one another, never looking at the entire task as a whole.
background_label: Because of this, they are constrained to use a single set of features for all possible test-time tasks, which hinders the ability to distinguish the most relevant dimensions for the task at hand.
method_label: In this work, we introduce a Category Traversal Module that can be inserted as a plug-and-play module into most metric-learning based few-shot learners.
method_label: This component traverses across the entire support set at once, identifying task-relevant features based on both intra-class commonality and inter-class uniqueness in the feature space.
result_label: Incorporating our module improves performance considerably (5%-10% relative) over baseline systems on both mini-ImageNet and tieredImageNet benchmarks, with overall performance competitive with recent state-of-the-art systems.

===================================
paper_id: 32156360; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Linguistic Resources and Evaluation Techniques for Evaluation of Cross-Document Automatic Content Extraction
ABSTRACT: background_label: AbstractThe NIST Automatic Content Extraction (ACE) Evaluation expands its focus in 2008 to encompass the challenge of cross-document and cross-language global integration and reconciliation of information.
background_label: While past ACE evaluations were limited to local (within-document) detection and disambiguation of entities, relations and events, the current evaluation adds global (cross-document and cross-language) entity disambiguation tasks for Arabic and English.
objective_label: This paper presents the 2008 ACE XDoc evaluation task and associated infrastructure.
result_label: We describe the creation of development and test data to support the evaluation, focusing on new approaches required in data selection, annotation task definition and annotation software; and we conclude with a discussion of the metrics developed to support the evaluation.

===================================
paper_id: 6641909; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: title_tfidfcbow200
TITLE: WILDCAT: Weakly Supervised Learning of Deep ConvNets for Image Classification, Pointwise Localization and Segmentation
ABSTRACT: objective_label: This paper introduces WILDCAT, a deep learning method which jointly aims at aligning image regions for gaining spatial invariance and learning strongly localized features.
method_label: Our model is trained using only global image labels and is devoted to three main visual recognition tasks: image classification, weakly supervised object localization and semantic segmentation.
method_label: WILDCAT extends state-of-the-art Convolutional Neural Networks at three main levels: the use of Fully Convolutional Networks for maintaining spatial resolution, the explicit design in the network of local features related to different class modalities, and a new way to pool these features to provide a global image prediction required for weakly supervised training.
result_label: Extensive experiments show that our model significantly outperforms state-of-the-art methods.

===================================
paper_id: 67855702; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_tfidf - title_tfidf
TITLE: Centroid Networks for Few-Shot Clustering and Unsupervised Few-Shot Classification
ABSTRACT: background_label: Traditional clustering algorithms such as K-means rely heavily on the nature of the chosen metric or data representation.
background_label: To get meaningful clusters, these representations need to be tailored to the downstream task (e.g.
background_label: cluster photos by object category, cluster faces by identity).
method_label: Therefore, we frame clustering as a meta-learning task, few-shot clustering, which allows us to specify how to cluster the data at the meta-training level, despite the clustering algorithm itself being unsupervised.
method_label: We propose Centroid Networks, a simple and efficient few-shot clustering method based on learning representations which are tailored both to the task to solve and to its internal clustering module.
method_label: We also introduce unsupervised few-shot classification, which is conceptually similar to few-shot clustering, but is strictly harder than supervised* few-shot classification and therefore allows direct comparison with existing supervised few-shot classification methods.
method_label: On Omniglot and miniImageNet, our method achieves accuracy competitive with popular supervised few-shot classification algorithms, despite using *no labels* from the support set.
result_label: We also show performance competitive with state-of-the-art learning-to-cluster methods.

===================================
paper_id: 8909022; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Matching Networks for One Shot Learning
ABSTRACT: background_label: Learning from a few examples remains a key challenge in machine learning.
background_label: Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data.
objective_label: In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories.
method_label: Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types.
method_label: We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks.
method_label: Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches.
result_label: We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.

===================================
paper_id: 202537280; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Snowball: Iterative Model Evolution and Confident Sample Discovery for Semi-Supervised Learning on Very Small Labeled Datasets
ABSTRACT: background_label: In this work, we develop a joint sample discovery and iterative model evolution method for semi-supervised learning on very small labeled training sets.
method_label: We propose a master-teacher-student model framework to provide multi-layer guidance during the model evolution process with multiple iterations and generations.
method_label: The teacher model is constructed by performing an exponential moving average of the student models obtained from past training steps.
method_label: The master network combines the knowledge of the student and teacher models with additional access to newly discovered samples.
method_label: The master and teacher models are then used to guide the training of the student network by enforcing the consistence between their predictions of unlabeled samples and evolve all models when more and more samples are discovered.
result_label: Our extensive experiments demonstrate that the discovering confident samples from the unlabeled dataset, once coupled with the above master-teacher-student network evolution, can significantly improve the overall semi-supervised learning performance.
result_label: For example, on the CIFAR-10 dataset, with a very small set of 250 labeled samples, our method achieves an error rate of 11.81 %, more than 38 % lower than the state-of-the-art method Mean-Teacher (49.91 %).

===================================
paper_id: 1996180; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Supervised learning and evaluation of KITTI's cars detector with DPM
ABSTRACT: background_label: This paper carries out a discussion on the supervised learning of a car detector built as a Discriminative Part-based Model (DPM) from images in the recently published KITTI benchmark suite as part of the object detection and orientation estimation challenge.
objective_label: We present a wide set of experiments and many hints on the different ways to supervise and enhance the well-known DPM on a challenging and naturalistic urban dataset as KITTI.
method_label: The evaluation algorithm and metrics, the selection of a clean but representative subset of training samples and the DPM tuning are key factors to learn an object detector in a supervised fashion.
result_label: We provide evidence of subtle differences in performance depending on these aspects.
result_label: Besides, the generalization of the trained models to an independent dataset is validated by 5-fold cross-validation.

===================================
paper_id: 49653712; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidf - specter - abs_tfidf
TITLE: Large Margin Few-Shot Learning
ABSTRACT: background_label: The key issue of few-shot learning is learning to generalize.
objective_label: This paper proposes a large margin principle to improve the generalization capacity of metric based methods for few-shot learning.
method_label: To realize it, we develop a unified framework to learn a more discriminative metric space by augmenting the classification loss function with a large margin distance loss function for training.
result_label: Extensive experiments on two state-of-the-art few-shot learning methods, graph neural networks and prototypical networks, show that our method can improve the performance of existing models substantially with very little computational overhead, demonstrating the effectiveness of the large margin principle and the potential of our method.

===================================
paper_id: 102351194; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_tfidfcbow200 - abs_tfidf
TITLE: Meta-Learning with Differentiable Convex Optimization
ABSTRACT: background_label: Many meta-learning approaches for few-shot learning rely on simple base learners such as nearest-neighbor classifiers.
background_label: However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization.
objective_label: We propose to use these predictors as base learners to learn representations for few-shot learning and show they offer better tradeoffs between feature size and performance across a range of few-shot recognition benchmarks.
objective_label: Our objective is to learn feature embeddings that generalize well under a linear classification rule for novel categories.
method_label: To efficiently solve the objective, we exploit two properties of linear classifiers: implicit differentiation of the optimality conditions of the convex problem and the dual formulation of the optimization problem.
method_label: This allows us to use high-dimensional embeddings with improved generalization at a modest increase in computational overhead.
method_label: Our approach, named MetaOptNet, achieves state-of-the-art performance on miniImageNet, tieredImageNet, CIFAR-FS, and FC100 few-shot learning benchmarks.
other_label: Our code is available at https://github.com/kjunelee/MetaOptNet.

===================================
paper_id: 119425731; YEAR: 1972
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidf
TITLE: Unzerlegbare Darstellungen I
ABSTRACT: background_label: LetK be the structure got by forgetting the composition law of morphisms in a given category.
background_label: A linear representation ofK is given by a map V associating with any morphism ϕ: a→e ofK a linear vector space map V(ϕ): V(a)→V(e).
method_label: We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations.
other_label: This classification is related to an old paper by Yoshii [3].

===================================
paper_id: 82456167; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidf
TITLE: Janeway's Immunobiology
ABSTRACT: background_label: Part I An Introduction to Immunobiology and Innate Immunity 1.
background_label: Basic Concepts in Immunology 2.
background_label: Innate Immunity Part II The Recognition of Antigen 3.
background_label: Antigen Recognition by B-cell and T-cell Receptors 4.
method_label: The Generation of Lymphocyte Antigen Receptors 5.
method_label: Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6.
method_label: Signaling Through Immune System Receptors 7.
result_label: The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8.
background_label: T Cell-Mediated Immunity 9.
background_label: The Humoral Immune Response 10.
background_label: Dynamics of Adaptive Immunity 11.
other_label: The Mucosal Immune System Part V The Immune System in Health and Disease 12.
background_label: Failures of Host Defense Mechanism 13.
other_label: Allergy and Hypersensitivity 14.
other_label: Autoimmunity and Transplantation 15.
other_label: Manipulation of the Immune Response Part VI The Origins of Immune Responses 16.
other_label: Evolution of the Immune System Appendix I Immunologists' Toolbox Appendix II CD Antigens Appendix III Cytokines and their Receptors Appendix IV Chemokines and their Receptors Appendix V Immunological Constants

===================================
paper_id: 36117198; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidf
TITLE: DeepMind_Commentary
ABSTRACT: background_label: We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential.
background_label: However, we favor an approach that centers on one additional ingredient: autonomy.
objective_label: In particular, we aim toward agents that can both build and exploit their own internal models, with minimal human hand-engineering.
method_label: We believe an approach centered on autonomous learning has the greatest chance of success as we scale toward real-world complexity, tackling domains for which ready-made formal models are not available.
result_label: Here we survey several important examples of the progress that has been made toward building autonomous agents with humanlike abilities, and highlight some outstanding challenges.

===================================
paper_id: 247735; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Improved Relation Extraction with Feature-Rich Compositional Embedding Models
ABSTRACT: background_label: Compositional embedding models build a representation (or embedding) for a linguistic structure based on its component word embeddings.
objective_label: We propose a Feature-rich Compositional Embedding Model (FCM) for relation extraction that is expressive, generalizes to new domains, and is easy-to-implement.
objective_label: The key idea is to combine both (unlexicalized) hand-crafted features with learned word embeddings.
method_label: The model is able to directly tackle the difficulties met by traditional compositional embeddings models, such as handling arbitrary types of sentence annotations and utilizing global information for composition.
result_label: We test the proposed model on two relation extraction tasks, and demonstrate that our model outperforms both previous compositional models and traditional feature rich models on the ACE 2005 relation extraction task, and the SemEval 2010 relation classification task.
result_label: The combination of our model and a log-linear classifier with hand-crafted features gives state-of-the-art results.

===================================
paper_id: 118988729; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidf
TITLE: A Microphotonic Astrocomb
ABSTRACT: background_label: One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers.
background_label: It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources.
background_label: A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers.
method_label: Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz.
method_label: This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer.
result_label: As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research.

===================================
paper_id: 10538587; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidfcbow200 - title_cbow200 - title_tfidf
TITLE: A Large-Scale Pseudoword-Based Evaluation Framework for State-of-the-Art Word Sense Disambiguation
ABSTRACT: background_label: The evaluation of several tasks in lexical semantics is often limited by the lack of large amounts of manual annotations, not only for training purposes, but also for testing purposes.
background_label: Word Sense Disambiguation (WSD) is a case in point, as hand-labeled datasets are particularly hard and time-consuming to create.
objective_label: Consequently, evaluations tend to be performed on a small scale, which does not allow for in-depth analysis of the factors that determine a systems' performance.In this paper we address this issue by means of a realistic simulation of large-scale evaluation for the WSD task.
method_label: We do this by providing two main contributions: First, we put forward two novel approaches to the wide-coverage generation of semantically aware pseudowords (i.e., artificial words capable of modeling real polysemous words); second, we leverage the most suitable type of pseudoword to create large pseudosense-annotated corpora, which enable a large-scale experimental framework for the comparison of state-of-the-art supervised and knowledge-based algorithms.
result_label: Using this framework, we study the impact of supervision and knowledge on the two major disambiguation paradigms and perform an in-depth analysis of the factors which affect their performance.

===================================
paper_id: 17055842; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: title_tfidfcbow200 - title_cbow200
TITLE: Weakly-supervised DCNN for RGB-D Object Recognition in Real-World Applications Which Lack Large-scale Annotated Training Data
ABSTRACT: background_label: This paper addresses the problem of RGBD object recognition in real-world applications, where large amounts of annotated training data are typically unavailable.
method_label: To overcome this problem, we propose a novel, weakly-supervised learning architecture (DCNN-GPC) which combines parametric models (a pair of Deep Convolutional Neural Networks (DCNN) for RGB and D modalities) with non-parametric models (Gaussian Process Classification).
method_label: Our system is initially trained using a small amount of labeled data, and then automatically prop- agates labels to large-scale unlabeled data.
method_label: We first run 3D- based objectness detection on RGBD videos to acquire many unlabeled object proposals, and then employ DCNN-GPC to label them.
result_label: As a result, our multi-modal DCNN can be trained end-to-end using only a small amount of human annotation.
background_label: Finally, our 3D-based objectness detection and multi-modal DCNN are integrated into a real-time detection and recognition pipeline.
background_label: In our approach, bounding-box annotations are not required and boundary-aware detection is achieved.
objective_label: We also propose a novel way to pretrain a DCNN for the depth modality, by training on virtual depth images projected from CAD models.
method_label: We pretrain our multi-modal DCNN on public 3D datasets, achieving performance comparable to state-of-the-art methods on Washington RGBS Dataset.
method_label: We then finetune the network by further training on a small amount of annotated data from our novel dataset of industrial objects (nuclear waste simulants).
result_label: Our weakly supervised approach has demonstrated to be highly effective in solving a novel RGBD object recognition application which lacks of human annotations.

===================================
paper_id: 3179925; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: A Large Contextual Dataset for Classification, Detection and Counting of Cars with Deep Learning
ABSTRACT: background_label: We have created a large diverse set of cars from overhead images, which are useful for training a deep learner to binary classify, detect and count them.
background_label: The dataset and all related material will be made publically available.
background_label: The set contains contextual matter to aid in identification of difficult targets.
method_label: We demonstrate classification and detection on this dataset using a neural network we call ResCeption.
method_label: This network combines residual learning with Inception-style layers and is used to count cars in one look.
method_label: This is a new way to count objects rather than by localization or density estimation.
method_label: It is fairly accurate, fast and easy to implement.
method_label: Additionally, the counting method is not car or scene specific.
result_label: It would be easy to train this method to count other kinds of objects and counting over new scenes requires no extra set up or assumptions about object locations.

===================================
paper_id: 102351185; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: specter - abs_tfidfcbow200 - abs_cbow200 - abs_tfidf - title_tfidf
TITLE: A Closer Look at Few-shot Classification
ABSTRACT: background_label: Few-shot classification aims to learn a classifier to recognize unseen classes during training with limited labeled examples.
background_label: While significant progress has been made, the growing complexity of network designs, meta-learning algorithms, and differences in implementation details make a fair comparison difficult.
method_label: In this paper, we present 1) a consistent comparative analysis of several representative few-shot classification algorithms, with results showing that deeper backbones significantly reduce the performance differences among methods on datasets with limited domain differences, 2) a modified baseline method that surprisingly achieves competitive performance when compared with the state-of-the-art on both the \miniI and the CUB datasets, and 3) a new experimental setting for evaluating the cross-domain generalization ability for few-shot classification algorithms.
result_label: Our results reveal that reducing intra-class variation is an important factor when the feature backbone is shallow, but not as critical when using deeper backbones.
result_label: In a realistic cross-domain evaluation setting, we show that a baseline method with a standard fine-tuning practice compares favorably against other state-of-the-art few-shot learning algorithms.

===================================
paper_id: 53038426; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_tfidfcbow200 - specter
TITLE: Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering
ABSTRACT: background_label: Given only a few image-text pairs, humans can learn to detect semantic concepts and describe the content.
background_label: For machine learning algorithms, they usually require a lot of data to train a deep neural network to solve the problem.
background_label: However, it is challenging for the existing systems to generalize well to the few-shot multi-modal scenario, because the learner should understand not only images and texts but also their relationships from only a few examples.
objective_label: In this paper, we tackle two multi-modal problems, i.e., image captioning and visual question answering (VQA), in the few-shot setting.
method_label: We propose Fast Parameter Adaptation for Image-Text Modeling (FPAIT) that learns to learn jointly understanding image and text data by a few examples.
result_label: In practice, FPAIT has two benefits.
result_label: (1) Fast learning ability.
background_label: FPAIT learns proper initial parameters for the joint image-text learner from a large number of different tasks.
background_label: When a new task comes, FPAIT can use a small number of gradient steps to achieve a good performance.
background_label: (2) Robust to few examples.
background_label: In few-shot tasks, the small training data will introduce large biases in Convolutional Neural Networks (CNN) and damage the learner's performance.
method_label: FPAIT leverages dynamic linear transformations to alleviate the side effects of the small training set.
method_label: In this way, FPAIT flexibly normalizes the features and thus reduces the biases during training.
result_label: Quantitatively, FPAIT achieves superior performance on both few-shot image captioning and VQA benchmarks.

===================================
paper_id: 13746427; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidfcbow200 - abs_tfidf - title_tfidf
TITLE: Dynamic Few-Shot Visual Learning without Forgetting
ABSTRACT: background_label: The human visual system has the remarkably ability to be able to effortlessly learn novel concepts from only a few examples.
background_label: Mimicking the same behavior on machine learning vision systems is an interesting and very challenging research problem with many practical advantages on real world vision applications.
objective_label: In this context, the goal of our work is to devise a few-shot visual learning system that during test time it will be able to efficiently learn novel categories from only a few training data while at the same time it will not forget the initial categories on which it was trained (here called base categories).
method_label: To achieve that goal we propose (a) to extend an object recognition system with an attention based few-shot classification weight generator, and (b) to redesign the classifier of a ConvNet model as the cosine similarity function between feature representations and classification weight vectors.
method_label: The latter, apart from unifying the recognition of both novel and base categories, it also leads to feature representations that generalize better on"unseen"categories.
method_label: We extensively evaluate our approach on Mini-ImageNet where we manage to improve the prior state-of-the-art on few-shot recognition (i.e., we achieve 56.20% and 73.00% on the 1-shot and 5-shot settings respectively) while at the same time we do not sacrifice any accuracy on the base categories, which is a characteristic that most prior approaches lack.
method_label: Finally, we apply our approach on the recently introduced few-shot benchmark of Bharath and Girshick [4] where we also achieve state-of-the-art results.
other_label: The code and models of our paper will be published on: https://github.com/gidariss/FewShotWithoutForgetting

===================================
paper_id: 14168099; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 1; annotator1: 1; annotator2: 0
sources: title_cbow200
TITLE: Large-scale Classification of Fine-Art Paintings: Learning The Right Metric on The Right Feature
ABSTRACT: background_label: In the past few years, the number of fine-art collections that are digitized and publicly available has been growing rapidly.
background_label: With the availability of such large collections of digitized artworks comes the need to develop multimedia systems to archive and retrieve this pool of data.
background_label: Measuring the visual similarity between artistic items is an essential step for such multimedia systems, which can benefit more high-level multimedia tasks.
method_label: In order to model this similarity between paintings, we should extract the appropriate visual features for paintings and find out the best approach to learn the similarity metric based on these features.
method_label: We investigate a comprehensive list of visual features and metric learning approaches to learn an optimized similarity measure between paintings.
method_label: We develop a machine that is able to make aesthetic-related semantic-level judgments, such as predicting a painting's style, genre, and artist, as well as providing similarity measures optimized based on the knowledge available in the domain of art historical interpretation.
result_label: Our experiments show the value of using this similarity measure for the aforementioned prediction tasks.

===================================
paper_id: 48360450; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200
TITLE: Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering
ABSTRACT: background_label: In this paper, we analyze several neural network designs (and their variations) for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, semantic textual similarity, natural language inference, and question answering tasks.
background_label: Although most of these models have claimed state-of-the-art performance, the original papers often reported on only one or two selected datasets.
result_label: We provide a systematic study and show that (i) encoding contextual information by LSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter datasets, (iii) the Enhanced Sequential Inference Model is the best so far for larger datasets, while the Pairwise Word Interaction Model achieves the best performance when less data is available.
result_label: We release our implementations as an open-source toolkit.

===================================
paper_id: 12479002; YEAR: 2005
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidf - title_cbow200
TITLE: Large-scale evaluation of multimodal biometric authentication using state-of-the-art systems
ABSTRACT: background_label: We examine the performance of multimodal biometric authentication systems using state-of-the-art commercial off-the-shelf (COTS) fingerprint and face biometric systems on a population approaching 1,000 individuals.
background_label: The majority of prior studies of multimodal biometrics have been limited to relatively low accuracy non-COTS systems and populations of a few hundred users.
method_label: Our work is the first to demonstrate that multimodal fingerprint and face biometric systems can achieve significant accuracy gains over either biometric alone, even when using highly accurate COTS systems on a relatively large-scale population.
method_label: In addition to examining well-known multimodal methods, we introduce new methods of normalization and fusion that further improve the accuracy.

===================================
paper_id: 689719; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200
TITLE: Active learning-based information structure analysis of full scientific articles and two applications for biomedical literature review.
ABSTRACT: background_label: MOTIVATION Techniques that are capable of automatically analyzing the information structure of scientific articles could be highly useful for improving information access to biomedical literature.
background_label: However, most existing approaches rely on supervised machine learning (ML) and substantial labeled data that are expensive to develop and apply to different sub-fields of biomedicine.
background_label: Recent research shows that minimal supervision is sufficient for fairly accurate information structure analysis of biomedical abstracts.
background_label: However, is it realistic for full articles given their high linguistic and informational complexity?
method_label: We introduce and release a novel corpus of 50 biomedical articles annotated according to the Argumentative Zoning (AZ) scheme, and investigate active learning with one of the most widely used ML models-Support Vector Machines (SVM)-on this corpus.
background_label: Additionally, we introduce two novel applications that use AZ to support real-life literature review in biomedicine via question answering and summarization.
background_label: RESULTS We show that active learning with SVM trained on 500 labeled sentences (6% of the corpus) performs surprisingly well with the accuracy of 82%, just 2% lower than fully supervised learning.
background_label: In our question answering task, biomedical researchers find relevant information significantly faster from AZ-annotated than unannotated articles.
method_label: In the summarization task, sentences extracted from particular zones are significantly more similar to gold standard summaries than those extracted from particular sections of full articles.
result_label: These results demonstrate that active learning of full articles' information structure is indeed realistic and the accuracy is high enough to support real-life literature review in biomedicine.
other_label: AVAILABILITY The annotated corpus, our AZ classifier and the two novel applications are available at http://www.cl.cam.ac.uk/yg244/12bioinfo.html

===================================
paper_id: 10902413; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Fine-Grained Classification of Pedestrians in Video: Benchmark and State of the Art
ABSTRACT: background_label: A video dataset that is designed to study fine-grained categorisation of pedestrians is introduced.
background_label: Pedestrians were recorded"in-the-wild"from a moving vehicle.
background_label: Annotations include bounding boxes, tracks, 14 keypoints with occlusion information and the fine-grained categories of age (5 classes), sex (2 classes), weight (3 classes) and clothing style (4 classes).
background_label: There are a total of 27,454 bounding box and pose labels across 4222 tracks.
method_label: This dataset is designed to train and test algorithms for fine-grained categorisation of people, it is also useful for benchmarking tracking, detection and pose estimation of pedestrians.
result_label: State-of-the-art algorithms for fine-grained classification and pose estimation were tested using the dataset and the results are reported as a useful performance baseline.

===================================
paper_id: 7427287; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Extracting microRNA-gene relations from biomedical literature using distant supervision
ABSTRACT: background_label: Many biomedical relation extraction approaches are based on supervised machine learning, requiring an annotated corpus.
background_label: Distant supervision aims at training a classifier by combining a knowledge base with a corpus, reducing the amount of manual effort necessary.
background_label: This is particularly useful for biomedicine because many databases and ontologies have been made available for many biological processes, while the availability of annotated corpora is still limited.
method_label: We studied the extraction of microRNA-gene relations from text.
result_label: MicroRNA regulation is an important biological process due to its close association with human diseases.
background_label: The proposed method, IBRel, is based on distantly supervised multi-instance learning.
method_label: We evaluated IBRel on three datasets, and the results were compared with a co-occurrence approach as well as a supervised machine learning algorithm.
result_label: While supervised learning outperformed on two of those datasets, IBRel obtained an F-score 28.3 percentage points higher on the dataset for which there was no training set developed specifically.
method_label: To demonstrate the applicability of IBRel, we used it to extract 27 miRNA-gene relations from recently published papers about cystic fibrosis.
result_label: Our results demonstrate that our method can be successfully used to extract relations from literature about a biological process without an annotated corpus.
other_label: The source code and data used in this study are available at https://github.com/AndreLamurias/IBRel.

===================================
paper_id: 118078438; YEAR: 1997
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200
TITLE: Characteristic concept representations
ABSTRACT: background_label: In machine learning, concepts have traditionally been represented and learned using algorithms that represent only those characteristics that discriminate between two or more classes.
background_label: Representations such as decision trees and rules provide increased classification ability, but do not provide a general characteristic description of the concepts.
objective_label: This dissertation explores the use of characteristic descriptions for concepts in the classification task.
objective_label: In our research, characteristic descriptions are represented by prototypes.
method_label: The methods described focus on the issue of learning multiple prototypes for a class when necessary.
method_label: Two diverse methods are developed.
method_label: The first method, PL (Prototype Learner), attempts to separate examples into smaller subgroups with similar characteristics.
method_label: The second method, SNMC (Symbolic Nearest Mean with Clustering), applies clustering techniques to separate groups of examples, using classification accuracy on the training set as its heuristic.
method_label: The groups of examples in each of these algorithms are simplified into prototypes representing the examples and a nearest neighbor classification approach is used for class prediction.
background_label: Our empirical results show that SNMC has an increase in average classification accuracy of about 2% over C4.5 and PEBLS on 20 domains from the UCI data repository.
method_label: The experimental results on the UCI domains showed that SNMC classifies the best in average rank and accuracy of the six algorithms compared.
method_label: PL classifies favorably to C4.5 and PEBLS on the same domains.
result_label: These results show that prototype concept representations can be successfully applied to the classification task.
method_label: The last portion of this dissertation introduces a task, inductive inference, which is a generalization of classification.
method_label: In this task the algorithm must make predictions about any of the attribute values.
method_label: We discuss five subtasks of the inductive inference task, including the classification task.
method_label: We also discuss metrics that can be used to evaluate algorithms on these tasks.
result_label: We contend that these metrics used in conjunction with classification accuracy provides a more general evaluation methodology than classification accuracy alone.
result_label: We provide comparisons among PL, C4.5, PEBLS, and COBWEB.

===================================
paper_id: 2818758; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_cbow200
TITLE: All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning
ABSTRACT: background_label: BACKGROUND Automated extraction of protein-protein interactions (PPI) is an important and widely studied task in biomedical text mining.
objective_label: We propose a graph kernel based approach for this task.
method_label: In contrast to earlier approaches to PPI extraction, the introduced all-paths graph kernel has the capability to make use of full, general dependency graphs representing the sentence structure.
result_label: RESULTS We evaluate the proposed method on five publicly available PPI corpora, providing the most comprehensive evaluation done for a machine learning based PPI-extraction system.
result_label: We additionally perform a detailed evaluation of the effects of training and testing on different resources, providing insight into the challenges involved in applying a system beyond the data it was trained on.
background_label: Our method is shown to achieve state-of-the-art performance with respect to comparable evaluations, with 56.4 F-score and 84.8 AUC on the AImed corpus.
method_label: CONCLUSION We show that the graph kernel approach performs on state-of-the-art level in PPI extraction, and note the possible extension to the task of extracting complex interactions.
result_label: Cross-corpus results provide further insight into how the learning generalizes beyond individual corpora.
method_label: Further, we identify several pitfalls that can make evaluations of PPI-extraction systems incomparable, or even invalid.
result_label: These include incorrect cross-validation strategies and problems related to comparing F-score results achieved on different evaluation resources.
result_label: Recommendations for avoiding these pitfalls are provided.

===================================
paper_id: 3507990; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: specter - title_tfidf
TITLE: Meta-Learning for Semi-Supervised Few-Shot Classification
ABSTRACT: background_label: In few-shot classification, we are interested in learning algorithms that train a classifier from only a handful of labeled examples.
background_label: Recent progress in few-shot classification has featured meta-learning, in which a parameterized model for a learning algorithm is defined and trained on episodes representing different classification problems, each with a small labeled training set and its corresponding test set.
objective_label: In this work, we advance this few-shot classification paradigm towards a scenario where unlabeled examples are also available within each episode.
method_label: We consider two situations: one where all unlabeled examples are assumed to belong to the same set of classes as the labeled examples of the episode, as well as the more challenging situation where examples from other distractor classes are also provided.
method_label: To address this paradigm, we propose novel extensions of Prototypical Networks (Snell et al., 2017) that are augmented with the ability to use unlabeled examples when producing prototypes.
method_label: These models are trained in an end-to-end way on episodes, to learn to leverage the unlabeled examples successfully.
result_label: We evaluate these methods on versions of the Omniglot and miniImageNet benchmarks, adapted to this new framework augmented with unlabeled examples.
method_label: We also propose a new split of ImageNet, consisting of a large set of classes, with a hierarchical structure.
result_label: Our experiments confirm that our Prototypical Networks can learn to improve their predictions due to unlabeled examples, much like a semi-supervised algorithm would.

===================================
paper_id: 44061218; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: abs_tfidf - specter - title_tfidf
TITLE: TADAM: Task dependent adaptive metric for improved few-shot learning
ABSTRACT: background_label: Few-shot learning has become essential for producing models that generalize from few examples.
objective_label: In this work, we identify that metric scaling and metric task conditioning are important to improve the performance of few-shot algorithms.
method_label: Our analysis reveals that simple metric scaling completely changes the nature of few-shot algorithm parameter updates.
method_label: Metric scaling provides improvements up to 14% in accuracy for certain metrics on the mini-Imagenet 5-way 5-shot classification task.
method_label: We further propose a simple and effective way of conditioning a learner on the task sample set, resulting in learning a task-dependent metric space.
method_label: Moreover, we propose and empirically test a practical end-to-end optimization procedure based on auxiliary task co-training to learn a task-dependent metric space.
method_label: The resulting few-shot learning model based on the task-dependent scaled metric achieves state of the art on mini-Imagenet.
result_label: We confirm these results on another few-shot dataset that we introduce in this paper based on CIFAR100.
other_label: Our code is publicly available at https://github.com/ElementAI/TADAM.

===================================
paper_id: 201070109; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator1: 0; annotator2: 0
sources: abs_tfidfcbow200 - abs_tfidf
TITLE: PANet: Few-Shot Image Semantic Segmentation with Prototype Alignment
ABSTRACT: background_label: Despite the great progress made by deep CNNs in image semantic segmentation, they typically require a large number of densely-annotated images for training and are difficult to generalize to unseen object categories.
background_label: Few-shot segmentation has thus been developed to learn to perform segmentation from only a few annotated examples.
objective_label: In this paper, we tackle the challenging few-shot segmentation problem from a metric learning perspective and present PANet, a novel prototype alignment network to better utilize the information of the support set.
method_label: Our PANet learns class-specific prototype representations from a few support images within an embedding space and then performs segmentation over the query images through matching each pixel to the learned prototypes.
method_label: With non-parametric metric learning, PANet offers high-quality prototypes that are representative for each semantic class and meanwhile discriminative for different classes.
method_label: Moreover, PANet introduces a prototype alignment regularization between support and query.
method_label: With this, PANet fully exploits knowledge from the support and provides better generalization on few-shot segmentation.
result_label: Significantly, our model achieves the mIoU score of 48.1% and 55.7% on PASCAL-5i for 1-shot and 5-shot settings respectively, surpassing the state-of-the-art method by 1.8% and 8.6%.

===================================
paper_id: 29162291; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator1: 0; annotator2: 1
sources: cited - abs_tfidfcbow200 - specter - abs_tfidf - title_tfidf
TITLE: Diverse Few-Shot Text Classification with Multiple Metrics
ABSTRACT: background_label: We study few-shot learning in natural language domains.
background_label: Compared to many existing works that apply either metric-based or optimization-based meta-learning to image domain with low inter-task variance, we consider a more realistic setting, where tasks are diverse.
background_label: However, it imposes tremendous difficulties to existing state-of-the-art metric-based algorithms since a single metric is insufficient to capture complex task variations in natural language domain.
method_label: To alleviate the problem, we propose an adaptive metric learning approach that automatically determines the best weighted combination from a set of metrics obtained from meta-training tasks for a newly seen few-shot task.
result_label: Extensive quantitative evaluations on real-world sentiment analysis and dialog intent classification datasets demonstrate that the proposed method performs favorably against state-of-the-art few shot learning algorithms in terms of predictive accuracy.
result_label: We make our code and data available for further study.

