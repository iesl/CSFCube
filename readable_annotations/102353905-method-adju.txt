======================================================================
paper_id: 102353905; YEAR: 2019
TITLE: Document-Level $N$-ary Relation Extraction with Multiscale Representation Learning
ABSTRACT: background_label: Most information extraction methods focus on binary relations expressed within single sentences.
background_label: In high-value domains, however, $n$-ary relations are of great demand (e.g., drug-gene-mutation interactions in precision oncology).
background_label: Such relations often involve entity mentions that are far apart in the document, yet existing work on cross-sentence relation extraction is generally confined to small text spans (e.g., three consecutive sentences), which severely limits recall.
objective_label: In this paper, we propose a novel multiscale neural architecture for document-level $n$-ary relation extraction.
method_label: Our system combines representations learned over various text spans throughout the document and across the subrelation hierarchy.
method_label: Widening the system's purview to the entire document maximizes potential recall.
method_label: Moreover, by integrating weak signals across the document, multiscale modeling increases precision, even in the presence of noisy labels from distant supervision.
result_label: Experiments on biomedical machine reading show that our approach substantially outperforms previous $n$-ary relation extraction methods.
===================================
paper_id: 543003; YEAR: 2016
adju relevance: Identical (+3)
difference: 1; annotator4: 2; annotator3: 3
sources: abs_tfidf - abs_tfidfcbow200 - specter
TITLE: Chemical-induced disease relation extraction with various linguistic features.
ABSTRACT: background_label: Understanding the relations between chemicals and diseases is crucial in various biomedical tasks such as new drug discoveries and new therapy developments.
background_label: While manually mining these relations from the biomedical literature is costly and time-consuming, such a procedure is often difficult to keep up-to-date.
background_label: To address these issues, the BioCreative-V community proposed a challenging task of automatic extraction of chemical-induced disease (CID) relations in order to benefit biocuration.
objective_label: This article describes our work on the CID relation extraction task on the BioCreative-V tasks.
method_label: We built a machine learning based system that utilized simple yet effective linguistic features to extract relations with maximum entropy models.
background_label: In addition to leveraging various features, the hypernym relations between entity concepts derived from the Medical Subject Headings (MeSH)-controlled vocabulary were also employed during both training and testing stages to obtain more accurate classification models and better extraction performance, respectively.
method_label: We demoted relation extraction between entities in documents to relation extraction between entity mentions.
method_label: In our system, pairs of chemical and disease mentions at both intra- and inter-sentence levels were first constructed as relation instances for training and testing, then two classification models at both levels were trained from the training examples and applied to the testing examples.
method_label: Finally, we merged the classification results from mention level to document level to acquire final relations between chemicals and diseases.
result_label: Our system achieved promisingF-scores of 60.4% on the development dataset and 58.3% on the test dataset using gold-standard entity annotations, respectively.
other_label: Database URL:https://github.com/JHnlp/BC5CIDTask.

===================================
paper_id: 16483125; YEAR: 2011
adju relevance: Similar (+2)
difference: 2; annotator4: 1; annotator3: 3
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations
ABSTRACT: background_label: AbstractInformation extraction (IE) holds the promise of generating a large-scale knowledge base from the Web's natural language text.
background_label: Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors.
background_label: Recently, researchers have developed multiinstance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint -for example they cannot extract the pair Founded(Jobs, Apple) and CEO-of(Jobs, Apple).
method_label: This paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts.
method_label: We apply our model to learn extractors for NY Times text using weak supervision from Freebase.
result_label: Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level.

===================================
paper_id: 184487889; YEAR: 2019
adju relevance: Similar (+2)
difference: 1; annotator4: 2; annotator3: 1
sources: title_tfidf - title_cbow200 - title_tfidfcbow200 - abs_tfidf - specter
TITLE: Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network
ABSTRACT: background_label: Inter-sentence relation extraction deals with a number of complex semantic relationships in documents, which require local, non-local, syntactic and semantic dependencies.
background_label: Existing methods do not fully exploit such dependencies.
method_label: We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph.
method_label: The graph is constructed using various inter- and intra-sentence dependencies to capture local and non-local dependency information.
method_label: In order to predict the relation of an entity pair, we utilise multi-instance learning with bi-affine pairwise scoring.
result_label: Experimental results show that our model achieves comparable performance to the state-of-the-art neural models on two biochemistry datasets.
result_label: Our analysis shows that all the types in the graph are effective for inter-sentence relation extraction.

===================================
paper_id: 3576631; YEAR: 2018
adju relevance: Similar (+2)
difference: 0; annotator4: 2; annotator3: 2
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction
ABSTRACT: background_label: Most work in relation extraction forms a prediction by looking at a short span of text within a single sentence containing a single entity pair mention.
background_label: This approach often does not consider interactions across mentions, requires redundant computation for each mention pair, and ignores relationships expressed across sentence boundaries.
background_label: These problems are exacerbated by the document- (rather than sentence-) level annotation common in biological text.
objective_label: In response, we propose a model which simultaneously predicts relationships between all mention pairs in a document.
method_label: We form pairwise predictions over entire paper abstracts using an efficient self-attention encoder.
method_label: All-pairs mention scores allow us to perform multi-instance learning by aggregating over mentions to form entity pair representations.
method_label: We further adapt to settings without mention-level annotation by jointly training to predict named entities and adding a corpus of weakly labeled data.
method_label: In experiments on two Biocreative benchmark datasets, we achieve state of the art performance on the Biocreative V Chemical Disease Relation dataset for models without external KB resources.
result_label: We also introduce a new dataset an order of magnitude larger than existing human-annotated biological information extraction datasets and more accurate than distantly supervised alternatives.

===================================
paper_id: 52115592; YEAR: 2018
adju relevance: Similar (+2)
difference: 2; annotator4: 0; annotator3: 2
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: N-ary Relation Extraction using Graph State LSTM
ABSTRACT: background_label: Cross-sentence $n$-ary relation extraction detects relations among $n$ entities across multiple sentences.
method_label: Typical methods formulate an input as a \textit{document graph}, integrating various intra-sentential and inter-sentential dependencies.
method_label: The current state-of-the-art method splits the input graph into two DAGs, adopting a DAG-structured LSTM for each.
method_label: Though being able to model rich linguistic knowledge by leveraging graph edges, important information can be lost in the splitting procedure.
method_label: We propose a graph-state LSTM model, which uses a parallel state to model each word, recurrently enriching state values via message passing.
method_label: Compared with DAG LSTMs, our graph LSTM keeps the original graph structure, and speeds up computation by allowing more parallelization.
result_label: On a standard benchmark, our model shows the best result in the literature.

===================================
paper_id: 202541610; YEAR: 2019
adju relevance: Similar (+2)
difference: 0; annotator4: 2; annotator3: 2
sources: title_tfidf - title_cbow200 - title_tfidfcbow200 - abs_tfidf - specter
TITLE: Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs
ABSTRACT: background_label: Document-level relation extraction is a complex human process that requires logical inference to extract relationships between named entities in text.
background_label: Existing approaches use graph-based neural models with words as nodes and edges as relations between them, to encode relations across sentences.
background_label: These models are node-based, i.e., they form pair representations based solely on the two target node representations.
background_label: However, entity relations can be better expressed through unique edge representations formed as paths between nodes.
objective_label: We thus propose an edge-oriented graph neural model for document-level relation extraction.
method_label: The model utilises different types of nodes and edges to create a document-level graph.
method_label: An inference mechanism on the graph edges enables to learn intra- and inter-sentence relations using multi-instance learning internally.
result_label: Experiments on two document-level biomedical datasets for chemical-disease and gene-disease associations show the usefulness of the proposed edge-oriented approach.

===================================
paper_id: 15359942; YEAR: 2016
adju relevance: Similar (+2)
difference: 2; annotator4: 0; annotator3: 2
sources: specter - abs_cbow200 - abs_tfidf - abs_tfidfcbow200
TITLE: Distant Supervision for Relation Extraction beyond the Sentence Boundary
ABSTRACT: background_label: The growing demand for structured knowledge has led to great interest in relation extraction, especially in cases with limited supervision.
background_label: However, existing distance supervision approaches only extract relations expressed in single sentences.
background_label: In general, cross-sentence relation extraction is under-explored, even in the supervised-learning setting.
objective_label: In this paper, we propose the first approach for applying distant supervision to cross- sentence relation extraction.
method_label: At the core of our approach is a graph representation that can incorporate both standard dependencies and discourse relations, thus providing a unifying way to model relations within and across sentences.
method_label: We extract features from multiple paths in this graph, increasing accuracy and robustness when confronted with linguistic variation and analysis error.
result_label: Experiments on an important extraction task for precision medicine show that our approach can learn an accurate cross-sentence extractor, using only a small existing knowledge base and unlabeled text from biomedical research articles.
result_label: Compared to the existing distant supervision paradigm, our approach extracted twice as many relations at similar precision, thus demonstrating the prevalence of cross-sentence relations and the promise of our approach.

===================================
paper_id: 53812671; YEAR: 2018
adju relevance: Similar (+2)
difference: 2; annotator4: 0; annotator3: 2
sources: abs_tfidfcbow200 - abs_tfidf
TITLE: A Deep Cascade Model for Multi-Document Reading Comprehension
ABSTRACT: background_label: A fundamental trade-off between effectiveness and efficiency needs to be balanced when designing an online question answering system.
background_label: Effectiveness comes from sophisticated functions such as extractive machine reading comprehension (MRC), while efficiency is obtained from improvements in preliminary retrieval components such as candidate document selection and paragraph ranking.
background_label: Given the complexity of the real-world multi-document MRC scenario, it is difficult to jointly optimize both in an end-to-end system.
method_label: To address this problem, we develop a novel deep cascade learning model, which progressively evolves from the document-level and paragraph-level ranking of candidate texts to more precise answer extraction with machine reading comprehension.
method_label: Specifically, irrelevant documents and paragraphs are first filtered out with simple functions for efficiency consideration.
method_label: Then we jointly train three modules on the remaining texts for better tracking the answer: the document extraction, the paragraph extraction and the answer extraction.
result_label: Experiment results show that the proposed method outperforms the previous state-of-the-art methods on two large-scale multi-document benchmark datasets, i.e., TriviaQA and DuReader.
result_label: In addition, our online system can stably serve typical scenarios with millions of daily requests in less than 50ms.

===================================
paper_id: 14175558; YEAR: 2016
adju relevance: Similar (+2)
difference: 1; annotator4: 2; annotator3: 1
sources: abs_tfidf
TITLE: Incremental Global Event Extraction
ABSTRACT: background_label: AbstractEvent extraction is a difficult information extraction task.
background_label: explore the benefits of modeling event extraction and two related tasks, entity mention and relation extraction, jointly.
background_label: This joint system achieves state-of-the-art performance in all tasks.
background_label: However, as a system operating only at the sentence level, it misses valuable information from other parts of the document.
method_label: In this paper, we present an incremental approach to make the global context of the entire document available to the intra-sentential, state-of-the-art event extractor.
result_label: We show that our method robustly increases performance on two datasets, namely ACE 2005 and TAC 2015.

===================================
paper_id: 752623; YEAR: 2005
adju relevance: Similar (+2)
difference: 0; annotator4: 2; annotator3: 2
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Simple Algorithms for Complex Relation Extraction with Applications to Biomedical IE
ABSTRACT: background_label: A complex relation is any n-ary relation in which some of the arguments may be be unspecified.
method_label: We present here a simple two-stage method for extracting complex relations between named entities in text.
method_label: The first stage creates a graph from pairs of entities that are likely to be related, and the second stage scores maximal cliques in that graph as potential complex relation instances.
result_label: We evaluate the new method against a standard baseline for extracting genomic variation relations from biomedical text.

===================================
paper_id: 12390812; YEAR: 2018
adju relevance: Similar (+2)
difference: 1; annotator4: 1; annotator3: 2
sources: specter - abs_tfidf
TITLE: SEE: Syntax-aware Entity Embedding for Neural Relation Extraction
ABSTRACT: background_label: Distant supervised relation extraction is an efficient approach to scale relation extraction to very large corpora, and has been widely used to find novel relational facts from plain text.
background_label: Recent studies on neural relation extraction have shown great progress on this task via modeling the sentences in low-dimensional spaces, but seldom considered syntax information to model the entities.
objective_label: In this paper, we propose to learn syntax-aware entity embedding for neural relation extraction.
method_label: First, we encode the context of entities on a dependency tree as sentence-level entity embedding based on tree-GRU.
method_label: Then, we utilize both intra-sentence and inter-sentence attentions to obtain sentence set-level entity embedding over all sentences containing the focus entity pair.
method_label: Finally, we combine both sentence embedding and entity embedding for relation classification.
result_label: We conduct experiments on a widely used real-world dataset and the experimental results show that our model can make full use of all informative instances and achieve state-of-the-art performance of relation extraction.

===================================
paper_id: 1463401; YEAR: 2016
adju relevance: Similar (+2)
difference: 0; annotator4: 2; annotator3: 2
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Hierarchical Multiscale Recurrent Neural Networks
ABSTRACT: background_label: Learning both hierarchical and temporal representation has been among the long-standing challenges of recurrent neural networks.
background_label: Multiscale recurrent neural networks have been considered as a promising approach to resolve this issue, yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence.
method_label: In this paper, we propose a novel multiscale approach, called the hierarchical multiscale recurrent neural networks, which can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism.
method_label: We show some evidence that our proposed multiscale architecture can discover underlying hierarchical structure in the sequences without using explicit boundary information.
result_label: We evaluate our proposed model on character-level language modelling and handwriting sequence modelling.

===================================
paper_id: 53250562; YEAR: 2018
adju relevance: Similar (+2)
difference: 1; annotator4: 1; annotator3: 2
sources: title_tfidf - title_cbow200 - abs_tfidf
TITLE: A Hierarchical Framework for Relation Extraction with Reinforcement Learning
ABSTRACT: background_label: Most existing methods determine relation types only after all the entities have been recognized, thus the interaction between relation types and entity mentions is not fully modeled.
objective_label: This paper presents a novel paradigm to deal with relation extraction by regarding the related entities as the arguments of a relation.
method_label: We apply a hierarchical reinforcement learning (HRL) framework in this paradigm to enhance the interaction between entity mentions and relation types.
method_label: The whole extraction process is decomposed into a hierarchy of two-level RL policies for relation detection and entity extraction respectively, so that it is more feasible and natural to deal with overlapping relations.
result_label: Our model was evaluated on public datasets collected via distant supervision, and results show that it gains better performance than existing methods and is more powerful for extracting overlapping relations.

===================================
paper_id: 6054133; YEAR: 2017
adju relevance: Similar (+2)
difference: 0; annotator4: 2; annotator3: 2
sources: specter - abs_cbow200 - abs_tfidfcbow200
TITLE: Attending to All Mention Pairs for Full Abstract Biological Relation Extraction
ABSTRACT: background_label: Most work in relation extraction forms a prediction by looking at a short span of text within a single sentence containing a single entity pair mention.
background_label: However, many relation types, particularly in biomedical text, are expressed across sentences or require a large context to disambiguate.
objective_label: We propose a model to consider all mention and entity pairs simultaneously in order to make a prediction.
method_label: We encode full paper abstracts using an efficient self-attention encoder and form pairwise predictions between all mentions with a bi-affine operation.
method_label: An entity-pair wise pooling aggregates mention pair scores to make a final prediction while alleviating training noise by performing within document multi-instance learning.
method_label: We improve our model's performance by jointly training the model to predict named entities and adding an additional corpus of weakly labeled data.
result_label: We demonstrate our model's effectiveness by achieving the state of the art on the Biocreative V Chemical Disease Relation dataset for models without KB resources, outperforming ensembles of models which use hand-crafted features and additional linguistic resources.

===================================
paper_id: 52960685; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: specter
TITLE: Neural Relation Extraction Within and Across Sentence Boundaries
ABSTRACT: background_label: Past work in relation extraction mostly focuses on binary relation between entity pairs within single sentence.
background_label: Recently, the NLP community has gained interest in relation extraction in entity pairs spanning multiple sentences.
objective_label: In this paper, we propose a novel architecture for this task: inter-sentential dependency-based neural networks (iDepNN).
method_label: iDepNN models the shortest and augmented dependency paths via recurrent and recursive neural networks to extract relationships within (intra-) and across (inter-) sentence boundaries.
objective_label: Compared to SVM and neural network baselines, iDepNN is more robust to false positives in relationships spanning sentences.
result_label: We evaluate our models on four datasets from newswire (MUC6) and medical (BioNLP shared task) domains that achieve state-of-the-art performance and show a better balance in precision and recall for inter-sentential relationships.
result_label: We perform better than 11 teams participating in the BioNLP shared task 2016 and achieve a gain of 5.2% (0.587 vs 0.558) in F1 over the winning team.
result_label: We also release the crosssentence annotations for MUC6.

===================================
paper_id: 189927788; YEAR: 2019
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: specter - abs_cbow200 - abs_tfidfcbow200
TITLE: BERE: An accurate distantly supervised biomedical entity relation extraction network
ABSTRACT: background_label: Automated entity relation extraction (RE) from literature provides an important source for constructing biomedical database, which is more efficient and extensible than manual curation.
background_label: However, existing RE models usually ignore the information contained in sentence structures and target entities.
objective_label: In this paper, we propose BERE, a deep learning based model which uses Gumbel Tree-GRU to learn sentence structures and joint embedding to incorporate entity information.
method_label: It also employs word-level attention for improved relation extraction and sentence-level attention to suit the distantly supervised dataset.
method_label: Because the existing dataset are relatively small, we further construct a much larger drug-target interaction extraction (DTIE) dataset by distant supervision.
result_label: Experiments conducted on both DDIExtraction 2013 task and DTIE dataset show our model's effectiveness over state-of-the-art baselines in terms of F1 measures and PR curves.

===================================
paper_id: 8709585; YEAR: 2016
adju relevance: Related (+1)
difference: 2; annotator4: 0; annotator3: 2
sources: title_cbow200 - title_tfidfcbow200
TITLE: Enhancing Sentence Relation Modeling with Auxiliary Character-level Embedding
ABSTRACT: background_label: Neural network based approaches for sentence relation modeling automatically generate hidden matching features from raw sentence pairs.
background_label: However, the quality of matching feature representation may not be satisfied due to complex semantic relations such as entailment or contradiction.
objective_label: To address this challenge, we propose a new deep neural network architecture that jointly leverage pre-trained word embedding and auxiliary character embedding to learn sentence meanings.
method_label: The two kinds of word sequence representations as inputs into multi-layer bidirectional LSTM to learn enhanced sentence representation.
method_label: After that, we construct matching features followed by another temporal CNN to learn high-level hidden matching feature representations.
result_label: Experimental results demonstrate that our approach consistently outperforms the existing methods on standard evaluation datasets.

===================================
paper_id: 10910955; YEAR: 2009
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Distant supervision for relation extraction without labeled data
ABSTRACT: background_label: Modern models of relation extraction for tasks like ACE are based on supervised learning of relations from small hand-labeled corpora.
background_label: We investigate an alternative paradigm that does not require labeled corpora, avoiding the domain dependence of ACE-style algorithms, and allowing the use of corpora of any size.
method_label: Our experiments use Freebase, a large semantic database of several thousand relations, to provide distant supervision.
method_label: For each pair of entities that appears in some Freebase relation, we find all sentences containing those entities in a large unlabeled corpus and extract textual features to train a relation classifier.
method_label: Our algorithm combines the advantages of supervised IE (combining 400,000 noisy pattern features in a probabilistic classifier) and unsupervised IE (extracting large numbers of relations from large corpora of any domain).
result_label: Our model is able to extract 10,000 instances of 102 relations at a precision of 67.6%.
result_label: We also analyze feature performance, showing that syntactic parse features are particularly helpful for relations that are ambiguous or lexically distant in their expression.

===================================
paper_id: 35133176; YEAR: 2009
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_tfidf
TITLE: A document-sensitive graph model for multi-document summarization
ABSTRACT: background_label: In recent years, graph-based models and ranking algorithms have drawn considerable attention from the extractive document summarization community.
background_label: Most existing approaches take into account sentence-level relations (e.g.
background_label: sentence similarity) but neglect the difference among documents and the influence of documents on sentences.
objective_label: In this paper, we present a novel document-sensitive graph model that emphasizes the influence of global document set information on local sentence evaluation.
method_label: By exploiting document–document and document–sentence relations, we distinguish intra-document sentence relations from inter-document sentence relations.
method_label: In such a way, we move towards the goal of truly summarizing multiple documents rather than a single combined document.
method_label: Based on this model, we develop an iterative sentence ranking algorithm, namely DsR (Document-Sensitive Ranking).
result_label: Automatic ROUGE evaluations on the DUC data sets show that DsR outperforms previous graph-based models in both generic and query-oriented summarization tasks.

===================================
paper_id: 53064621; YEAR: 2018
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: specter
TITLE: RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information
ABSTRACT: background_label: Distantly-supervised Relation Extraction (RE) methods train an extractor by automatically aligning relation instances in a Knowledge Base (KB) with unstructured text.
background_label: In addition to relation instances, KBs often contain other relevant side information, such as aliases of relations (e.g., founded and co-founded are aliases for the relation founderOfCompany).
background_label: RE models usually ignore such readily available side information.
method_label: In this paper, we propose RESIDE, a distantly-supervised neural relation extraction method which utilizes additional side information from KBs for improved relation extraction.
method_label: It uses entity type and relation alias information for imposing soft constraints while predicting relations.
method_label: RESIDE employs Graph Convolution Networks (GCN) to encode syntactic information from text and improves performance even when limited side information is available.
result_label: Through extensive experiments on benchmark datasets, we demonstrate RESIDE's effectiveness.
result_label: We have made RESIDE's source code available to encourage reproducible research.

===================================
paper_id: 9778664; YEAR: 2017
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Exploiting Document Level Information to Improve Event Detection via Recurrent Neural Networks
ABSTRACT: background_label: AbstractThis paper tackles the task of event detection, which involves identifying and categorizing events.
method_label: The previous work mainly exists two problems: (1) the traditional feature-based methods apply crosssentence information, yet need taking a large amount of human effort to design complicated feature sets and inference rules; (2) the representation-based methods though overcome the problem of manually extracting features, while just depend on local sentence representation.
method_label: Considering local sentence context is insufficient to resolve ambiguities in identifying particular event types, therefore, we propose a novel document level Recurrent Neural Networks (DLRNN) model, which can automatically extract cross-sentence clues to improve sentence level event detection without designing complex reasoning rules.
result_label: Experiment results show that our approach outperforms other state-ofthe-art methods on ACE 2005 dataset neither the external knowledge base nor the event arguments are used explicitly.

===================================
paper_id: 11992031; YEAR: 2011
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Coreference based event-argument relation extraction on biomedical text
ABSTRACT: objective_label: This paper presents a new approach to exploit coreference information for extracting event-argument (E-A) relations from biomedical documents.
method_label: This approach has two advantages: (1) it can extract a large number of valuable E-A relations based on the concept of salience in discourse; (2) it enables us to identify E-A relations over sentence boundaries (cross-links) using transitivity of coreference relations.
method_label: We propose two coreference-based models: a pipeline based on Support Vector Machine (SVM) classifiers, and a joint Markov Logic Network (MLN).
method_label: We show the effectiveness of these models on a biomedical event corpus.
result_label: Both models outperform the systems that do not use coreference information.
result_label: When the two proposed models are compared to each other, joint MLN outperforms pipeline SVM with gold coreference information.

===================================
paper_id: 2797612; YEAR: 2017
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: specter - title_cbow200 - abs_cbow200 - title_tfidfcbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf
TITLE: Cross-Sentence N-ary Relation Extraction with Graph LSTMs
ABSTRACT: background_label: Past work in relation extraction has focused on binary relations in single sentences.
background_label: Recent NLP inroads in high-value domains have sparked interest in the more general setting of extracting n-ary relations that span multiple sentences.
objective_label: In this paper, we explore a general relation extraction framework based on graph long short-term memory networks (graph LSTMs) that can be easily extended to cross-sentence n-ary relation extraction.
method_label: The graph formulation provides a unified way of exploring different LSTM approaches and incorporating various intra-sentential and inter-sentential dependencies, such as sequential, syntactic, and discourse relations.
method_label: A robust contextual representation is learned for the entities, which serves as input to the relation classifier.
method_label: This simplifies handling of relations with arbitrary arity, and enables multi-task learning with related relations.
result_label: We evaluate this framework in two important precision medicine settings, demonstrating its effectiveness with both conventional supervised learning and distant supervision.
result_label: Cross-sentence extraction produced larger knowledge bases.
result_label: and multi-task learning significantly improved extraction accuracy.
result_label: A thorough analysis of various LSTM approaches yielded useful insight the impact of linguistic analysis on extraction accuracy.

===================================
paper_id: 52952241; YEAR: None
adju relevance: Related (+1)
difference: 2; annotator4: 0; annotator3: 2
sources: title_cbow200
TITLE: Learning with Structured Representations for Negation Scope Extraction
ABSTRACT: background_label: AbstractWe report an empirical study on the task of negation scope extraction given the negation cue.
objective_label: Our key observation is that certain useful information such as features related to negation cue, long distance dependencies as well as some latent structural information can be exploited for such a task.
method_label: We design approaches based on conditional random fields (CRF), semiMarkov CRF, as well as latent-variable CRF models to capture such information.
result_label: Extensive experiments on several standard datasets demonstrate that our approaches are able to achieve better results than existing approaches reported in the literature.

===================================
paper_id: 182616; YEAR: 2017
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: title_tfidf - abs_tfidf
TITLE: Global Relation Embedding for Relation Extraction
ABSTRACT: background_label: We study the problem of textual relation embedding with distant supervision.
objective_label: To combat the wrong labeling problem of distant supervision, we propose to embed textual relations with global statistics of relations, i.e., the co-occurrence statistics of textual and knowledge base relations collected from the entire corpus.
method_label: This approach turns out to be more robust to the training noise introduced by distant supervision.
method_label: On a popular relation extraction dataset, we show that the learned textual relation embedding can be used to augment existing relation extraction models and significantly improve their performance.
result_label: Most remarkably, for the top 1,000 relational facts discovered by the best existing model, the precision can be improved from 83.9% to 89.3%.

===================================
paper_id: 16222004; YEAR: 2014
adju relevance: Related (+1)
difference: 2; annotator4: 2; annotator3: 0
sources: abs_tfidf - title_tfidf
TITLE: Biomedical Relation Extraction: From Binary to Complex
ABSTRACT: objective_label: Biomedical relation extraction aims to uncover high-quality relations from life science literature with high accuracy and efficiency.
background_label: Early biomedical relation extraction tasks focused on capturing binary relations, such as protein-protein interactions, which are crucial for virtually every process in a living cell.
background_label: Information about these interactions provides the foundations for new therapeutic approaches.
background_label: In recent years, more interests have been shifted to the extraction of complex relations such as biomolecular events.
background_label: While complex relations go beyond binary relations and involve more than two arguments, they might also take another relation as an argument.
objective_label: In the paper, we conduct a thorough survey on the research in biomedical relation extraction.
method_label: We first present a general framework for biomedical relation extraction and then discuss the approaches proposed for binary and complex relation extraction with focus on the latter since it is a much more difficult task compared to binary relation extraction.
result_label: Finally, we discuss challenges that we are facing with complex relation extraction and outline possible solutions and future directions.

===================================
paper_id: 16389974; YEAR: 2016
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: specter - title_tfidf
TITLE: Relation Extraction with Multi-instance Multi-label Convolutional Neural Networks
ABSTRACT: background_label: AbstractDistant supervision is an efficient approach that automatically generates labeled data for relation extraction (RE).
background_label: Traditional distantly supervised RE systems rely heavily on handcrafted features, and hence suffer from error propagation.
background_label: Recently, a neural network architecture has been proposed to automatically extract features for relation classification.
method_label: However, this approach follows the traditional expressed-at-least-once assumption, and fails to make full use of information across different sentences.
background_label: Moreover, it ignores the fact that there can be multiple relations holding between the same entity pair.
objective_label: In this paper, we propose a multi-instance multi-label convolutional neural network for distantly supervised RE.
method_label: It first relaxes the expressed-at-least-once assumption, and employs cross-sentence max-pooling so as to enable information sharing across different sentences.
method_label: Then it handles overlapping relations by multi-label learning with a neural network classifier.
result_label: Experimental results show that our approach performs significantly and consistently better than state-of-the-art methods.

===================================
paper_id: 4004795; YEAR: 2013
adju relevance: Related (+1)
difference: 0; annotator4: 1; annotator3: 1
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Approximate Subgraph Matching-Based Literature Mining for Biomedical Events and Relations
ABSTRACT: background_label: The biomedical text mining community has focused on developing techniques to automatically extract important relations between biological components and semantic events involving genes or proteins from literature.
objective_label: In this paper, we propose a novel approach for mining relations and events in the biomedical literature using approximate subgraph matching.
method_label: Extraction of such knowledge is performed by searching for an approximate subgraph isomorphism between key contextual dependencies and input sentence graphs.
method_label: Our approach significantly increases the chance of retrieving relations or events encoded within complex dependency contexts by introducing error tolerance into the graph matching process, while maintaining the extraction precision at a high level.
result_label: When evaluated on practical tasks, it achieves a 51.12% F-score in extracting nine types of biological events on the GE task of the BioNLP-ST 2011 and an 84.22% F-score in detecting protein-residue associations.
result_label: The performance is comparable to the reported systems across these tasks, and thus demonstrates the generalizability of our proposed approach.

===================================
paper_id: 2335236; YEAR: 2011
adju relevance: Related (+1)
difference: 2; annotator4: 0; annotator3: 2
sources: title_tfidf
TITLE: Relation Extraction with Relation Topics
ABSTRACT: background_label: AbstractThis paper describes a novel approach to the semantic relation detection problem.
background_label: Instead of relying only on the training instances for a new relation, we leverage the knowledge learned from previously trained relation detectors.
method_label: Specifically, we detect a new semantic relation by projecting the new relation's training instances onto a lower dimension topic space constructed from existing relation detectors through a three step process.
method_label: First, we construct a large relation repository of more than 7,000 relations from Wikipedia.
method_label: Second, we construct a set of non-redundant relation topics defined at multiple scales from the relation repository to characterize the existing relations.
method_label: Similar to the topics defined over words, each relation topic is an interpretable multinomial distribution over the existing relations.
method_label: Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations.
result_label: The experimental results on Wikipedia and ACE data have confirmed that backgroundknowledge-based topics generated from the Wikipedia relation repository can significantly improve the performance over the state-of-theart relation detection approaches.

===================================
paper_id: 1724837; YEAR: 2016
adju relevance: Related (+1)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_tfidfcbow200 - abs_cbow200 - abs_tfidf - specter
TITLE: CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases
ABSTRACT: background_label: Extracting entities and relations for types of interest from text is important for understanding massive text corpora.
background_label: Traditionally, systems of entity relation extraction have relied on human-annotated corpora for training and adopted an incremental pipeline.
background_label: Such systems require additional human expertise to be ported to a new domain, and are vulnerable to errors cascading down the pipeline.
objective_label: In this paper, we investigate joint extraction of typed entities and relations with labeled data heuristically obtained from knowledge bases (i.e., distant supervision).
method_label: As our algorithm for type labeling via distant supervision is context-agnostic, noisy training data poses unique challenges for the task.
method_label: We propose a novel domain-independent framework, called CoType, that runs a data-driven text segmentation algorithm to extract entity mentions, and jointly embeds entity mentions, relation mentions, text features and type labels into two low-dimensional spaces (for entity and relation mentions respectively), where, in each space, objects whose types are close will also have similar representations.
method_label: CoType, then using these learned embeddings, estimates the types of test (unlinkable) mentions.
method_label: We formulate a joint optimization problem to learn embeddings from text corpora and knowledge bases, adopting a novel partial-label loss function for noisy labeled data and introducing an object"translation"function to capture the cross-constraints of entities and relations on each other.
result_label: Experiments on three public datasets demonstrate the effectiveness of CoType across different domains (e.g., news, biomedical), with an average of 25% improvement in F1 score compared to the next best method.

===================================
paper_id: 8328889; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Efficient Vector Representation for Documents through Corruption
ABSTRACT: background_label: We present an efficient document representation learning framework, Document Vector through Corruption (Doc2VecC).
background_label: Doc2VecC represents each document as a simple average of word embeddings.
method_label: It ensures a representation generated as such captures the semantic meanings of the document during learning.
method_label: A corruption model is included, which introduces a data-dependent regularization that favors informative or rare words while forcing the embeddings of common and non-discriminative ones to be close to zero.
method_label: Doc2VecC produces significantly better word embeddings than Word2Vec.
method_label: We compare Doc2VecC with several state-of-the-art document representation learning algorithms.
result_label: The simple model architecture introduced by Doc2VecC matches or out-performs the state-of-the-art in generating high-quality document representations for sentiment analysis, document classification as well as semantic relatedness tasks.
result_label: The simplicity of the model enables training on billions of words per hour on a single machine.
result_label: At the same time, the model is very efficient in generating representations of unseen documents at test time.

===================================
paper_id: 12057965; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200 - abs_tfidf
TITLE: x.ent: R Package for Entities and Relations Extraction based on Unsupervised Learning and Document Structure
ABSTRACT: background_label: Relation extraction with accurate precision is still a challenge when processing full text databases.
objective_label: We propose an approach based on cooccurrence analysis in each document for which we used document organization to improve accuracy of relation extraction.
method_label: This approach is implemented in a R package called \emph{x.ent}.
method_label: Another facet of extraction relies on use of extracted relation into a querying system for expert end-users.
method_label: Two datasets had been used.
method_label: One of them gets interest from specialists of epidemiology in plant health.
method_label: For this dataset usage is dedicated to plant-disease exploration through agricultural information news.
result_label: An open-data platform exploits exports from \emph{x.ent} and is publicly available.

===================================
paper_id: 8465797; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: title_tfidf
TITLE: Relation Extraction : A Survey
ABSTRACT: background_label: With the advent of the Internet, large amount of digital text is generated everyday in the form of news articles, research publications, blogs, question answering forums and social media.
background_label: It is important to develop techniques for extracting information automatically from these documents, as lot of important information is hidden within them.
method_label: This extracted information can be used to improve access and management of knowledge hidden in large text corpora.
background_label: Several applications such as Question Answering, Information Retrieval would benefit from this information.
result_label: Entities like persons and organizations, form the most basic unit of the information.
background_label: Occurrences of entities in a sentence are often linked through well-defined relations; e.g., occurrences of person and organization in a sentence may be linked through relations such as employed at.
objective_label: The task of Relation Extraction (RE) is to identify such relations automatically.
method_label: In this paper, we survey several important supervised, semi-supervised and unsupervised RE techniques.
method_label: We also cover the paradigms of Open Information Extraction (OIE) and Distant Supervision.
method_label: Finally, we describe some of the recent trends in the RE techniques and possible future research directions.
result_label: This survey would be useful for three kinds of readers - i) Newcomers in the field who want to quickly learn about RE; ii) Researchers who want to know how the various RE techniques evolved over time and what are possible future research directions and iii) Practitioners who just need to know which RE technique works best in various settings.

===================================
paper_id: 118988729; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: A Microphotonic Astrocomb
ABSTRACT: background_label: One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers.
background_label: It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources.
background_label: A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers.
method_label: Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz.
method_label: This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer.
result_label: As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research.

===================================
paper_id: 13357550; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Document image binarization using background estimation and stroke edges
ABSTRACT: background_label: Document images often suffer from different types of degradation that renders the document image binarization a challenging task.
objective_label: This paper presents a document image binarization technique that segments the text from badly degraded document images accurately.
method_label: The proposed technique is based on the observations that the text documents usually have a document background of the uniform color and texture and the document text within it has a different intensity level compared with the surrounding document background.
method_label: Given a document image, the proposed technique first estimates a document background surface through an iterative polynomial smoothing procedure.
method_label: Different types of document degradation are then compensated by using the estimated document background surface.
method_label: The text stroke edge is further detected from the compensated document image by using L1-norm image gradient.
method_label: Finally, the document text is segmented by a local threshold that is estimated based on the detected text stroke edges.
result_label: The proposed technique was submitted to the recent document image binarization contest (DIBCO) held under the framework of ICDAR 2009 and has achieved the top performance among 43 algorithms that are submitted from 35 international research groups.

===================================
paper_id: 5857908; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: WINGNUS: Keyphrase Extraction Utilizing Document Logical Structure
ABSTRACT: background_label: AbstractWe present a system description of the WINGNUS team work 1 for the SemEval-2010 task #5 Automatic Keyphrase Extraction from Scientific Articles.
method_label: A key feature of our system is that it utilizes an inferred document logical structure in our candidate identification process, to limit the number of phrases in the candidate list, while maintaining its coverage of important phrases.
method_label: Our top performing system achieves an F 1 of 25.22% for the combined keyphrases (author and reader assigned) in the final test data.
result_label: We note that the method we report here is novel and orthogonal from other systems, so it can be combined with other techniques to potentially achieve higher performance.

===================================
paper_id: 3103489; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Distributional Semantics Resources for Biomedical Text Processing
ABSTRACT: background_label: The openly available biomedical literature contains over 5 billion words in publication abstracts and full texts.
background_label: Recent advances in unsupervised language processing methods have made it possible to make use of such large unannotated corpora for building statistical language models and inducing high quality vector space representations, which are, in turn, of utility in many tasks such as text classification, named entity recognition and query expansion.
method_label: In this study, we introduce the first set of such language resources created from analysis of the entire available biomedical literature, including a dataset of all 1to 5-grams and their probabilities in these texts and new models of word semantics.
method_label: We discuss the opportunities created by these resources and demonstrate their application.
other_label: All resources introduced in this study are available under open licenses at http://bio.nlplab.org.

===================================
paper_id: 1877280; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Database of genomic biomarkers for cancer drugs and clinical targetability in solid tumors.
ABSTRACT: background_label: SUMMARY Comprehensive genomic profiling is expected to revolutionize cancer therapy.
background_label: In this Prospective, we present the prevalence of mutations and copy-number alterations with predictive associations across solid tumors at different levels of stringency for gene-drug targetability.
background_label: More than 90% of The Cancer Genome Atlas samples have potentially targetable alterations, the majority with multiple events, illustrating the challenges for treatment prioritization given the complexity of the genomic landscape.
background_label: Nearly 80% of the variants in rarely mutated oncogenes are of uncertain functional significance, reflecting the gap in our understanding of the relevance of many alterations potentially linked to therapeutic actions.
result_label: Access to targeted agents in early clinical trials could affect treatment decision in 75% of patients with cancer.
result_label: Prospective implementation of large-scale molecular profiling and standardized reports of predictive biomarkers are fundamental steps for making precision cancer medicine a reality.

===================================
paper_id: 14846155; YEAR: 2011
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Extracting Relations Within and Across Sentences
ABSTRACT: background_label: AbstractPrevious work on relation extraction has focussed on identifying relationships between entities that occur in the same sentence (intra-sentential relations) rather than between entities in different sentences (inter-sentential relations) despite previous research having shown that intersentential relations commonly occur in information extraction corpora.
objective_label: This paper describes a SVM-based approach to relation extraction that is applied to both types.
method_label: Adapted features and techniques for counter-acting bias in SVM models are used to deal with specific issues that arise in the inter-sentential case.
result_label: It was found that the structured features used for intrasentential relation extraction can be easily adapted for the inter-sentential case and provides comparable performance.

===================================
paper_id: 6509744; YEAR: 2003
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Information Retrieval Based on OCR Errors in Scanned Documents
ABSTRACT: background_label: An important proportion of documents are document images, i.e.
background_label: scanned documents.
background_label: For their retrieval, it is important to recognize their contents.
background_label: Current technologies for optical character recognition (OCR) and document analysis do not handle such documents adequately because of the recognition errors.
objective_label: In this paper, we describe an approach that integrates the detection of errors in scanned texts without relying on a lexicon, and this detection is integrated in the research process.
method_label: The proposed algorithm consists of two basic steps.
method_label: In the first step, we apply editing operations on OCR words that generate a collection of error-grams and correction rules.
method_label: The second step uses query terms, error-grams, and correction rules to create searchable keywords, identify appropriate matching terms, and determine the degree of relevance of retrieved document images.
result_label: Algorithms has been tested on 979 document images provided by Media-team databases from Washington University, and the experimental results obtained show the effectiveness of our method and indicate improvement in comparison with the standard methods such as exact or partial matching, N-gram overlaps, and Q-gram distance.

===================================
paper_id: 19226723; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf - abs_tfidf
TITLE: Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach
ABSTRACT: background_label: Relation extraction is a fundamental task in information extraction.
background_label: Most existing methods have heavy reliance on annotations labeled by human experts, which are costly and time-consuming.
objective_label: To overcome this drawback, we propose a novel framework, REHession, to conduct relation extractor learning using annotations from heterogeneous information source, e.g., knowledge base and domain heuristics.
objective_label: These annotations, referred as heterogeneous supervision, often conflict with each other, which brings a new challenge to the original relation extraction task: how to infer the true label from noisy labels for a given instance.
method_label: Identifying context information as the backbone of both relation extraction and true label discovery, we adopt embedding techniques to learn the distributed representations of context, which bridges all components with mutual enhancement in an iterative fashion.
result_label: Extensive experimental results demonstrate the superiority of REHession over the state-of-the-art.

===================================
paper_id: 546306; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: title_tfidf
TITLE: Semi-Supervised Learning for Relation Extraction
ABSTRACT: objective_label: AbstractThis paper proposes a semi-supervised learning method for relation extraction.
method_label: Given a small amount of labeled data and a large amount of unlabeled data, it first bootstraps a moderate number of weighted support vectors via SVM through a co-training procedure with random feature projection and then applies a label propagation (LP) algorithm via the bootstrapped support vectors.
method_label: Evaluation on the ACE RDC 2003 corpus shows that our method outperforms the normal LP algorithm via all the available labeled data without SVM bootstrapping.
result_label: Moreover, our method can largely reduce the computational burden.
result_label: This suggests that our proposed method can integrate the advantages of both SVM bootstrapping and label propagation.

===================================
paper_id: 9484609; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidf - title_tfidfcbow200
TITLE: A Relation Extraction Framework for Biomedical Text Using Hybrid Feature Set
ABSTRACT: background_label: The information extraction from unstructured text segments is a complex task.
background_label: Although manual information extraction often produces the best results, it is harder to manage biomedical data extraction manually because of the exponential increase in data size.
background_label: Thus, there is a need for automatic tools and techniques for information extraction in biomedical text mining.
background_label: Relation extraction is a significant area under biomedical information extraction that has gained much importance in the last two decades.
method_label: A lot of work has been done on biomedical relation extraction focusing on rule-based and machine learning techniques.
background_label: In the last decade, the focus has changed to hybrid approaches showing better results.
background_label: This research presents a hybrid feature set for classification of relations between biomedical entities.
method_label: The main contribution of this research is done in the semantic feature set where verb phrases are ranked using Unified Medical Language System (UMLS) and a ranking algorithm.
method_label: Support Vector Machine and Naïve Bayes, the two effective machine learning techniques, are used to classify these relations.
method_label: Our approach has been validated on the standard biomedical text corpus obtained from MEDLINE 2001.
result_label: Conclusively, it can be articulated that our framework outperforms all state-of-the-art approaches used for relation extraction on the same corpus.

===================================
paper_id: 129945536; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: specter
TITLE: A bag-of-concepts model improves relation extraction in a narrow knowledge domain with limited data
ABSTRACT: background_label: This paper focuses on a traditional relation extraction task in the context of limited annotated data and a narrow knowledge domain.
method_label: We explore this task with a clinical corpus consisting of 200 breast cancer follow-up treatment letters in which 16 distinct types of relations are annotated.
method_label: We experiment with an approach to extracting typed relations called window-bounded co-occurrence (WBC), which uses an adjustable context window around entity mentions of a relevant type, and compare its performance with a more typical intra-sentential co-occurrence baseline.
method_label: We further introduce a new bag-of-concepts (BoC) approach to feature engineering based on the state-of-the-art word embeddings and word synonyms.
result_label: We demonstrate the competitiveness of BoC by comparing with methods of higher complexity, and explore its effectiveness on this small dataset.

===================================
paper_id: 1330896; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: Learning Object Location Predictors with Boosting and Grammar-Guided Feature Extraction
ABSTRACT: background_label: We present BEAMER: a new spatially exploitative approach to learning object detectors which shows excellent results when applied to the task of detecting objects in greyscale aerial imagery in the presence of ambiguous and noisy data.
background_label: There are four main contributions used to produce these results.
method_label: First, we introduce a grammar-guided feature extraction system, enabling the exploration of a richer feature space while constraining the features to a useful subset.
method_label: This is specified with a rule-based generative grammar crafted by a human expert.
method_label: Second, we learn a classifier on this data using a newly proposed variant of AdaBoost which takes into account the spatially correlated nature of the data.
method_label: Third, we perform another round of training to optimize the method of converting the pixel classifications generated by boosting into a high quality set of (x, y) locations.
method_label: Lastly, we carefully define three common problems in object detection and define two evaluation criteria that are tightly matched to these problems.
result_label: Major strengths of this approach are: (1) a way of randomly searching a broad feature space, (2) its performance when evaluated on well-matched evaluation criteria, and (3) its use of the location prediction domain to learn object detectors as well as to generate detections that perform well on several tasks: object counting, tracking, and target detection.
result_label: We demonstrate the efficacy of BEAMER with a comprehensive experimental evaluation on a challenging data set.

===================================
paper_id: 3356807; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks
ABSTRACT: background_label: Learning a similarity function between pairs of objects is at the core of learning to rank approaches.
background_label: In information retrieval tasks we typically deal with query-document pairs, in question answering -- question-answer pairs.
background_label: However, before learning can take place, such pairs needs to be mapped from the original space of symbolic words into some feature space encoding various aspects of their relatedness, e.g.
background_label: lexical, syntactic and semantic.
background_label: Feature engineering is often a laborious task and may require external knowledge sources that are not always available or difficult to obtain.
background_label: Recently, deep learning approaches have gained a lot of attention from the research community and industry for their ability to automatically learn optimal feature representation for a given task, while claiming state-of-the-art performance in many tasks in computer vision, speech recognition and natural language processing.
method_label: In this paper, we present a convolutional neural network architecture for reranking pairs of short texts, where we learn the optimal representation of text pairs and a similarity function to relate them in a supervised way from the available training data.
method_label: Our network takes only words in the input, thus requiring minimal preprocessing.
method_label: In particular, we consider the task of reranking short text pairs where elements of the pair are sentences.
method_label: We test our deep learning system on two popular retrieval tasks from TREC: Question Answering and Microblog Retrieval.
result_label: Our model demonstrates strong performance on the first task beating previous state-of-the-art systems by about 3\% absolute points in both MAP and MRR and shows comparable results on tweet reranking, while enjoying the benefits of no manual feature engineering and no additional syntactic parsers.

===================================
paper_id: 13804679; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates
ABSTRACT: background_label: AbstractDespite its substantial coverage, NomBank does not account for all withinsentence arguments and ignores extrasentential arguments altogether.
background_label: These arguments, which we call implicit, are important to semantic processing, and their recovery could potentially benefit many NLP applications.
method_label: We present a study of implicit arguments for a select group of frequent nominal predicates.
method_label: We show that implicit arguments are pervasive for these predicates, adding 65% to the coverage of NomBank.
method_label: We demonstrate the feasibility of recovering implicit arguments with a supervised classification model.
result_label: Our results and analyses provide a baseline for future work on this emerging task.

===================================
paper_id: 2367456; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Joint Extraction of Events and Entities within a Document Context
ABSTRACT: background_label: Events and entities are closely related; entities are often actors or participants in events and events without entities are uncommon.
background_label: The interpretation of events and entities is highly contextually dependent.
background_label: Existing work in information extraction typically models events separately from entities, and performs inference at the sentence level, ignoring the rest of the document.
objective_label: In this paper, we propose a novel approach that models the dependencies among variables of events, entities, and their relations, and performs joint inference of these variables across a document.
objective_label: The goal is to enable access to document-level contextual information and facilitate context-aware predictions.
result_label: We demonstrate that our approach substantially outperforms the state-of-the-art methods for event extraction as well as a strong baseline for entity extraction.

===================================
paper_id: 2591187; YEAR: 1999
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Constructing Biological Knowledge Bases by Extracting Information from Text Sources
ABSTRACT: background_label: Recently, there has been much effort in making databases for molecular biology more accessible and interoperable.
background_label: However, information in text form, such as MEDLINE records, remains a greatly underutilized source of biological information.
background_label: We have begun a research effort aimed at automatically mapping information from text sources into structured representations, such as knowledge bases.
objective_label: Our approach to this task is to use machine-learning methods to induce routines for extracting facts from text.
method_label: We describe two learning methods that we have applied to this task--a statistical text classification method, and a relational learning method--and our initial experiments in learning such information-extraction routines.
method_label: We also present an approach to decreasing the cost of learning information-extraction routines by learning from "weakly" labeled training data.

===================================
paper_id: 52100484; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Deep Probabilistic Logic: A Unifying Framework for Indirect Supervision
ABSTRACT: background_label: Deep learning has emerged as a versatile tool for a wide range of NLP tasks, due to its superior capacity in representation learning.
background_label: But its applicability is limited by the reliance on annotated examples, which are difficult to produce at scale.
background_label: Indirect supervision has emerged as a promising direction to address this bottleneck, either by introducing labeling functions to automatically generate noisy examples from unlabeled text, or by imposing constraints over interdependent label decisions.
method_label: A plethora of methods have been proposed, each with respective strengths and limitations.
background_label: Probabilistic logic offers a unifying language to represent indirect supervision, but end-to-end modeling with probabilistic logic is often infeasible due to intractable inference and learning.
method_label: In this paper, we propose deep probabilistic logic (DPL) as a general framework for indirect supervision, by composing probabilistic logic with deep learning.
method_label: DPL models label decisions as latent variables, represents prior knowledge on their relations using weighted first-order logical formulas, and alternates between learning a deep neural network for the end task and refining uncertain formula weights for indirect supervision, using variational EM.
method_label: This framework subsumes prior indirect supervision methods as special cases, and enables novel combination via infusion of rich domain and linguistic knowledge.
result_label: Experiments on biomedical machine reading demonstrate the promise of this approach.

===================================
paper_id: 30606; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200
TITLE: FBK-IRST: Kernel Methods for Semantic Relation Extraction
ABSTRACT: background_label: We present an approach for semantic relation extraction between nominals that combines shallow and deep syntactic processing and semantic information using kernel methods.
method_label: Two information sources are considered: (i) the whole sentence where the relation appears, and (ii) WordNet synsets and hypernymy relations of the candidate nominals.
method_label: Each source of information is represented by kernel functions.
method_label: In particular, five basic kernel functions are linearly combined and weighted under different conditions.
method_label: The experiments were carried out using support vector machines as classifier.
result_label: The system achieves an overall F1 of 71.8% on the Classification of Semantic Relations between Nominals task at SemEval-2007.

===================================
paper_id: 119425731; YEAR: 1972
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Unzerlegbare Darstellungen I
ABSTRACT: background_label: LetK be the structure got by forgetting the composition law of morphisms in a given category.
background_label: A linear representation ofK is given by a map V associating with any morphism ϕ: a→e ofK a linear vector space map V(ϕ): V(a)→V(e).
method_label: We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations.
other_label: This classification is related to an old paper by Yoshii [3].

===================================
paper_id: 4871532; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Local Word Vectors Guiding Keyphrase Extraction
ABSTRACT: background_label: Automated keyphrase extraction is a fundamental textual information processing task concerned with the selection of representative phrases from a document that summarize its content.
method_label: This work presents a novel unsupervised method for keyphrase extraction, whose main innovation is the use of local word embeddings (in particular GloVe vectors), i.e., embeddings trained from the single document under consideration.
method_label: We argue that such local representation of words and keyphrases are able to accurately capture their semantics in the context of the document they are part of, and therefore can help in improving keyphrase extraction quality.
result_label: Empirical results offer evidence that indeed local representations lead to better keyphrase extraction results compared to both embeddings trained on very large third corpora or larger corpora consisting of several documents of the same scientific field and to other state-of-the-art unsupervised keyphrase extraction methods.

===================================
paper_id: 13710324; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200 - specter
TITLE: An effective neural model extracting document level chemical-induced disease relations from biomedical literature.
ABSTRACT: background_label: Since identifying relations between chemicals and diseases (CDR) are important for biomedical research and healthcare, the challenge proposed by BioCreative V requires automatically mining causal relationships between chemicals and diseases which may span sentence boundaries.
background_label: Although most systems explore feature engineering and knowledge bases to recognize document level CDR relations, feature learning automatically is limited only in a sentence.
objective_label: In this work, we proposed an effective model that automatically learns document level semantic representations to extract chemical-induced disease (CID) relations from articles by combining advantages of convolutional neural network and recurrent neural network.
method_label: First, to purposefully collect contexts, candidate entities existing in multiple sentences of an article were masked to make the model have ability to discern candidate entities and general terms.
method_label: Next, considering the contiguity and temporality among associated sentences as well as the topic of an article, a hierarchical network architecture was designed at the document level to capture semantic information of different types of text segments in an article.
method_label: Finally, a softmax classifier performed the CID recognition.
result_label: Experimental results on the CDR corpus show that the proposed model achieves a good overall performance compared with other state-of-the-art methods.
result_label: Although only using two types of embedding vectors, our approach can perform well for recognizing not only intra-sentential but also inter-sentential CID relations.

===================================
paper_id: 6202202; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Type-Aware Distantly Supervised Relation Extraction with Linked Arguments
ABSTRACT: background_label: Distant supervision has become the leading method for training large-scale relation extractors, with nearly universal adoption in recent TAC knowledge-base population competitions.
background_label: However, there are still many questions about the best way to learn such extractors.
objective_label: In this paper we investigate four orthogonal improvements: integrating named entity linking (NEL) and coreference resolution into argument identification for training and extraction, enforcing type constraints of linked arguments, and partitioning the model by relation type signature.
method_label: We evaluate sentential extraction performance on two datasets: the popular set of NY Times articles partially annotated by Hoffmann et al.
method_label: (2011) and a new dataset, called GORECO, that is comprehensively annotated for 48 common relations.
result_label: We find that using NEL for argument identification boosts performance over the traditional approach (named entity recognition with string match), and there is further improvement from using argument types.
result_label: Our best system boosts precision by 44% and recall by 70%.

===================================
paper_id: 2015967; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200 - specter
TITLE: Probabilistic Bag-Of-Hyperlinks Model for Entity Linking
ABSTRACT: background_label: Many fundamental problems in natural language processing rely on determining what entities appear in a given text.
background_label: Commonly referenced as entity linking, this step is a fundamental component of many NLP tasks such as text understanding, automatic summarization, semantic search or machine translation.
background_label: Name ambiguity, word polysemy, context dependencies and a heavy-tailed distribution of entities contribute to the complexity of this problem.
objective_label: We here propose a probabilistic approach that makes use of an effective graphical model to perform collective entity disambiguation.
method_label: Input mentions (i.e.,~linkable token spans) are disambiguated jointly across an entire document by combining a document-level prior of entity co-occurrences with local information captured from mentions and their surrounding context.
method_label: The model is based on simple sufficient statistics extracted from data, thus relying on few parameters to be learned.
method_label: Our method does not require extensive feature engineering, nor an expensive training procedure.
method_label: We use loopy belief propagation to perform approximate inference.
method_label: The low complexity of our model makes this step sufficiently fast for real-time usage.
result_label: We demonstrate the accuracy of our approach on a wide range of benchmark datasets, showing that it matches, and in many cases outperforms, existing state-of-the-art methods.

===================================
paper_id: 52039417; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Kernelized Hashcode Representations for Relation Extraction
ABSTRACT: background_label: Kernel methods have produced state-of-the-art results for a number of NLP tasks such as relation extraction, but suffer from poor scalability due to the high cost of computing kernel similarities between natural language structures.
background_label: A recently proposed technique, kernelized locality-sensitive hashing (KLSH), can significantly reduce the computational cost, but is only applicable to classifiers operating on kNN graphs.
method_label: Here we propose to use random subspaces of KLSH codes for efficiently constructing an explicit representation of NLP structures suitable for general classification methods.
method_label: Further, we propose an approach for optimizing the KLSH model for classification problems by maximizing an approximation of mutual information between the KLSH codes (feature vectors) and the class labels.
result_label: We evaluate the proposed approach on biomedical relation extraction datasets, and observe significant and robust improvements in accuracy w.r.t.
result_label: state-of-the-art classifiers, along with drastic (orders-of-magnitude) speedup compared to conventional kernel methods.

===================================
paper_id: 16584058; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: A hybrid approach to automatic text summarization
ABSTRACT: background_label: Automatic text summarization is to compress an original document into an abridged version by extracting almost all of the essential concepts with text mining techniques.
objective_label: This research focuses on developing a hybrid automatic text summarization approach, KCS, to enhancing the quality of summaries.
method_label: KCS employs the K-mixture probabilistic model to establish term weights in a statistical sense, and further identifies the term relationships to derive the connective strength (CS) of nouns.
method_label: Sentences are ranked and extracted based on their CS values.
method_label: We conduct two experiments to justify the proposed approach.
method_label: The quality of extracted summary is examined by its capability of increasing text classification accuracy.
result_label: The results show that our proposed approach, KCS, performs best among all approaches considered.
result_label: It implies that KCS can extract more representative sentences from the document and its feasibility in text summarization applications is thus justified.

===================================
paper_id: 36117198; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: DeepMind_Commentary
ABSTRACT: background_label: We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential.
background_label: However, we favor an approach that centers on one additional ingredient: autonomy.
objective_label: In particular, we aim toward agents that can both build and exploit their own internal models, with minimal human hand-engineering.
method_label: We believe an approach centered on autonomous learning has the greatest chance of success as we scale toward real-world complexity, tackling domains for which ready-made formal models are not available.
result_label: Here we survey several important examples of the progress that has been made toward building autonomous agents with humanlike abilities, and highlight some outstanding challenges.

===================================
paper_id: 49539740; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Theme-weighted Ranking of Keywords from Text Documents using Phrase Embeddings
ABSTRACT: background_label: Keyword extraction is a fundamental task in natural language processing that facilitates mapping of documents to a concise set of representative single and multi-word phrases.
background_label: Keywords from text documents are primarily extracted using supervised and unsupervised approaches.
method_label: In this paper, we present an unsupervised technique that uses a combination of theme-weighted personalized PageRank algorithm and neural phrase embeddings for extracting and ranking keywords.
method_label: We also introduce an efficient way of processing text documents and training phrase embeddings using existing techniques.
method_label: We share an evaluation dataset derived from an existing dataset that is used for choosing the underlying embedding model.
result_label: The evaluations for ranked keyword extraction are performed on two benchmark datasets comprising of short abstracts (Inspec), and long scientific papers (SemEval 2010), and is shown to produce results better than the state-of-the-art systems.

===================================
paper_id: 17211750; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: The clinical trial landscape in oncology and connectivity of somatic mutational profiles to targeted therapies
ABSTRACT: background_label: BACKGROUND Precision medicine in oncology relies on rapid associations between patient-specific variations and targeted therapeutic efficacy.
background_label: Due to the advancement of genomic analysis, a vast literature characterizing cancer-associated molecular aberrations and relative therapeutic relevance has been published.
background_label: However, data are not uniformly reported or readily available, and accessing relevant information in a clinically acceptable time-frame is a daunting proposition, hampering connections between patients and appropriate therapeutic options.
background_label: One important therapeutic avenue for oncology patients is through clinical trials.
background_label: Accordingly, a global view into the availability of targeted clinical trials would provide insight into strengths and weaknesses and potentially enable research focus.
result_label: However, data regarding the landscape of clinical trials in oncology is not readily available, and as a result, a comprehensive understanding of clinical trial availability is difficult.
background_label: RESULTS To support clinical decision-making, we have developed a data loader and mapper that connects sequence information from oncology patients to data stored in an in-house database, the JAX Clinical Knowledgebase (JAX-CKB), which can be queried readily to access comprehensive data for clinical reporting via customized reporting queries.
method_label: JAX-CKB functions as a repository to house expertly curated clinically relevant data surrounding our 358-gene panel, the JAX Cancer Treatment Profile (JAX CTP), and supports annotation of functional significance of molecular variants.
method_label: Through queries of data housed in JAX-CKB, we have analyzed the landscape of clinical trials relevant to our 358-gene targeted sequencing panel to evaluate strengths and weaknesses in current molecular targeting in oncology.
method_label: Through this analysis, we have identified patient indications, molecular aberrations, and targeted therapy classes that have strong or weak representation in clinical trials.
method_label: CONCLUSIONS Here, we describe the development and disseminate system methods for associating patient genomic sequence data with clinically relevant information, facilitating interpretation and providing a mechanism for informing therapeutic decision-making.
result_label: Additionally, through customized queries, we have the capability to rapidly analyze the landscape of targeted therapies in clinical trials, enabling a unique view into current therapeutic availability in oncology.

===================================
paper_id: 7991041; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: LTH: Semantic Structure Extraction using Nonprojective Dependency Trees
ABSTRACT: objective_label: We describe our contribution to the SemEval task on Frame-Semantic Structure Extraction.
background_label: Unlike most previous systems described in literature, ours is based on dependency syntax.
method_label: We also describe a fully automatic method to add words to the FrameNet lexical database, which gives an improvement in the recall of frame detection.

===================================
paper_id: 62678445; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Semantic Role Labeling
ABSTRACT: background_label: This tutorial will describe semantic role labeling, the assignment of semantic roles to eventuality participants in an attempt to approximate a semantic representation of an utterance.
background_label: The linguistic background and motivation for the definition of semantic roles will be presented, as well as the basic approach to semantic role annotation of large amounts of corpora.
background_label: Recent extensions to this approach that encompass light verb constructions and predicative adjectives will be included, with reference to their impact on English, Arabic, Hindi and Chinese.
method_label: Current proposed extensions such as Abstract Meaning Representations and richer event representations will also be touched on.Details of machine learning approaches will be provided, beginning with fully supervised approaches that use the annotated corpora as training material.
method_label: The importance of syntactic parse information and the contributions of different feature choices, including tree kernels, will be discussed, as well as the advantages and disadvantages of particular machine learning algorithms and approaches such as joint inference.
method_label: Appropriate considerations for evaluation will be presented as well as successful uses of semantic role labeling in NLP applications.We will also cover techniques for exploiting unlabeled corpora and transferring models across languages.
method_label: These include methods, which project annotations across languages using parallel data, induce representations solely from unlabeled corpora (unsupervised methods) or exploit a combination of a small amount of human annotation and a large unlabeled corpus (semi-supervised techniques).
method_label: We will discuss methods based on different machine learning paradigms, including generative Bayesian models, graph-based algorithms and bootstrapping style techniques.
result_label: 102 Outline

===================================
paper_id: 1320606; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Refining Event Extraction through Cross-Document Inference
ABSTRACT: background_label: AbstractWe apply the hypothesis of "One Sense Per Discourse" (Yarowsky, 1995) to information extraction (IE), and extend the scope of "discourse" from one single document to a cluster of topically-related documents.
method_label: We employ a similar approach to propagate consistent event arguments across sentences and documents.
method_label: Combining global evidence from related documents with local decisions, we design a simple scheme to conduct cross-document inference for improving the ACE event extraction task 1 .
result_label: Without using any additional labeled data this new approach obtained 7.6% higher F-Measure in trigger labeling and 6% higher F-Measure in argument labeling over a state-of-the-art IE system which extracts events independently for each sentence.

===================================
paper_id: 15846774; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Inferring Implicit Causal Relationships in Biomedical Literature
ABSTRACT: background_label: AbstractBiomedical relations are often expressed between entities occurring within the same sentence through syntactic means.
background_label: However, a significant portion of such relations (in particular, causal relations) are expressed implicitly across sentence boundaries.
background_label: Inferring these discourse-level relations can be challenging in the absence of syntactic clues.
objective_label: In this paper, we present a study of textual characteristics that contribute to expression of implicit causal relations across sentence boundaries.
method_label: Focusing on a chemical-disease relationship corpus, we identify and investigate the contribution of various features that can assist in identifying such inter-sentential relations.
method_label: Using these features for supervised learning, we were able to improve previously reported best results by more than 13%.
result_label: Our results demonstrate the usefulness of the proposed features and the importance of using a balanced dataset for this task.

===================================
paper_id: 8496802; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Monogenic Binary Pattern (MBP): A Novel Feature Extraction and Representation Model for Face Recognition
ABSTRACT: method_label: A novel feature extraction method, namely monogenic binary pattern (MBP), is proposed in this paper based on the theory of monogenic signal analysis, and the histogram of MBP (HMBP) is subsequently presented for robust face representation and recognition.
method_label: MBP consists of two parts: one is monogenic magnitude encoded via uniform LBP, and the other is monogenic orientation encoded as quadrant-bit codes.
method_label: The HMBP is established by concatenating the histograms of MBP of all sub-regions.
method_label: Compared with the well-known and powerful Gabor filtering based LBP schemes, one clear advantage of HMBP is its lower time and space complexity because monogenic signal analysis needs fewer convolutions and generates more compact feature vectors.
result_label: The experimental results on the AR and FERET face databases validate that the proposed MBP algorithm has better performance than or comparable performance with state-of-the-art local feature based methods but with significantly lower time and space complexity.

===================================
paper_id: 7333692; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Semantic Representations for Domain Adaptation: A Case Study on the Tree Kernel-based Method for Relation Extraction
ABSTRACT: background_label: We study the application of word embeddings to generate semantic representations for the domain adaptation problem of relation extraction (RE) in the tree kernelbased method.
method_label: We systematically evaluate various techniques to generate the semantic representations and demonstrate that they are effective to improve the generalization performance of a tree kernel-based relation extractor across domains (up to 7% relative improvement).
method_label: In addition, we compare the tree kernel-based and the feature-based method for RE in a compatible way, on the same resources and settings, to gain insights into which kind of system is more robust to domain changes.
result_label: Our results and error analysis shows that the tree kernel-based method outperforms the feature-based approach.

===================================
paper_id: 247735; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200 - title_tfidf
TITLE: Improved Relation Extraction with Feature-Rich Compositional Embedding Models
ABSTRACT: background_label: Compositional embedding models build a representation (or embedding) for a linguistic structure based on its component word embeddings.
objective_label: We propose a Feature-rich Compositional Embedding Model (FCM) for relation extraction that is expressive, generalizes to new domains, and is easy-to-implement.
objective_label: The key idea is to combine both (unlexicalized) hand-crafted features with learned word embeddings.
method_label: The model is able to directly tackle the difficulties met by traditional compositional embeddings models, such as handling arbitrary types of sentence annotations and utilizing global information for composition.
result_label: We test the proposed model on two relation extraction tasks, and demonstrate that our model outperforms both previous compositional models and traditional feature rich models on the ACE 2005 relation extraction task, and the SemEval 2010 relation classification task.
result_label: The combination of our model and a log-linear classifier with hand-crafted features gives state-of-the-art results.

===================================
paper_id: 18895336; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Employing Word Representations and Regularization for Domain Adaptation of Relation Extraction
ABSTRACT: background_label: Relation extraction suffers from a performance loss when a model is applied to out-of-domain data.
background_label: This has fostered the development of domain adaptation techniques for relation extraction.
objective_label: This paper evaluates word embeddings and clustering on adapting feature-based relation extraction systems.
method_label: We systematically explore various ways to apply word embeddings and show the best adaptation improvement by combining word cluster and word embedding information.
result_label: Finally, we demonstrate the effectiveness of regularization for the adaptability of relation extractors.

===================================
paper_id: 15568379; YEAR: 2012
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Summarizing figures, tables, and algorithms in scientific publications to augment search results
ABSTRACT: background_label: Increasingly, special-purpose search engines are being built to enable the retrieval of document-elements like tables, figures, and algorithms [Bhatia et al.
background_label: 2010; Liu et al.
background_label: 2007; Hearst et al.
background_label: 2007].
background_label: These search engines present a thumbnail view of document-elements, some document metadata such as the title of the papers and their authors, and the caption of the document-element.
method_label: While some authors in some disciplines write carefully tailored captions, generally, the author of a document assumes that the caption will be read in the context of the text in the document.
result_label: When the caption is presented out of context as in a document-element-search-engine result, it may not contain enough information to help the end-user understand what the content of the document-element is.
background_label: Consequently, end-users examining document-element search results would want a short “synopsis” of this information presented along with the document-element.
background_label: Having access to the synopsis allows the end-user to quickly understand the content of the document-element without having to download and read the entire document as examining the synopsis takes a shorter time than finding information about a document element by downloading, opening and reading the file.
background_label: Furthermore, it may allow the end-user to examine more results than they would otherwise.
method_label: In this paper, we present the first set of methods to extract this useful information (synopsis) related to document-elements automatically.
method_label: We use Naïve Bayes and support vector machine classifiers to identify relevant sentences from the document text based on the similarity and the proximity of the sentences with the caption and the sentences in the document text that refer to the document-element.
method_label: We compare the two classification methods and study the effects of different features used.
method_label: We also investigate the problem of choosing the optimum synopsis-size that strikes a balance between the information content and the size of the generated synopses.
result_label: A user study is also performed to measure how the synopses generated by our proposed method compare with other state-of-the-art approaches.

===================================
paper_id: 32012283; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: LRAGE: Learning Latent Relationships With Adaptive Graph Embedding for Aerial Scene Classification
ABSTRACT: background_label: The performance of scene classification relies heavily on the spatial and structural features that are extracted from high spatial resolution remote-sensing images.
background_label: Existing approaches, however, are limited in adequately exploiting latent relationships between scene images.
objective_label: Aiming to decrease the distances between intraclass images and increase the distances between interclass images, we propose a latent relationship learning framework that integrates an adaptive graph with the constraints of the feature space and label propagation for high-resolution aerial image classification.
method_label: To describe the latent relationships among scene images in the framework, we construct an adaptive graph that is embedded into the constrained joint space for features and labels.
method_label: To remove redundant information and improve the computational efficiency, subspace learning is introduced to assist in the latent relationship learning.
method_label: To address out-of-sample data, linear regression is adopted to project the semisupervised classification results onto a linear classifier.
method_label: Learning efficiency is improved by minimizing the objective function via the linearized alternating direction method with an adaptive penalty.
method_label: We test our method on three widely used aerial scene image data sets.
result_label: The experimental results demonstrate the superior performance of our method over the state-of-the-art algorithms in aerial scene image classification.

===================================
paper_id: 1893204; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Autonomously semantifying wikipedia
ABSTRACT: background_label: Berners-Lee's compelling vision of a Semantic Web is hindered by a chicken-and-egg problem, which can be best solved by a bootstrapping method - creating enough structured data to motivate the development of applications.
objective_label: This paper argues that autonomously "Semantifying Wikipedia" is the best way to solve the problem.
method_label: We choose Wikipedia as an initial data source, because it is comprehensive, not too large, high-quality, and contains enough manually-derived structure to bootstrap an autonomous, self-supervised process.
method_label: We identify several types of structures which can be automatically enhanced in Wikipedia (e.g., link structure, taxonomic data, infoboxes, etc.
method_label: ), and we describea prototype implementation of a self-supervised, machine learning system which realizes our vision.
result_label: Preliminary experiments demonstrate the high precision of our system's extracted data - in one case equaling that of humans.

===================================
paper_id: 8692445; YEAR: 2006
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Learning Field Compatibilities To Extract Database Records From Unstructured Text
ABSTRACT: background_label: Named-entity recognition systems extract entities such as people, organizations, and locations from unstructured text.
background_label: Rather than extract these mentions in isolation, this paper presents a record extraction system that assembles mentions into records (i.e.
objective_label: database tuples).
method_label: We construct a probabilistic model of the compatibility between field values, then employ graph partitioning algorithms to cluster fields into cohesive records.
method_label: We also investigate compatibility functions over sets of fields, rather than simply pairs of fields, to examine how higher representational power can impact performance.
method_label: We apply our techniques to the task of extracting contact records from faculty and student homepages, demonstrating a 53% error reduction over baseline approaches.

===================================
paper_id: 44134207; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_cbow200
TITLE: Resolving Event Coreference with Supervised Representation Learning and Clustering-Oriented Regularization
ABSTRACT: background_label: We present an approach to event coreference resolution by developing a general framework for clustering that uses supervised representation learning.
objective_label: We propose a neural network architecture with novel Clustering-Oriented Regularization (CORE) terms in the objective function.
method_label: These terms encourage the model to create embeddings of event mentions that are amenable to clustering.
method_label: We then use agglomerative clustering on these embeddings to build event coreference chains.
result_label: For both within- and cross-document coreference on the ECB+ corpus, our model obtains better results than models that require significantly more pre-annotated information.
result_label: This work provides insight and motivating results for a new general approach to solving coreference and clustering problems with representation learning.

===================================
paper_id: 9631585; YEAR: 2009
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Overview of BioNLP’09 Shared Task on Event Extraction
ABSTRACT: background_label: The paper presents the design and implementation of the BioNLP'09 Shared Task, and reports the final results with analysis.
method_label: The shared task consists of three sub-tasks, each of which addresses bio-molecular event extraction at a different level of specificity.
method_label: The data was developed based on the GENIA event corpus.
method_label: The shared task was run over 12 weeks, drawing initial interest from 42 teams.
method_label: Of these teams, 24 submitted final results.
result_label: The evaluation results are encouraging, indicating that state-of-the-art performance is approaching a practically applicable level and revealing some remaining challenges.

===================================
paper_id: 14646431; YEAR: 2012
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidfcbow200 - title_cbow200 - title_tfidf
TITLE: Pattern Learning for Relation Extraction with a Hierarchical Topic Model
ABSTRACT: background_label: AbstractWe describe the use of a hierarchical topic model for automatically identifying syntactic and lexical patterns that explicitly state ontological relations.
method_label: We leverage distant supervision using relations from the knowledge base FreeBase, but do not require any manual heuristic nor manual seed list selections.
result_label: Results show that the learned patterns can be used to extract new relations with good precision.

===================================
paper_id: 60588668; YEAR: 1998
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Overview of MUC-7/MET-2
ABSTRACT: background_label: Abstract : The tasks performed by the systems participating in the seventh Message Understanding Conference and the Second Multilingual Entity Task are described here in general terms with examples.
background_label: On the level of entity extraction, Named Entities (NE) were defined as proper names and quantities of interest.
background_label: Person, organization, and location names were marked as well as dates, times, percentages, and monetary amounts.
method_label: The annotation was SGML within the text stream.
method_label: An example from MUC-7 (New York Times News Service) in English follows.
result_label: The ENAMEX TYPE=LOCATIONU.K./ENAMEX satellite television broadcaster said its subscriber base grew NUMEX TYPE=PERCENT17.5 percent/NUMEX during TIMEX TYPE=DATEthe past year/TIMEX to 5.35 million The Named Entity task was carried out in Chinese and Japanese (MET-2) concurrently with English (MUC-7).

===================================
paper_id: 202558859; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - specter
TITLE: Global Locality in Event Extraction
ABSTRACT: background_label: Due to the exponential growth of biomedical literature, event and relation extraction are important tasks in biomedical text mining.
background_label: Most work in relation extraction detect a single entity pair mention on a short span of text, which is not ideal due to long sentences that appear in biomedical contexts.
objective_label: We propose an approach to both event and relation extraction, for simultaneously predicting relationships between all mention pairs in a text.
method_label: Our model includes a set of multi-head attentions and convolutions, an adaptation of the transformer architecture, which offers self-attention the ability to strengthen dependencies among related elements, and models the interaction between features extracted by multiple attention heads.
result_label: Experiment results demonstrate that our approach outperforms the state-of-the-art on a set of benchmark biomedical corpora including BioNLP 2009, 2011, 2013 and BioCreative 2017 shared tasks.

===================================
paper_id: 53297099; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf - title_tfidf
TITLE: Combining Long Short Term Memory and Convolutional Neural Network for Cross-Sentence n-ary Relation Extraction
ABSTRACT: background_label: We propose in this paper a combined model of Long Short Term Memory and Convolutional Neural Networks (LSTM-CNN) that exploits word embeddings and positional embeddings for cross-sentence n-ary relation extraction.
method_label: The proposed model brings together the properties of both LSTMs and CNNs, to simultaneously exploit long-range sequential information and capture most informative features, essential for cross-sentence n-ary relation extraction.
method_label: The LSTM-CNN model is evaluated on standard dataset on cross-sentence n-ary relation extraction, where it significantly outperforms baselines such as CNNs, LSTMs and also a combined CNN-LSTM model.
result_label: The paper also shows that the LSTM-CNN model outperforms the current state-of-the-art methods on cross-sentence n-ary relation extraction.

===================================
paper_id: 3409061; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Chinese Open Relation Extraction and Knowledge Base Establishment
ABSTRACT: background_label: Named entity relation extraction is an important subject in the field of information extraction.
background_label: Although many English extractors have achieved reasonable performance, an effective system for Chinese relation extraction remains undeveloped due to the lack of Chinese annotation corpora and the specificity of Chinese linguistics.
background_label: Here, we summarize three kinds of unique but common phenomena in Chinese linguistics.
objective_label: In this article, we investigate unsupervised linguistics-based Chinese open relation extraction (ORE), which can automatically discover arbitrary relations without any manually labeled datasets, and research the establishment of a large-scale corpus.
method_label: By mapping the entity relations into dependency-trees and considering the unique Chinese linguistic characteristics, we propose a novel unsupervised Chinese ORE model based on Dependency Semantic Normal Forms (DSNFs).
method_label: This model imposes no restrictions on the relative positions among entities and relationships and achieves a high yield by extracting relations mediated by verbs or nouns and processing the parallel clauses.
result_label: Empirical results from our model demonstrate the effectiveness of this method, which obtains stable performance on four heterogeneous datasets and achieves better precision and recall in comparison with several Chinese ORE systems.
result_label: Furthermore, a large-scale knowledge base of entity and relation, called COER, is established and published by applying our method to web text, which conquers the trouble of lack of Chinese corpora.

===================================
paper_id: 139526472; YEAR: 2015
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf
TITLE: Automatic Text Summarization
ABSTRACT: background_label: This paper investigates on sentence extraction based single Document summarization.
background_label: It saves time in our daily work once we get summarized data.
background_label: Today there are so many Documents, articles, papers and reports available in digital form, but most of them lack summaries.
method_label: Automatic text Summarization is a technique where a computer summarizes a text.
method_label: A text is given to the computer and the computer returns a required extract of the original text document.
method_label: Our methods on the sentence extraction-based text summarization task use the graph based algorithm to calculate importance of each sentence in document and most important sentences are extracted to generate document summary.
method_label: These extraction based text summarization methods give an indexing weight to the document terms to compute the similarity values between sentences

===================================
paper_id: 49304811; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200 - abs_tfidfcbow200
TITLE: Multi-task Character-Level Attentional Networks for Medical Concept Normalization
ABSTRACT: background_label: Recognizing standard medical concepts in the colloquial text is significant for kinds of applications such as the medical question answering system.
background_label: Recently, word-level neural network methods, which can learn complex informal expression features, achieved remarkable performance on this task.
method_label: However, they have two main limitations: (1) Existing word-level methods cannot learn character structure features inside words and suffer from “Out-of-vocabulary” (OOV) words, which are common in noisy colloquial text.
method_label: (2) Since these methods handle the normalization task as a classification issue, concept phrases are represented by category labels.
method_label: Hence the word morphological information inside the concept is lost.
method_label: In this work, we present a multi-task character-level attentional network model for medical concept normalization.
background_label: Specifically, the character-level encoding scheme of our model can alleviate the OOV word problem.
background_label: The attention mechanism can effectively exploit the word morphological information through multi-task training.
background_label: It generates higher attention weights on domain-related positions in the text sequence, helping the downstream convolution focus on the characters that are related to medical concepts.
method_label: To test our model, we first introduce a labeled Chinese dataset (overall 314,991 records) for this task.
method_label: Other two real-world English datasets are also used.
result_label: Our model outperforms state-of-the-art methods on all three datasets.
result_label: Besides, by adding four types noises to the datasets, we validate the robustness of our model against common noises in the colloquial text.

===================================
paper_id: 1120217; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidf - title_cbow200 - title_tfidfcbow200
TITLE: Exploiting neighborhood knowledge for single document summarization and keyphrase extraction
ABSTRACT: objective_label: Document summarization and keyphrase extraction are two related tasks in the IR and NLP fields, and both of them aim at extracting condensed representations from a single text document.
method_label: Existing methods for single document summarization and keyphrase extraction usually make use of only the information contained in the specified document.
method_label: This article proposes using a small number of nearest neighbor documents to improve document summarization and keyphrase extraction for the specified document, under the assumption that the neighbor documents could provide additional knowledge and more clues.
method_label: The specified document is expanded to a small document set by adding a few neighbor documents close to the document, and the graph-based ranking algorithm is then applied on the expanded document set to make use of both the local information in the specified document and the global information in the neighbor documents.
result_label: Experimental results on the Document Understanding Conference (DUC) benchmark datasets demonstrate the effectiveness and robustness of our proposed approaches.
result_label: The cross-document sentence relationships in the expanded document set are validated to be beneficial to single document summarization, and the word cooccurrence relationships in the neighbor documents are validated to be very helpful to single document keyphrase extraction.

===================================
paper_id: 13756489; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Attention Is All You Need
ABSTRACT: background_label: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration.
background_label: The best performing models also connect the encoder and decoder through an attention mechanism.
objective_label: We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.
method_label: Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train.
method_label: Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU.
result_label: On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.
result_label: We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.

===================================
paper_id: 2410895; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: BIOSMILE: A semantic role labeling system for biomedical verbs using a maximum-entropy model with automatically generated template features
ABSTRACT: background_label: BackgroundBioinformatics tools for automatic processing of biomedical literature are invaluable for both the design and interpretation of large-scale experiments.
background_label: Many information extraction (IE) systems that incorporate natural language processing (NLP) techniques have thus been developed for use in the biomedical field.
background_label: A key IE task in this field is the extraction of biomedical relations, such as protein-protein and gene-disease interactions.
background_label: However, most biomedical relation extraction systems usually ignore adverbial and prepositional phrases and words identifying location, manner, timing, and condition, which are essential for describing biomedical relations.
method_label: Semantic role labeling (SRL) is a natural language processing technique that identifies the semantic roles of these words or phrases in sentences and expresses them as predicate-argument structures.
method_label: We construct a biomedical SRL system called BIOSMILE that uses a maximum entropy (ME) machine-learning model to extract biomedical relations.
result_label: BIOSMILE is trained on BioProp, our semi-automatic, annotated biomedical proposition bank.
method_label: Currently, we are focusing on 30 biomedical verbs that are frequently used or considered important for describing molecular events.ResultsTo evaluate the performance of BIOSMILE, we conducted two experiments to (1) compare the performance of SRL systems trained on newswire and biomedical corpora; and (2) examine the effects of using biomedical-specific features.
result_label: The experimental results show that using BioProp improves the F-score of the SRL system by 21.45% over an SRL system that uses a newswire corpus.
method_label: It is noteworthy that adding automatically generated template features improves the overall F-score by a further 0.52%.
result_label: Specifically, ArgM-LOC, ArgM-MNR, and Arg2 achieve statistically significant performance improvements of 3.33%, 2.27%, and 1.44%, respectively.ConclusionWe demonstrate the necessity of using a biomedical proposition bank for training SRL systems in the biomedical domain.
result_label: Besides the different characteristics of biomedical and newswire sentences, factors such as cross-domain framesets and verb usage variations also influence the performance of SRL systems.
method_label: For argument classification, we find that NE (named entity) features indicating if the target node matches with NEs are not effective, since NEs may match with a node of the parsing tree that does not have semantic role labels in the training set.
method_label: We therefore incorporate templates composed of specific words, NE types, and POS tags into the SRL system.
result_label: As a result, the classification accuracy for adjunct arguments, which is especially important for biomedical SRL, is improved significantly.

===================================
paper_id: 955518; YEAR: 2014
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200 - title_tfidf
TITLE: Modeling Joint Entity and Relation Extraction with Table Representation
ABSTRACT: background_label: This paper proposes a history-based structured learning approach that jointly extracts entities and relations in a sentence.
objective_label: We introduce a novel simple and flexible table representation of entities and relations.
method_label: We investigate several feature settings, search orders, and learning methods with inexact search on the table.
result_label: The experimental results demonstrate that a joint learning approach significantly outperforms a pipeline approach by incorporating global features and by selecting appropriate learning methods and search orders.

===================================
paper_id: 2129710; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200 - title_tfidf
TITLE: TransNet: Translation-Based Network Representation Learning for Social Relation Extraction
ABSTRACT: background_label: AbstractConventional network representation learning (NRL) models learn low-dimensional vertex representations by simply regarding each edge as a binary or continuous value.
background_label: However, there exists rich semantic information on edges and the interactions between vertices usually preserve distinct meanings, which are largely neglected by most existing NRL models.
objective_label: In this work, we present a novel Translation-based NRL model, TransNet, by regarding the interactions between vertices as a translation operation.
result_label: Moreover, we formalize the task of Social Relation Extraction (SRE) to evaluate the capability of NRL methods on modeling the relations between vertices.Experimental results on SRE demonstrate that TransNet significantly outperforms other baseline methods by 10% to 20% on hits@1.
other_label: The source code and datasets can be obtained from https: //github.com/thunlp/TransNet.

===================================
paper_id: 59158885; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: Phonetic-enriched Text Representation for Chinese Sentiment Analysis with Reinforcement Learning
ABSTRACT: background_label: The Chinese pronunciation system offers two characteristics that distinguish it from other languages: deep phonemic orthography and intonation variations.
background_label: We are the first to argue that these two important properties can play a major role in Chinese sentiment analysis.
method_label: Particularly, we propose two effective features to encode phonetic information.
method_label: Next, we develop a Disambiguate Intonation for Sentiment Analysis (DISA) network using a reinforcement network.
method_label: It functions as disambiguating intonations for each Chinese character (pinyin).
method_label: Thus, a precise phonetic representation of Chinese is learned.
method_label: Furthermore, we also fuse phonetic features with textual and visual features in order to mimic the way humans read and understand Chinese text.
result_label: Experimental results on five different Chinese sentiment analysis datasets show that the inclusion of phonetic features significantly and consistently improves the performance of textual and visual representations and outshines the state-of-the-art Chinese character level representations.

===================================
paper_id: 51877084; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: A Deep Relevance Model for Zero-Shot Document Filtering
ABSTRACT: background_label: AbstractIn the era of big data, focused analysis for diverse topics with a short response time becomes an urgent demand.
background_label: As a fundamental task, information filtering therefore becomes a critical necessity.
objective_label: In this paper, we propose a novel deep relevance model for zero-shot document filtering, named DAZER.
method_label: DAZER estimates the relevance between a document and a category by taking a small set of seed words relevant to the category.
method_label: With pre-trained word embeddings from a large external corpus, DAZER is devised to extract the relevance signals by modeling the hidden feature interactions in the word embedding space.
method_label: The relevance signals are extracted through a gated convolutional process.
method_label: The gate mechanism controls which convolution filters output the relevance signals in a category dependent manner.
result_label: Experiments on two document collections of two different tasks (i.e., topic categorization and sentiment analysis) demonstrate that DAZER significantly outperforms the existing alternative solutions, including the state-of-the-art deep relevance ranking models.

===================================
paper_id: 60035918; YEAR: 2012
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200
TITLE: BioKeySpotter: An Unsupervised Keyphrase Extraction Technique in the Biomedical Full-Text Collection
ABSTRACT: background_label: Extracting keyphrases from full-text is a daunting task in that many different concepts and themes are intertwined and extensive term variations exist in full-text.
objective_label: In this chapter, we proposes a novel unsupervised keyphrase extraction system, BioKeySpotter, which incorporates lexical syntactic features to weigh candidate keyphrases.
method_label: The main contribution of our study is that BioKeySpotter is an innovative approach for combining Natural Language Processing (NLP), information extraction, and integration techniques into extracting keyphrases from full-text.
result_label: The results of the experiment demonstrate that BioKeySpotter generates a higher performance, in terms of accuracy, compared to other supervised learning algorithms.

===================================
paper_id: 9372965; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200 - abs_cbow200 - title_tfidfcbow200 - abs_tfidfcbow200
TITLE: Learning Word-Class Lattices for Definition and Hypernym Extraction
ABSTRACT: background_label: AbstractDefinition extraction is the task of automatically identifying definitional sentences within texts.
background_label: The task has proven useful in many research areas including ontology learning, relation extraction and question answering.
background_label: However, current approaches -mostly focused on lexicosyntactic patterns -suffer from both low recall and precision, as definitional sentences occur in highly variable syntactic structures.
method_label: In this paper, we propose WordClass Lattices (WCLs), a generalization of word lattices that we use to model textual definitions.
method_label: Lattices are learned from a dataset of definitions from Wikipedia.
method_label: Our method is applied to the task of definition and hypernym extraction and compares favorably to other pattern generalization methods proposed in the literature.

===================================
paper_id: 3627801; YEAR: 2017
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: cited - abs_cbow200 - abs_tfidf - abs_tfidfcbow200 - title_tfidf - specter
TITLE: Fonduer: Knowledge Base Construction from Richly Formatted Data
ABSTRACT: background_label: We focus on knowledge base construction (KBC) from richly formatted data.
objective_label: In contrast to KBC from text or tabular data, KBC from richly formatted data aims to extract relations conveyed jointly via textual, structural, tabular, and visual expressions.
method_label: We introduce Fonduer, a machine-learning-based KBC system for richly formatted data.
method_label: Fonduer presents a new data model that accounts for three challenging characteristics of richly formatted data: (1) prevalent document-level relations, (2) multimodality, and (3) data variety.
method_label: Fonduer uses a new deep-learning model to automatically capture the representation (i.e., features) needed to learn how to extract relations from richly formatted data.
background_label: Finally, Fonduer provides a new programming model that enables users to convert domain expertise, based on multiple modalities of information, to meaningful signals of supervision for training a KBC system.
background_label: Fonduer-based KBC systems are in production for a range of use cases, including at a major online retailer.
method_label: We compare Fonduer against state-of-the-art KBC approaches in four different domains.
method_label: We show that Fonduer achieves an average improvement of 41 F1 points on the quality of the output knowledge base---and in some cases produces up to 1.87x the number of correct entries---compared to expert-curated public knowledge bases.
method_label: We also conduct a user study to assess the usability of Fonduer's new programming model.
result_label: We show that after using Fonduer for only 30 minutes, non-domain experts are able to design KBC systems that achieve on average 23 F1 points higher quality than traditional machine-learning-based KBC approaches.

===================================
paper_id: 82456167; YEAR: 2007
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidf
TITLE: Janeway's Immunobiology
ABSTRACT: background_label: Part I An Introduction to Immunobiology and Innate Immunity 1.
background_label: Basic Concepts in Immunology 2.
background_label: Innate Immunity Part II The Recognition of Antigen 3.
background_label: Antigen Recognition by B-cell and T-cell Receptors 4.
method_label: The Generation of Lymphocyte Antigen Receptors 5.
method_label: Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6.
method_label: Signaling Through Immune System Receptors 7.
result_label: The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8.
background_label: T Cell-Mediated Immunity 9.
background_label: The Humoral Immune Response 10.
background_label: Dynamics of Adaptive Immunity 11.
other_label: The Mucosal Immune System Part V The Immune System in Health and Disease 12.
background_label: Failures of Host Defense Mechanism 13.
other_label: Allergy and Hypersensitivity 14.
other_label: Autoimmunity and Transplantation 15.
other_label: Manipulation of the Immune Response Part VI The Origins of Immune Responses 16.
other_label: Evolution of the Immune System Appendix I Immunologists' Toolbox Appendix II CD Antigens Appendix III Cytokines and their Receptors Appendix IV Chemokines and their Receptors Appendix V Immunological Constants

===================================
paper_id: 3011134; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_tfidfcbow200 - title_cbow200
TITLE: Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction
ABSTRACT: background_label: AbstractRelation Extraction (RE) is the task of extracting semantic relationships between entities in text.
background_label: Recent studies on relation extraction are mostly supervised.
background_label: The clear drawback of supervised methods is the need of training data: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to.
background_label: This is the problem of domain adaptation.
method_label: In this paper, we propose to combine (i) term generalization approaches such as word clustering and latent semantic analysis (LSA) and (ii) structured kernels to improve the adaptability of relation extractors to new text genres/domains.
result_label: The empirical evaluation on ACE 2005 domains shows that a suitable combination of syntax and lexical generalization is very promising for domain adaptation.

===================================
paper_id: 2678540; YEAR: 2012
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_cbow200 - abs_tfidf - abs_tfidfcbow200
TITLE: A robust approach to extract biomedical events from literature.
ABSTRACT: background_label: MOTIVATION The abundance of biomedical literature has attracted significant interest in novel methods to automatically extract biomedical relations from the literature.
background_label: Until recently, most research was focused on extracting binary relations such as protein-protein interactions and drug-disease relations.
background_label: However, these binary relations cannot fully represent the original biomedical data.
background_label: Therefore, there is a need for methods that can extract fine-grained and complex relations known as biomedical events.
method_label: RESULTS In this article we propose a novel method to extract biomedical events from text.
method_label: Our method consists of two phases.
background_label: In the first phase, training data are mapped into structured representations.
background_label: Based on that, templates are used to extract rules automatically.
method_label: In the second phase, extraction methods are developed to process the obtained rules.
result_label: When evaluated against the Genia event extraction abstract and full-text test datasets (Task 1), we obtain results with F-scores of 52.34 and 53.34, respectively, which are comparable to the state-of-the-art systems.
result_label: Furthermore, our system achieves superior performance in terms of computational efficiency.
other_label: AVAILABILITY Our source code is available for academic use at http://dl.dropbox.com/u/10256952/BioEvent.zip.

===================================
paper_id: 3611592; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_cbow200
TITLE: Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement Learning
ABSTRACT: background_label: With the increasing popularity of video sharing websites such as YouTube and Facebook, multimodal sentiment analysis has received increasing attention from the scientific community.
background_label: Contrary to previous works in multimodal sentiment analysis which focus on holistic information in speech segments such as bag of words representations and average facial expression intensity, we develop a novel deep architecture for multimodal sentiment analysis that performs modality fusion at the word level.
method_label: In this paper, we propose the Gated Multimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that is composed of 2 modules.
method_label: The Gated Multimodal Embedding alleviates the difficulties of fusion when there are noisy modalities.
method_label: The LSTM with Temporal Attention performs word level fusion at a finer fusion resolution between input modalities and attends to the most important time steps.
method_label: As a result, the GME-LSTM(A) is able to better model the multimodal structure of speech through time and perform better sentiment comprehension.
result_label: We demonstrate the effectiveness of this approach on the publicly-available Multimodal Corpus of Sentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achieving state-of-the-art sentiment classification and regression results.
result_label: Qualitative analysis on our model emphasizes the importance of the Temporal Attention Layer in sentiment prediction because the additional acoustic and visual modalities are noisy.
result_label: We also demonstrate the effectiveness of the Gated Multimodal Embedding in selectively filtering these noisy modalities out.
result_label: Our results and analysis open new areas in the study of sentiment analysis in human communication and provide new models for multimodal fusion.

===================================
paper_id: 54438611; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: specter - abs_cbow200 - abs_tfidf - abs_tfidfcbow200
TITLE: Integrating Local Context and Global Cohesiveness for Open Information Extraction
ABSTRACT: background_label: Extracting entities and their relations from text is an important task for understanding massive text corpora.
background_label: Open information extraction (IE) systems mine relation tuples (i.e., entity arguments and a predicate string to describe their relation) from sentences.
background_label: These relation tuples are not confined to a predefined schema for the relations of interests.
background_label: However, current Open IE systems focus on modeling local context information in a sentence to extract relation tuples, while ignoring the fact that global statistics in a large corpus can be collectively leveraged to identify high-quality sentence-level extractions.
objective_label: In this paper, we propose a novel Open IE system, called ReMine, which integrates local context signals and global structural signals in a unified, distant-supervision framework.
method_label: Leveraging facts from external knowledge bases as supervision, the new system can be applied to many different domains to facilitate sentence-level tuple extractions using corpus-level statistics.
method_label: Our system operates by solving a joint optimization problem to unify (1) segmenting entity/relation phrases in individual sentences based on local context; and (2) measuring the quality of tuples extracted from individual sentences with a translating-based objective.
method_label: Learning the two subtasks jointly helps correct errors produced in each subtask so that they can mutually enhance each other.
result_label: Experiments on two real-world corpora from different domains demonstrate the effectiveness, generality, and robustness of ReMine when compared to state-of-the-art open IE systems.

===================================
paper_id: 2642018; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: title_tfidfcbow200 - title_cbow200
TITLE: Multi-document summarization via sentence-level semantic analysis and symmetric matrix factorization
ABSTRACT: objective_label: Multi-document summarization aims to create a compressed summary while retaining the main characteristics of the original set of documents.
background_label: Many approaches use statistics and machine learning techniques to extract sentences from documents.
objective_label: In this paper, we propose a new multi-document summarization framework based on sentence-level semantic analysis and symmetric non-negative matrix factorization.
method_label: We first calculate sentence-sentence similarities using semantic analysis and construct the similarity matrix.
method_label: Then symmetric matrix factorization, which has been shown to be equivalent to normalized spectral clustering, is used to group sentences into clusters.
method_label: Finally, the most informative sentences are selected from each group to form the summary.
result_label: Experimental results on DUC2005 and DUC2006 data sets demonstrate the improvement of our proposed framework over the implemented existing summarization systems.
result_label: A further study on the factors that benefit the high performance is also conducted.

===================================
paper_id: 202542650; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_tfidfcbow200 - abs_cbow200 - title_tfidfcbow200
TITLE: Joint Extraction of Entities and Relations Based on a Novel Decomposition Strategy
ABSTRACT: background_label: Joint extraction of entities and relations aims to detect entity pairs along with their relations using a single model.
background_label: Prior works typically solve this task in the extract-then-classify or unified labeling manner.
background_label: However, these methods either suffer from the redundant entity pairs, or ignore the important inner structure in the process of extracting entities and relations.
method_label: To address these limitations, in this paper, we first decompose the joint extraction task into two inner-related subtasks, namely HE extraction and TER extraction.
method_label: The former subtask is to distinguish all head-entities that may be involved with target relations, and the latter is to identify corresponding tail-entities and relations for each extracted head-entity.
method_label: Next, these two subtasks are further deconstructed into several sequence labeling problems based on our proposed span-based tagging scheme, which are conveniently solved by a hierarchical boundary tagger and a multi-span decoding algorithm.
result_label: Owing to the reasonable decomposition strategy, our model can fully capture the semantic interdependency between different steps, as well as reduce noise from irrelevant entity pairs.Experimental results show that our method outperforms previous work by 5.6%, 17.2% and 3.7% (F1 score), achieving a new state-of-the-art on three public datasets.

===================================
paper_id: 2815993; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_cbow200
TITLE: Topic Modeling for Short Texts with Auxiliary Word Embeddings
ABSTRACT: background_label: For many applications that require semantic understanding of short texts, inferring discriminative and coherent latent topics from short texts is a critical and fundamental task.
background_label: Conventional topic models largely rely on word co-occurrences to derive topics from a collection of documents.
background_label: However, due to the length of each document, short texts are much more sparse in terms of word co-occurrences.
background_label: Data sparsity therefore becomes a bottleneck for conventional topic models to achieve good results on short texts.
method_label: On the other hand, when a human being interprets a piece of short text, the understanding is not solely based on its content words, but also her background knowledge (e.g., semantically related words).
result_label: The recent advances in word embedding offer effective learning of word semantic relations from a large corpus.
background_label: Exploiting such auxiliary word embeddings to enrich topic modeling for short texts is the main focus of this paper.
objective_label: To this end, we propose a simple, fast, and effective topic model for short texts, named GPU-DMM.
method_label: Based on the Dirichlet Multinomial Mixture (DMM) model, GPU-DMM promotes the semantically related words under the same topic during the sampling process by using the generalized Polya urn (GPU) model.
method_label: In this sense, the background knowledge about word semantic relatedness learned from millions of external documents can be easily exploited to improve topic modeling for short texts.
result_label: Through extensive experiments on two real-world short text collections in two languages, we show that GPU-DMM achieves comparable or better topic representations than state-of-the-art models, measured by topic coherence.
result_label: The learned topic representation leads to the best accuracy in text classification task, which is used as an indirect evaluation.

===================================
paper_id: 33278149; YEAR: 2016
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: title_cbow200 - title_tfidfcbow200
TITLE: Unsupervised High-Level Feature Extraction of SAR Imagery With Structured Sparsity Priors and Incremental Dictionary Learning
ABSTRACT: background_label: Sparse representation is an effective model for high-level feature extraction, and the dictionary is critical, since it can provide a sparse and discriminative feature for image classification.
background_label: However, the traditional sparse model with ℓ1- norm is unstable and ignores spatial context dependence.
background_label: Furthermore, the traditional off-line dictionary learning is less efficient.
method_label: In this letter, a high-level feature extraction approach is proposed, in which structured sparsity priors are imposed on the sparse representation to exploit the context dependence and an incremental structured dictionary learning method is proposed to exploit the inherent structures of a dictionary.
result_label: The experiment results on unsupervised synthetic aperture radar imagery classification show that the structured priors improve classification performance and the proposed algorithm is more efficient in dictionary learning compared with existing works.

===================================
paper_id: 16155178; YEAR: 2013
adju relevance: Irrelevant (0)
difference: 0; annotator4: 0; annotator3: 0
sources: abs_tfidfcbow200
TITLE: Multi-document summarization based on the Yago ontology
ABSTRACT: background_label: AbstractSentence-based multi-document summarization is the task of generating a succinct summary of a document collection, which consists of the most salient document sentences.
background_label: In recent years, the increasing availability of semanticsbased models (e.g., ontologies and taxonomies) has prompted researchers to investigate their usefulness for improving summarizer performance.
background_label: However, semantics-based document analysis is often applied as a preprocessing step, rather than integrating the discovered knowledge into the summarization process.
other_label: This paper proposes a novel summarizer, namely Yago-based Summarizer, * Corresponding author.
other_label: Tel.
other_label: : +39 011 090 7084.
other_label: Fax: +39 011 090 7099.
result_label: Email addresses: elena.baralis@polito.it (Elena Baralis), luca.cagliero@polito.it (Luca Cagliero), saima.jabeen@polito.it (Saima Jabeen), alessandro.fiori@ircc.it (Alessandro Fiori), sajid.shah@polito.it (Sajid Shah) Preprint submitted to that relies on an ontology-based evaluation and selection of the document sentences.
result_label: To capture the actual meaning and context of the document sentences and generate sound document summaries, an established entity recognition and disambiguation step based on the Yago ontology is integrated into the summarization process.The experimental results, which were achieved on the DUC'04 benchmark collections, demonstrate the effectiveness of the proposed approach compared to a large number of competitors as well as the qualitative soundness of the generated summaries.

===================================
paper_id: 2386383; YEAR: 2010
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: specter - abs_tfidf
TITLE: Modeling relations and their mentions without labeled text
ABSTRACT: other_label: Abstract.
background_label: Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision.
background_label: Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation.
objective_label: Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with.
method_label: We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB.
method_label: We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base.
result_label: When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction.

===================================
paper_id: 28322100; YEAR: 2004
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: abs_tfidfcbow200
TITLE: Computationally Efficient Approximation of a Probabilistic Model for Document Representation in the WEBSOM Full-Text Analysis Method
ABSTRACT: background_label: WEBSOM is a recently developed neural method for exploring full-text document collections, for information retrieval, and for information filtering.
background_label: In WEBSOM the full-text documents are encoded as vectors in a document space somewhat like in earlier information retrieval methods, but in WEBSOM the document space is formed in an unsupervised manner using the Self-Organizing Map algorithm.
method_label: In this article the document representations the WEBSOM creates are shown to be computationally efficient approximations of the results of a certain probabilistic model.
method_label: The probabilistic model incorporates information about the similarity of use of different words to take into account their semantic relations.

===================================
paper_id: 201126744; YEAR: 2019
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: specter
TITLE: Fine-tuning BERT for Joint Entity and Relation Extraction in Chinese Medical Text
ABSTRACT: background_label: Entity and relation extraction is the necessary step in structuring medical text.
background_label: However, the feature extraction ability of the bidirectional long short term memory network in the existing model does not achieve the best effect.
background_label: At the same time, the language model has achieved excellent results in more and more natural language processing tasks.
objective_label: In this paper, we present a focused attention model for the joint entity and relation extraction task.
method_label: Our model integrates well-known BERT language model into joint learning through dynamic range attention mechanism, thus improving the feature representation ability of shared parameter layer.
result_label: Experimental results on coronary angiography texts collected from Shuguang Hospital show that the F1-score of named entity recognition and relation classification tasks reach 96.89% and 88.51%, which are better than state-of-the-art methods 1.65% and 1.22%, respectively.

===================================
paper_id: 11473206; YEAR: 2008
adju relevance: Irrelevant (0)
difference: 1; annotator4: 1; annotator3: 0
sources: abs_cbow200 - abs_tfidf
TITLE: Extraction of semantic biomedical relations from text using conditional random fields
ABSTRACT: background_label: BACKGROUND The increasing amount of published literature in biomedicine represents an immense source of knowledge, which can only efficiently be accessed by a new generation of automated information extraction tools.
background_label: Named entity recognition of well-defined objects, such as genes or proteins, has achieved a sufficient level of maturity such that it can form the basis for the next step: the extraction of relations that exist between the recognized entities.
background_label: Whereas most early work focused on the mere detection of relations, the classification of the type of relation is also of great importance and this is the focus of this work.
method_label: In this paper we describe an approach that extracts both the existence of a relation and its type.
method_label: Our work is based on Conditional Random Fields, which have been applied with much success to the task of named entity recognition.
result_label: RESULTS We benchmark our approach on two different tasks.
result_label: The first task is the identification of semantic relations between diseases and treatments.
result_label: The available data set consists of manually annotated PubMed abstracts.
method_label: The second task is the identification of relations between genes and diseases from a set of concise phrases, so-called GeneRIF (Gene Reference Into Function) phrases.
result_label: In our experimental setting, we do not assume that the entities are given, as is often the case in previous relation extraction work.
background_label: Rather the extraction of the entities is solved as a subproblem.
background_label: Compared with other state-of-the-art approaches, we achieve very competitive results on both data sets.
method_label: To demonstrate the scalability of our solution, we apply our approach to the complete human GeneRIF database.
method_label: The resulting gene-disease network contains 34758 semantic associations between 4939 genes and 1745 diseases.
method_label: The gene-disease network is publicly available as a machine-readable RDF graph.
method_label: CONCLUSION We extend the framework of Conditional Random Fields towards the annotation of semantic relations from text and apply it to the biomedical domain.
method_label: Our approach is based on a rich set of textual features and achieves a performance that is competitive to leading approaches.
method_label: The model is quite general and can be extended to handle arbitrary biological entities and relation types.
result_label: The resulting gene-disease network shows that the GeneRIF database provides a rich knowledge source for text mining.
result_label: Current work is focused on improving the accuracy of detection of entities as well as entity boundaries, which will also greatly improve the relation extraction performance.

===================================
paper_id: 13755147; YEAR: 2018
adju relevance: Irrelevant (0)
difference: 1; annotator4: 0; annotator3: 1
sources: title_cbow200
TITLE: Unsupervised Disentangled Representation Learning with Analogical Relations
ABSTRACT: background_label: Learning the disentangled representation of interpretable generative factors of data is one of the foundations to allow artificial intelligence to think like people.
objective_label: In this paper, we propose the analogical training strategy for the unsupervised disentangled representation learning in generative models.
method_label: The analogy is one of the typical cognitive processes, and our proposed strategy is based on the observation that sample pairs in which one is different from the other in one specific generative factor show the same analogical relation.
method_label: Thus, the generator is trained to generate sample pairs from which a designed classifier can identify the underlying analogical relation.
method_label: In addition, we propose a disentanglement metric called the subspace score, which is inspired by subspace learning methods and does not require supervised information.
result_label: Experiments show that our proposed training strategy allows the generative models to find the disentangled factors, and that our methods can give competitive performances as compared with the state-of-the-art methods.

